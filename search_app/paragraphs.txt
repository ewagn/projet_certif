[{'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Manu: A Cloud Native Vector Database Management System †Zilliz ‡Department of Computer Science and Engineering, Southern University of Science and Technology §Technical University of Munich †{firstname.lastname}@zilliz.com ‡{xiangl3@mail., yanx@, 11911419@mail., tangb3@}sustech.edu.cn, §jigao.luo@tum.de With the development of learning-based embedding models, embed- ding vectors are widely used for analyzing and searching unstruc- tured data. As vector collections exceed billion-scale, fully managed and horizontally scalable vector databases are necessary. In the past three years, through interaction with our 1200+ industry users, we have sketched a vision for the features that next-generation vector databases should have, which include long-term evolvability, tunable consistency, good elasticity, and high performance. We present Manu, a cloud native vector database that imple- ments these features. It is difficult to integrate all these features if we follow traditional DBMS design rules. As most vector data applications do not require complex data models and strong data consistency, our design philosophy is to relax the data model and consistency constraints in exchange for the aforementioned fea- tures. Specifically, Manu firstly exposes the write-ahead log (WAL) and binlog as backbone services. Secondly, write components are designed as log publishers while all read-only analytic and search components are designed as independent subscribers to the log ser- vices. Finally, we utilize multi-version concurrency control (MVCC) and a delta consistency model to simplify the communication and cooperation among the system components. These designs achieve a low coupling among the system components, which is essential for elasticity and evolution. We also extensively optimize Manu for performance and usability with hardware-aware implementations and support for complex search semantics. Manu has been used for many applications, including, but not limited to, recommenda- tion, multimedia, language, medicine and security. We evaluated Manu in three typical application scenarios to demonstrate its effi- ciency, elasticity, and scalability.'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'PVLDB Reference Format: Rentong Guo, Xiaofan Luan, Long Xiang, Xiao Yan, Xiaomeng Yi, Jigao Luo, Qianya Cheng, Weizhi Xu, Jiarui Luo, Frank Liu, Zhenshan Cao, Yanliang Qiao, Ting Wang, Bo Tang, and Charles Xie. Manu: A Cloud Native Vector Database Management System. PVLDB, 15(12): XXX-XXX, 2022. doi:XX.XX/XXX.XX ∗Co-first-authors are ordered alphabetically. ‡ Work done while working with Zilliz, correspondence to Bo Tang. This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 15, No. 12 ISSN 2150-8097.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'PVLDB Artifact Availability: The source code, data, and/or other artifacts have been made available at https://github.com/milvus-io/milvus/tree/2.0.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'According to IDC, unstructured data, such as text, images, and video, took up about 80% of the 40,000 exabytes of new data generated in 2020, their percentage keeps rising due to the increasing amount of human-generated rich media [48]. With the rise of learning- based embedding models, especially deep neural networks, using embedding vectors to manage unstructured data has become com- monplace in many applications such as e-commerce, social media, and drug discovery [49, 63, 68]. A core feature of these applica- tions is that they encode the semantics of unstructured data into a high-dimensional vector space. Given the representation power of embedding vectors, operations like recommendation, search, and analysis can be implemented via similarity-based vector search. To support these applications, many specialized vector databases are built to manage vector data [11, 13, 18–20, 81]. In 2019, we open sourced Milvus [81], our previous vector data- base, under the LF AI & Data Foundation. Since then, we collected feed-backs from more than 1200 industry users and found that some of the design principles adopted by Milvus are not suitable. Milvus followed the design principles of relational databases, which are optimized for either transaction [52] or analytical [81] workloads, and focused on functionality supports (e.g., attribute filtering and multi-vector search) and execution efficiency (e.g., SIMD and cache optimizations). However, vector database applications have differ- ent requirements in the following three aspects, which motivates us to restructure Manu from scratch with focuses on a cloud-native architecture.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': '• Support for complex transactions is not necessary. Instead of decomposing entity representations into different fields or tables, learning-based models encode complex and hybrid data semantics into a single vector. As a result, multi-row or multi- table transactions are not necessary; row-level ACID is sufficient for the majority of vector database applications.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': '• A tunable performance-consistency trade-off is important. Different users have different consistency requirements; some users prefer high throughput and eventual consistency, while others require some level of guaranteed consistency, i.e., newly inserted data should be visible to queries either immediately or within a pre-configured time. Traditional relational databases generally support either strong consistency or eventual consis- tency; there is little to no room for customization between these two extremes. As such, tunable consistency is a crucial attribute for cloud-native vector databases.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '• High hardware cost calls for fine-grained elasticity. Some vector database operations (e.g., vector search and index build- ing) are computationally intensive, and hardware accelerators (e.g. GPUs or FPGAs) and/or a large working memory are re- quired for good performance. However, depending on application types, workload differs amongst database functionalities. Thus, resources can be wasted or improperly allocated if the vector database does not have fine-grained elasticity. This necessitates a careful decoupling of functional and hardware layers; system- level decoupling such as separation of read and write logic is insufficient, elasticity and resource isolation should be managed at the functionalities level rather than the system level.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'In summary, modern vector databases should have tunable con- sistency, functionality-level decoupling, and per-component scal- ability. Following the design principles of traditional relational databases makes achieving these design goals extremely difficult, if not impossible. A key opportunity for achieving these design goals lies in the potential for relaxing transaction complexity. Manu follows the “log as data” paradigm. Specifically, Manu struc- tures the entire system as a group of log publish/subscribe micro- services. The write-ahead log (WAL) and inter-component mes- sages are published as “logs", i.e., durable data streams that can be subscribed. Read-side components, such as search and analytical engines, are all built as log subscribers. This architecture provides a simple yet effective way to decouple system functionalities; it enables the decoupling of read from write, stateless from stateful, and storage from computing. Each log entry is assigned a global unique timestamp, and special log entries called time-tick (simi- lar to watermarks in Apache Flink [26]) are periodically inserted into each log channel signaling the progress of event-time for log subscribers. The timestamp and time-tick form the basis of the tunable consistency mechanism and multi-version consistency con- trol (MVCC). To control the consistency level, a user can specify a tolerable time lag between a query’s timestamp and the latest time-tick consumed by a subscriber. Additionally, we extensively optimize Manu for performance and usability. Manu supports various indexes for vector search, in- cluding vector quantization [22, 34, 37, 83], inverted index [24], and proximity graphs [33]. In particular, we tailor the implementations to better utilize the parallelization capabilities of modern CPUs and GPUs along with the improved read/write speeds of SSDs over HDDs. Manu also integrates refactored functionalities from Mil- vus [81], such as attribute filtering and multi-vector search. More- over, build a visualization tool that allows users to track the perfor- mance of Manu in real time and include an auto-configuration tool that recommends indexing algorithm parameters using machine learning. To summarize, this paper makes the following contributions: • We summarize lessons learned from communicating with over 1200 industry users over three years. We shed light on typical application requirements of vector databases and show how they differ from those of traditional relational databases. We then outline the key design goals that vector databases should meet.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '• We introduce Manu’s key architectural designs as a cloud native vector database, building around the core design philosophy of relaxing transaction complexity in exchange for tunable consis- tency and fine-grained elasticity.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '• We present important usability and performance-related en- hancements, e.g., high-level API, a GUI tool, automatic parameter configuration, and SSD support.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'The rest of the paper is organized as follows. Section 2 pro- vides background on the requirements and design goals of vector databases. Section 3 dives deep into Manu’s design. Section 4 high- lights the key features for usability and performance. Section 5 discusses representative use cases for Manu. Section 6 review re- lated works. Section 7 concludes the paper and outlines future work.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'Consider video recommendation as a typical use case of vector databases. The goal is to help users discover new videos based on their personal preferences and previous browsing history. Using machine learning models (especially deep neural networks), fea- tures of users and videos, such as search history, watch history, age, gender, video language, and tags are converted to embedding vectors. These models are carefully designed and trained to encode the similarity between user and video vectors into a common vec- tor space. Recommendation is conducted by retrieving candidate videos from the collection of video vectors via similarity scores with respect to the specified user vector. The system also needs to handle updates to vectors when new videos are updated, some videos are deleted and the embedding model is changed. Video recommendation and other applications of vector databases can involve hundreds of billions of vectors with daily growth at hundred-million scale, and serve million-scale queries per second (QPS). Existing DBMSs (e.g., relational databases [9, 12], NoSQL [76, 86], NewSQL [40, 74]) were not built to manage vector data on that scale. Moreover, the underlying data management requirements of their applications differ greatly from vector database applications. First, when compared with relational databases, both the archi- tecture and theory of vector databases are far from mature. A key reason for this is that AI- and data-driven applications are still in a state of constant evolution, thereby necessitating continued architectural and functionality changes to vector databases as well. Second, complex transactions are unnecessary for vector databases. In the above example, the recommendation system encodes all se- mantic features of users and videos into standalone vectors as opposed to multi-row or multi-column entity fields in a relational database. As a result, row-level ACID is sufficient; multi-table oper- ations (such as joins) are inessential. Third, vector database applications need a flexible performance- consistency trade-off. While some applications adopt a strong or eventual consistency model, there are others that fall between the two extremes. Users may wish to relax consistency constraints in exchange for better system throughput. In the video recommen- dation example, observing a newly uploaded video after several seconds is acceptable but keeping users waiting for recommenda- tion harms user experience. Thus, the application can configure the allowed maximal delay for the video updates in order to improve system throughput. Fourth, vector databases have more stringent and diversified hardware requirements compared with traditional databases. This is attributed to three reasons. First, vector database operations are computation-intensive, and thus hardware accelerators such as GPUs are critical for computing functionalities such as search and indexing. Second, accesses to vector data (e.g., search or up- date) generally have poor locality, thereby requiring large RAM for good performance. Third, different applications vary signifi- cantly in their resource demands for the system functionalities. Core functionalities of a vector database include data insertion, indexing, filtering, and vector search. Applications such as video recommendation require online insertion and high concurrency vector search. In contrast, for interactive use cases such as drug dis- covery, offline data ingestion and indexing are generally acceptable. Although interactive applications usually require lower throughput than recommendation systems, they have high demands for real- time filtering, similarity-based vector search, and hybrid queries. The high hardware costs as well as diverse workload features call for fine-grained elasticity. The key design goals of Manu are summarized below; these design goals not only fully encompass the above characteristics but also share some common goals with generic cloud-based databases.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Long-term evolvability: Overall system complexity must be controlled for the continuous evolution of Manu’s functionalities. Without the need to support complex transactions, there lies an opportunity to model all the event sequences (such as WAL and inter-component messages) as message queues to cleanly decou- ple the entire system. In this way, individual components can evolve, be added, or be replaced easily with minimal interference to other components. This design echos large-scale data analytic platforms, which often rely on data streaming systems such as Kafka to connect system components.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Tunable consistency: To enable flexible consistency-performance trade-off, Manu should introduce delta consistency that falls be- tween strong consistency and eventual consistency, where a read operation returns the last value that was produced at most delta time units preceding itself. It’s worth noting that strong consis- tency and eventual consistency can be realized as special cases of this model, with delta being zero and infinity, respectively.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Good elasticity: Workload fluctuations can cause different loads on individual system components. In order to dynamically al- locate compute resources to high-load tasks, components must be carefully decoupled, taking both functionality and hardware dependencies into consideration. System elasticity and resource isolation should be managed at the component-level rather than at the system-level (e.g. decoupling indexing from querying ver- sus decoupling read from write).', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• High availability: Availability is a must-have for modern cloud- based applications; Manu must isolate system failures at the component level and make failure recovery transparent.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Primary Key Feature Vector Label Numerical attribute LSN Figure 1: An example of Manu’s schema.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• High performance: Query processing performance is key to vector databases. For good performance, implementations to be extensively optimized for hardware. Moreover, the framework should be carefully designed so as to minimize system overheads for query serving.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Strong adaptability: Our customers use vector databases in a variety of environments, ranging from prototyping on laptops to large-scale deployments on the cloud. A vector database should provide consistent user experience and reduce code/data migra- tion overhead across environments.', 'part_title': '2 background and motivation'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'In this section, we begin by first introducing the basic concepts of Manu. Next, we present the system designs, including the overall system architecture, the log backbone, and how Manu conducts vector searches and builds vector search indexes.', 'part_title': '3 the manu system'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Schema: The basic data types of Manu are vector, string, boolean, integer, and floating point. A schema example is given in Figure 1. Suppose each entity consists of five fields and corresponds to a product on an e-commerce platform. The Primary key is the ID of the entity. It can either be an integer or a string. If users do not specify this field, the system will automatically add an integer primary key for each entity. The Feature vector is the embedding of the product. The Label is the category of the product, such as food, book, and cloth. The Numerical attribute is a float or an integer associated with the product, such as price, weight, or production date. Manu supports multiple labels and numerical attributes in each entity. Note that these fields are used for filtering, rather than join or aggregation. The Logical sequence number (LSN) is a system field hidden from users.', 'part_title': '3 the manu system', 'sub_title': '3.1 schema, collection, shard, and segment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Collection: A Collection is a set of entities similar to the concept of tables in relational databases. For example, a collection can contain all the products of an e-commerce platform. The key difference is that collections have no relations with each other; thus, relational algebra, such as join operations, are not supported.', 'part_title': '3 the manu system', 'sub_title': '3.1 schema, collection, shard, and segment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Shard: The Shard correspondence to insertion/deletion channel. Entities are hashed into multiple shards based on their primary keys during insertion/deletion. Manu’s data placement unit is segment rather than shard. 1 Segment: Entities from each shard are organized into segments. A segment can be in either a growing or sealed state. Sealed segments are read-only while growing segments can accept new entities. A growing segment will switch to sealed state when it reaches a prede- fined size (set to 512MB by default) or if a period of time has passed 1Using segments for data placement is more flexible than shards, as the number of shards is static, while the number of segments grows as the volume of the collection increases.', 'part_title': '3 the manu system', 'sub_title': '3.1 schema, collection, shard, and segment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'without an insertion (e.g., 10 seconds). As some segments may be small (e.g., when insertion has a low arrival rate), Manu merges small segments into larger ones for search efficiency.', 'part_title': '3 the manu system', 'sub_title': '3.1 schema, collection, shard, and segment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Manu adopts a service-oriented design [65] to achieve fine-grained decoupling among the system components. As shown in Figure 2, from top to bottom, Manu has four layers, i.e., access layer, coordi- nator layer, worker layer, and storage layer.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Access layer consists of stateless proxies that serve as the user endpoints. They work in parallel to receive requests from clients, distribute the requests to the corresponding processing components, and aggregate partial search results before returning to clients. Fur- thermore, the proxies cache a copy of the metadata for verifying the legitimacy of search requests (e.g., whether the collection to search exists). Search request verification is lightweight and moving it to the proxies has two key benefits. First, requests that fail verification are rejected early, thus lowering the load on other systems compo- nents. Second, it reduces the number of routing hops for requests, thus shortening request processing latency.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Coordinator layer manages system status, maintains metadata of the collections, and coordinates the system components for process- ing tasks. There are four coordinators, each responsible for different tasks. Root coordinator handles data definition requests, such as creating/deleting collections, and maintains meta-information of the collections. Data coordinator records detailed information about the collections (e.g., the routes of the segments on storage), and coordinates the data nodes to transform data update requests into binlogs [4]. Query coordinator manages the status of the query nodes, and adjusts the assignment of segments (along with related indexes) to query nodes for load balancing. Index coordinator main- tains meta-information of the indexes (e.g., index types and storage routes), and coordinates index nodes in index building tasks. A coordinator can have multiple instances (e.g., one main and two backups) for reliability. As vector databases usually do not have the cross table operations that relational databases have, different collections can be served by separate coordinator instances for throughput.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Worker layer conducts the actual computation tasks. The worker nodes are stateless—they fetch read-only copies of data to conduct Data Node Data Node Data Node Data Node Data Node Data Node Data Node Index Node Data Node Data Node Data Node Query Node More Analytic Figure 3: Overview of Manu’s log system.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'tasks and do not need to coordinate with each other. This ensures that computation intensive (thus expensive) worker nodes can be easily scaled on demand. We use different worker nodes for dif- ferent tasks, i.e., query nodes for query processing, index nodes for index building, and data nodes for log archiving. Due to the fact that the workloads for different computation tasks vary significantly over time and across applications, each worker type can scale inde- pendently. This design also achieves resource isolation as different computation tasks have different QoS requirements.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Storage layer persists system status, metadata, the collections, and associated indexes. Manu uses etcd [7] (a key-value store) to host system status and metadata for the coordinators as etcd provides high availability with its leader election mechanism for failure recovery. When metadata is updated, the updated data is first written to etcd, and then synchronized to coordinators. Since the volume of other data (e.g., binlog, data, index) is large, Manu uses AWS S3 [14] (an object storage) for persistence due to its high availability and low cost. The API of many other object storage systems is compatible with AWS S3. This allows Manu to easily swap storage engines, if necessary. At present, storage engines including AWS S3, MinIO [8], and Linux file system are supported. Note that the high latency that comes with object storage is not a performance bottleneck as the worker nodes conduct computation tasks on in-memory, read-only copies of data.', 'part_title': '3 the manu system', 'sub_title': '3.2 system architecture'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'The log system is the backbone of Manu, which connects the de- coupled system components. As shown in Figure 3, Manu exposes the write-ahead log (WAL) and binlog as backbone services. The WAL is the incremental part of system log while the binlog is the base part; they complement each other in delay, capacity and cost. Loggers are entry points for publishing data onto the WAL. Data nodes subscribe to the WAL and convert the row-based WALs into column-based binlogs. All read-only components such as index nodes and query nodes are independent subscribers to the log ser- vice to keep themselves up-to-date. This architecture completely decouples the write and read components, thus allowing the compo- nents (e.g., WAL, binlog, data nodes, index nodes and query nodes) to scale independently. Manu records all the requests that change system state to the log, including data definition requests (e.g., create/delete collection), data manipulation requests (e.g., insert/delete a vector), and sys- tem coordination messages (e.g., load/dump a collection to/from memory). Note that vector search requests are not written to the log as they are read-only operations and do not change system state. We use logical logs instead of physical logs, as logical logs focus on event recording, rather than describing the modifications to physical data pages. This allows the subscribers to consume the log data in different ways depending on their functions. Figure 4 illustrates the detailed architecture of the log system. For the sake of clarity, we only illustrate the parts related to insert requests. The loggers are organized in a hash ring, and each logger handles one or more logical buckets in the hash ring based on consistent hashing. Each shard corresponds to a logical bucket in the hash ring and a WAL channel. Each entity in insert requests is hashed to a shard (and thus channel) based on their ID. When a logger receives a request, it will first verify the legibility of the request, assign an LSN for the logged entity by consulting the central time service oracle (TSO), determine the segment the entity should go to, and write the entity to WAL. The logger also writes the mapping of the new entity ID to segment ID into a local LSM tree and periodically flushes the incremental part of the LSM tree to object storage, which keeps the entity to segment mapping using the SSTable format of RocksDB. Each logger caches the segment mapping (e.g., for checking if the entity to delete exists) for the shards it manages by consulting the SSTable in object storage. The WAL is row-based and read in a streaming manner for low delay and fine-grained log pub/sub. It is implemented via a cloud- based message queue such as Kafka or Pulsar. We use multiple logical channels for the WAL in order to prevent different types of requests from interfering with each other, thus achieving a high throughput. Data definition requests and system coordination mes- sages use their own channels while data manipulation requests hashed across multiple channels to increase throughput. Data nodes subscribe to the WAL and convert the row-based WALs into column-based binlogs. Specifically, values from the same field (e.g., attribute and vector) from the WALs are stored together in a column format in binlog files. The column-based nature of binlog makes it suitable for reading per field values in batches, thus increasing storage and IO efficiency. An example of this efficiency comes with the index nodes. Index nodes only read the required fields (e.g., attribute or vector) from the binlog for index building and thus are free from the read amplifications.', 'part_title': '3 the manu system', 'sub_title': '3.3 the log backbone'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'System coordination: Inter-component messages are also passed via log, e.g., data nodes announce when segments are written to storage and index nodes announce when indexes have been built. This is because the log system provides a simple and reliable mecha- nism for broadcasting system events. Moreover, the time semantics of the log system provide a deterministic order for coordination messages. For example, when a collection should be released from memory, the query coordinator publishes the request to log, and does not need to confirm whether the query nodes receive the mes- sage or handle query node failure. The query nodes independently subscribe to the log and asynchronously release segments of the collection.', 'part_title': '3 the manu system', 'sub_title': '3.3 the log backbone'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'We adopt a delta consistency model to enable flexible performance- consistency trade-offs, which guarantees a bounded staleness of data seen by search queries. Specifically, the data seen by a query Figure 4: Detailed structure of Manu’s log system.', 'part_title': '3 the manu system', 'sub_title': '3.4 tunable consistency'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'can be stale for up to delta time units, with respect to time of the last data update, where delta is an user-specified “staleness tolerance” given in virtual time. In practice, users prefer to define temporal tolerance as physical time, e.g., 10 seconds. Manu achieves this by making the LSN as- signed to each request extremely close to physical time. Manu uses a hybrid logical clock in the TSO to generate timestamps. Each timestamp has two components: a physical component that tracks physical time, and a logical component that tracks event order. The logical component is needed since multiple events may happen at the same physical time unit. Since a timestamp is used as a request’s LSN, the value of the physical component indicates the physical time when the request was received by Manu. For a log subscriber, e.g., a query node, to run the delta consis- tency model, it needs to know three things: (1) the user-specified staleness tolerance 𝜏, (2) the time of the last data update, and (3) the issue time of the search request. In order to let each log subscriber know (2), we introduce a time-tick mechanism. Special control mes- sages called time-ticks (similar to watermarks in Apache Flink [26]) are periodically inserted into each log channel (for example, WAL channel) signaling the progress of data synchronization. Denote the latest time-tick a subscriber consumed as 𝐿𝑠and the issue time of a query as 𝐿𝑟, if 𝐿𝑟−𝐿𝑠< 𝜏is not satisfied, the query node will wait for the next time-tick before executing the query. Note that strong consistency and eventual consistency are two special cases of delta consistency, where delta equals to 0 and infin- ity, respectively. To the best of our knowledge, our work is the first to support delta consistency in a vector database.', 'part_title': '3 the manu system', 'sub_title': '3.4 tunable consistency'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'Searching similar vectors in large collections by brute-force, i.e., scanning the whole dataset, usually yields unacceptably long de- lays. Numerous indexes have been proposed to accelerate vector search and Manu automatically builds user specified indexes. Ta- ble 1 summarizes the indexes currently supported by Manu, and we are continuously adding new indexes following the latest in- dexing algorithms. These indexes differ in their properties and use cases. Vector quantization (VQ) [34, 45] methods compress vectors to reduce memory footprint and the costs for vector distance/simi- larity computation. For example, scalar quantization (SQ) [91] maps each dimension of vector (data types typically are int32 and float) to a single byte. Inverted indexes [69] group vectors into clusters, and only scan the most promising clusters for a query. Proximity graphs [33, 42, 61] connect similar vectors to form a graph, and achieve high accuracy and low latency at the cost of high mem- ory consumption [54]. Besides vector indexes, Manu also supports indexes on the attribute field of the entities to accelerate attribute- based filtering. There are two index building scenarios in Manu, i.e., batch in- dexing and stream indexing. Batch indexing occurs when the user builds an index for an entire collection (e.g., when all vectors are updated with a new embedding model). In this case, the index co- ordinator obtains the paths of all segments in the collection from the data coordinator, and instructs index nodes to build indexes for each segment. Stream indexing happens when users contin- uously insert new entities, and indexes are built asynchronously on-the-fly without stopping search services. Specifically, after a seg- ment accumulates a sufficient number of vectors, its resident data node seals the segment and writes it to object storage as a binlog. The data coordinator then notifies the index coordinator, which instructs a index node to build index for the segment. The index node loads only the required column (e.g., vector or attribute) of the segment from object storage for indexing building to avoid read amplification. For entity deletions, Manu uses a bitmap to record the deleted vectors and rebuilds the index for a segment when a sufficient number of its entities have been deleted. In both batch and stream indexing scenarios, after the required index is built for a segment, the index node persists it in the object storage and sends the path to the index coordinator, which notifies the query coordi- nator so that query nodes can load the index for processing queries. The index coordinator also monitors the status of the index nodes and shuts down idle index nodes to save costs. As vector indexes generally have sub-linear search complexity w.r.t. the number of vectors, searching a large segment is cheaper than several small segments, Manu builds joint indexes on multiple segments when appropriate.', 'part_title': '3 the manu system', 'sub_title': '3.5 index building'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'Manu supports classical vector search, attribute filtering, and multi- vector search. For classical vector search, the distance/similarity function can be Euclidean distance, inner product or angular dis- tance. Attribute filtering is useful when searching vectors similar to the query subject to some attribute constraints. For example, an e-commerce platform may want to find products that interest the customer and cost less than 100$. Manu supports three strategies for attribute filtering and uses a cost-based model to choose the most suitable strategy for each segment. Multi-vector search is required when an entity is encoded by multiple vectors, for exam- ple, a product can be described by both embeddings of its image and embeddings of its text description. In this case, the similarity function between entities is defined as a composition of similarity functions on the constituting vectors. Manu supports two strategies for multi-vector search and chooses the one to use according to the entity similarity function. For more details about how Manu han- dles attribute filtering and multi-vector search, interested readers can refer to Milvus [81]. For vector search, Manu partitions a collection into segments and distributes the segments among query nodes for parallel exe- cution. 2 The proxies cache a copy of the distribution of segments on query nodes by inquiring the query coordinator, and dispatch search requests to query nodes that hold segments of the searched collection. The query nodes perform vector searches on their local segments without coordination using a two-phase reduce procedure. For a top-𝑘vector search request, the query nodes search their local segments to obtain the segment-wise top-𝑘results. These results are merged by each query node to form the node-wise top-𝑘results. Then, the node-wise top-𝑘results are aggregated by the proxy for the global top-𝑘results and returned to the application. To handle the deletion of vectors, the query nodes use a bitmap to record the deleted vectors in each segment and filter the deleted vectors from the segment-wise search results. Users can configure Manu to batch search requests to improve efficiency. In this case, the proxies organize cache search requests if results of the previous batches have not been returned yet. In the cache, requests of the same type (i.e., target the same collection and use the same similarity function) are organized into the one batch and handled by Manu together. Manu also allows maintaining multiple hot replicas of a collection to serve queries for availability and throughput. Query nodes obtain data from three sources, i.e., the WAL, the index files, and the binlog. For data in the growing segments, query nodes subscribe to the WAL and conduct searches using brute force scan so that updates can be searched within a short delay. A dilemma for segment size is that larger size yields better search efficiency once the index is built but brute force scan on growing segment is also more costly. To tackle this problem, we divide each segment into slices (each containing 10,000 vectors by default). New data are inserted into the slices sequentially, and after a slice is full, a light-weight temporary index (e.g., IVF-FLAT) is built for it. Empirically, we observed that the temporary index brings up to 10X speedup for searching growing segments. When a segment changes from growing state to sealed state, its index will be built by an index node and then stored in object storage. After that, query nodes are notified to load the index and replace the temporary index. Query nodes access the binlog for data when the distribution of segments among the query nodes changes, which may happen during scaling, load-balancing, query node failure and recovery. Specifically, the query coordinator manages the segment distribu- tion and monitors the query nodes for liveness and workload to coordinate failure recovery and scaling. On failure recovery, the segments and their corresponding indexes (if they exist) handled by failed query nodes are loaded to the healthy ones. 3 In the case of scaling down, a query node can be removed once other query nodes load the indexes for the segments it handles from the object storage. When scaling up, the query coordinator assigns some of 2Manu loads all data to the query nodes as different queries may access different parts of the data, and a hot compute side cache is necessary for low latency. This is different from general cloud DBMSs that decouple compute and storage (e.g., Snowflake [29]), which only fetch the required data to compute side upon request. 3The WAL channels subscribed to by failed query nodes are also assigned to healthy ones.', 'part_title': '3 the manu system', 'sub_title': '3.6 vector search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'Collection(name, schema) Create collection with name str and schema schema Collection.delete(expr) Delete vectors satisfying boolean expression expr from collection Collection.create_index(field, params) Create index on a field of the vectors using parameters params Collection.query(vec, params, expr) Vector search for vec with boolean expression expr as filters the segments to the newly added nodes. A new query node can join after it loads the assigned segments, and existing query nodes can release the segments no longer handled by them. The query coordi- nator also balances the workloads (and memory consumption) of the query nodes by migrating segments. Note that Manu does not ensure that segment redistribution is atomic, and a segment can re- side on more than one query node. This does not affect correctness as the proxies remove duplicate result vectors for a query.', 'part_title': '3 the manu system', 'sub_title': '3.6 vector search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'In this part, we introduce several key features of Manu for usability and performance.', 'part_title': '4 feature highlights', 'sub_title': '3.6 vector search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'The primary design goal of Manu is to be a cloud native vector database such that it fits well into cloud-based data pipelines. To this end, Manu decouples system functionalities into storage, coor- dinators, and workers in the overall design. For storage, Manu uses a transaction KV for metadata, message queues for logs, and an ob- ject KV for data, which are all general storage services provided by major cloud vendors and thus enables easy deployment. For coordi- nators that manage system functionalities, Manu uses the standard one main plus two hot backups configuration for high availability. For workers, Manu decouples vector search, log archiving and in- dex building tasks for component-wise scaling, a model suitable for cloud-based on-demand resource provisioning. The log backbone allows the system components to interact by writing/reading logs in their own ways. This enables the system components to evolve independently and makes it easy to add new components. The log backbone also provides consistent time semantics in the system, which are crucial for deterministic execution and failure recovery. Our customers use vector databases in the entire life-cycle of their applications. For example, an application usually starts with data scientists conducting proof of concept (PoC) on their personal computers. Then, it is migrated to dedicated clusters for testing and finally deployed on the cloud. Thus, to reduce migration costs, our customers expect vector databases to adapt to different deploy- ment scenarios while providing a consistent set of APIs. To this end, Manu defines unified interface for the system components but provides different invocation methods and implementations for different platforms. For example, on cloud, local cluster and per- sonal computer, Manu uses cloud service APIs, remote procedure call (RPC) and direct function calls to invoke system functionali- ties, respectively. The object KV can be the local file system (e.g., MinIO [8]) on personal computers, and S3 on AWS. Thus, Manu applications can migrate with little or no change across different deployment scenarios.', 'part_title': '4 feature highlights', 'sub_title': '4.1 cloud native and adaptive'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'Data pipelines interact with Manu in simple ways: vector collec- tions, updates for vector data and search requests are fed to Manu, and Manu returns the identifiers of the search results for each search request, which can be used to retrieve objects (e.g.. images, advertisements, movies) in other systems. Because different users adopt different programming languages and development envi- ronments, Manu provides APIs in popular languages including Python, Java, Go, C++, along with RESTful APIs. As an example, we show key commands of the Python-based PyManu API in Table 2, which uses the object-relational mapping (ORM) model and most commands are related to the collection class. As shown in Table 2, PyManu allows users to manage collections and indexes, update collections, and conduct vector searches. The search command is used for similarity-based vector search while the query command is mainly used for attribute filtering. We show an example of con- ducting top-𝑘vector search by specifying the parameters in params in as follows.', 'part_title': '4 feature highlights', 'sub_title': '4.2 good usability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'In the above example, the search request provides a high dimen- sional vector [0.6, 0.3, ..., 0.8] as query and searches the feature vector field of the collection. The similarity function is Euclidean distance and the targets are the top-2 similar vectors in the collec- tion (i.e., with limit = 2). For easy system management, Manu provides a GUI tool called Attu, for which a screen shot is shown in Figure 5. In the system view, users can observe overall system status including queries processed per second (QPS), average query latency, and memory consumption on the top of screen. By clicking a specific service (e.g., data service), users can view detailed information of the worker nodes for the service on the side. We also allow users to add and drop worker nodes with mouse clicks. In the collection view, users can check the collections in the system, load/dump collections to/from memory, delete/import collections, check the index built for the collections, and build new indexes. In the vector search view, users can check the search traffic and performance on each collection, configure the Figure 5: A screenshot of Attu, the GUI tool of Manu.', 'part_title': '4 feature highlights', 'sub_title': '4.2 good usability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'index and search parameters to use for each collection. The vector search view also allows to issue queries for functionality test. For vector search, using different parameters for the indexes (e.g., neighbor size 𝑀and queue size 𝐿for HNSW [61]) yields dif- ferent trade-offs among cost, accuracy, and performance. However, even experts find it difficult to set proper index parameters as the parameters are interdependent and their influences vary across collections. Manu adopts a Bayesian Optimization with Hyperband (BOHB) [32] method to automatically explore good index param- eter configurations. Users provide a utility function to score the configurations (e.g., according to search recall, query throughput) and set a budget to limit the costs of parameter search. BOHB starts with a group of initial configurations and evaluates their utilities. Then, Bayesian Optimization is used to generate new candidate configurations according to historical trials and Hyperband is used to allocate budgets to different areas in the configuration space. The idea is to prioritize the exploration of areas close to high util- ity configurations to find even better configurations. Manu also supports sampling a subset of the collection for the trails to reduce search costs. We are still improving the automatic parameter search module and plan to extend it to searching system configurations (e.g., the number and type of query nodes).', 'part_title': '4 feature highlights', 'sub_title': '4.2 good usability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'Users often need to rollback the database to fix corrupted data or code bugs. Manu allows users to specify a target physical time 𝑇 for database restore, and jointly uses checkpoint and log replay for rollback. We mark each segment with its progress 𝐿and periodi- cally checkpoints the segment map for a collection, which contains information (such a route, rather than data) of all its segments. To restore the database at time𝑇, we read the closest checkpoint before 𝑇, load all segments in the segment map and replay the WAL log for each segment from its local progress 𝐿. This design reduces storage consumption as we do not write entire collection for each check- point. Instead, segments that have no changes are shared among checkpoints. The replay overhead is also reduced as each segment has its own progress. Users can also specify a expiration period to delete outdated log and segments to reduce storage consumption.', 'part_title': '4 feature highlights', 'sub_title': '4.3 time travel'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'Manu comes with extensively optimized implementations for CPU, GPU and SSD for efficiency. For more details about our CPU and GPU optimizations, interested readers can refer to Milvus [81].', 'part_title': '4 feature highlights', 'sub_title': '4.4 hardware optimizations'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'Figure 6: Manu and Milvus for mixed workloads, numbers behind legends (e.g., 1k) indicate insertion rate.', 'part_title': '4 feature highlights', 'sub_title': '4.4 hardware optimizations'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'SSD is 100x cheaper than dram and offers 10x larger bandwidth than HDD. thus, Manu supports using SSD to store large vector collections on cheap query nodes with limited dram capacity. the challenge is that SSD bandwidth is still much smaller than dram, which may lead to low query processing throughput and thus ne- cessitates careful designs for storage layout and index structure. as SSD reads are conducted with 4kb blocks (i.e., reading less than 4kb has the same cost as reading 4kb), Manu organizes the vectors into buckets whose sizes are close to but smaller than 4kb. 4 this is achieved by conducting hierarchical k-means for the vectors and controlling the sizes of the clusters. each bucket is stored on 4kb aligned blocks on SSD for efficient read and represented by its k- means center in dram. these centers are organized using existing vector search indexes (e.g., ivf-flat, hnsw). vector search with SSD is conducted in two stages. first, we search the cluster centers in dram for the ones that are most similar to the query. then, the corresponding buckets are loaded from SSD for scan. to reduce the amount of data fetched from SSD, we compress the vectors using scalar quantization, which has negligible influence on the quality of search results according to our trials. another problem is that k-means can put vectors similar to a query into several buckets but the centers of some buckets may not be similar to the query, which leads to a low recall. to tackle this problem, Manu uses a strategy similar to multiple hash tables in locality sensitive hashing [41]. hierarchical k-means is conducted by multiple times, each time assigning a vector to a bucket. this means that a vector is replicated multiple times in SSD and we index all cluster centers for bucket search in dram. Manu’s SSD solution wins track 2 (search with SSD) of the billion-scale approximate nearest neighbor search challenge at neurips’2021 [3]. tests results show that Manu’s solution improves the recall of the competition baseline by up to 60% at the same query processing throughput. 5 we notice that another work adopts similar designs for SSD-based vector search [27].', 'part_title': '4 feature highlights', 'sub_title': '4.4 hardware optimizations'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'Before introducing the use cases of Manu, we first compare Manu with Milvus, our previous vector database. Milvus adopts an even- tual consistency model and thus does not support the tunable con- sistency of Manu. To show the advantages brought by Manu’s 4we set the bucket size to a few times (e.g., 4 and 8) of 4kb if the size of an individual vector is large. 5for more details about results please refer to [72].', 'part_title': '5 use cases and evaluation', 'sub_title': '4.4 hardware optimizations'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'fine-grained functionality decomposition, we create a mixed work- load. Specifically, we start with an empty collection, insert vectors at a fixed rate (e.g., 2k vectors per second), and measure the latency for search requests over time. Both Manu and Milvus use 6 nodes and are properly configured for good performance. The results in Figure 6 show that the search latency of Milvus is significantly longer than Manu, especially when insertion rates are high (e.g., at 3k and 4k). Milvus has multiple read nodes, but only one write node, to ensure eventual consistency. The write node responsible for data insertion and index construction, and thus write tasks and index building tasks contend for resource. As a result, the index building latency is long and brute force search is used for a large amount of data. In contrast, with dedicated index nodes, Manu finishes index building quickly and thus search latency remains low over the entire period.', 'part_title': '5 use cases and evaluation', 'sub_title': '4.4 hardware optimizations'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'We classify our customers into 5 application domains in Figure 7 and briefly elaborate them as follows.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Recommendation: Platforms for e-commerce [79], music [77], news [55], video [28], and social network [44] record user-content interactions, and use the data to map users and contents to em- bedding vectors with techniques such as ALS [75] and deep learn- ing [50]. Finding contents of interest for a user is conducted by searching content vectors having large similarity scores (typically inner product) with user vector.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Multimedia: Multimedia contents (e.g., images, video and audio) are becoming increasingly popular, and searches for multimedia contents from large corpus are common online. The general prac- tice is to embed both user query and corpus contents into vectors using tools such as CNN [49] and RNN [87]. Searching multimedia contents is conducted by finding vectors similar to the user query.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Language: Automatic questing answering and machine-based dia- logue attract much attention recently with products such as Siri [15] and Xiaoice [21], and searches for text contents is a general need. With models such as Word2Vec [63] and BERT [31], language se- quences are embedded into vectors such that retrieving language contents boils down to finding content vectors that are similar to user query.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Security: Blocking spams and scanning viruses are important for security. The common practice is to map spams and viruses into vectors using hashing [59] or tailored algorithms [39]. After that, suspicious spams and viruses can be checked by finding the most similar candidates in the corpus for further check.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Medicine: Many medical applications search for certain chemical structures and gene sequences for drug discovery or health risk identification. With tools such as GNN [68] and LSTM [84], chemi- cal structures and gene sequences can be embedded into vectors and their search tasks are cast into vector search. Full-fledged vector databases are necessary for the forgoing do- mains as they require much more complex functionality support in addition to vector search. Specifically, as the vector datasets are large and applications have high requirements for throughput, they need distributed computing with multiple nodes for scalability. The vectors are also continuously updated when new user/content comes, user behavior changes or the embedding model is updated. Since most of these applications serve end users, they require high availability and durability. Some of our customers have deployed Manu in their production environment, and they found Manu satis- factory in terms of usability, performance, elasticity, and adaptabil- ity. In what follows, we simulate some typical application scenarios of our customers to demonstrate the advantages of Manu.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.1 overview of use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Due to business security, the names of the customers are anony- mous. For the experiments, we use two datasets widely used for vector search research, i.e., SIFT [5](with 128-dim vectors) and DEEP [2] (with 96-dim vectors), and extract sub-datasets with the re- quired sizes. By default, we use two query nodes, one data node and one index node for Manu. Each worker node is an EC2 m5.4xlarge instance running on Amazon Linux AMI version 5.4.129. For in- dex, we experiment with IVF-FLAT [46] and HNSW [61], which are widely used in practice. When comparing Manu with other systems, we always ensure that the systems use the same resource and are properly configured. Due to time and expense limits, we are only able to compare with some vector databases in a subset of the experiments. We search the top-50 most similar vectors for each query, and ensure that average search recall is above 0.8 if recall is not reported explicitly.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'Figure 9: Search workload, query latency, and number of query nodes used by Manu over time. Different colors indi- cate different number of query nodes are used.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'E-commerce recommendation. Company A is a leading online shopping platform in China that mainly sells clothing and make- ups. They use Manu for recommendation, and products are recom- mended to a user according to their similarity scores with the user embedding vector. They have three main requirements for vector database: (1) high throughput as they need to handle the requests of many concurrent costumers; (2) high quality search results for good recommendation effect; (3) good elasticity for low costs as their search requests have large fluctuations over time (peaks in evening but very low in midnight, very high at promotion events). In Figure 8, we compare the recall-throughput performance of Manu with Elasticsearch (ES for short) [6], Vearch [52], Vald [18], and Vespa [19], four popular open-source vector search systems, when using a single node. Note that the ES we use is the latest 8.0 version with tailored support for vector search instead of ES Plugin. We use Euclidean distance for SIFT and inner product for DEEP to test different similarity functions. Datasets with 10 million (10M) vectors are used as ES takes too much time to build index for larger dataset. As Vald only supports the NGT index [10] and Vespa only supports the HNSW index [61] (both are efficient proximity graphs), we have only a single curve for them in each plot. The results show that Manu consistently outperforms the baselines across different datasets and similarity functions. ES and Vearch achieve signifi- cantly lower query processing throughput than Manu at the same recall. This is because that ES is a disk-based solution and Vearch’s three-layer aggregation procedure (searcher-broker-blender) for search results introduces high overhead. The performances of Vald and Vespa are much better than ES and Vearch but still inferior com- pared with Manu. We conjecture this is because Manu has better implementations with optimizations for CPU cache and SIMD. To test the elasticity of Manu, we use the search traffic of an e-commerce platform over one day period [17], which is plotted as the purple curve in Figure 9. The results show that search workload fluctuates violently over time, and the peak is much higher than the valley. We use SIFT100M as the dataset and Euclidean distance as the similarity function. Manu is configured to reduce query nodes by 0.5x when search latency is shorter than 100ms and add query nodes to 2x when search latency is over 150ms. The colors in Figure 9 indicate the number of query nodes used by Manu, which shows that Manu has good elasticity to adapt to query workload.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'The black line reports the search latency and shows that Manu can keep search latency within the target range via scaling.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'Video deduplication. Company B is a video sharing website in Europe, on which users can upload videos and share with others. They find that there are many duplicate videos that result in high management costs and thus conduct deduplication before archiving the videos. They model a video as a set of its critical frames and encode each frame into a vector. They use vector search to find videos in the corpus that are most similar to a new video and conduct further checking on the shortlisted videos to determine if the new video is a duplicate. They also use vector search to find videos similar to those viewed by users for recommendation. They require vector DBMS to have good scalability with respect to both data volume and computing resource as their corpus grows quickly. In Figure 10 and Figure 11, we test the scalability of Manu when changing the number of query nodes and the size of dataset, respec- tively. The results show that query processing throughput scales almost linearly with the number of query nodes and the reciprocal of dataset size. The observation is consistent for different datasets, indexes and similarity functions. This is because Manu uses seg- ments to distribute search tasks among query nodes. With segment size fixed, each query node handles more segments when data vol- ume increases, and fewer segments when the number of query nodes increases. Note that better scalability w.r.t. data volume can be achieved by configuring Manu to use larger segments when dataset size increases. This is because similarity search indexes usually have sub-linear complexity w.r.t. dataset size.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'Virus scan. Company C is a world leading software security service provider and one of its main service is scanning viruses for smart phones. They have a virus base that continuously collects new Figure 12: The relation between search latency and grace time, legends stand for the time tick interval.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'Figure 13: Index construction time of Manu vs. data volume.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'viruses and develop specialized algorithms to map virus and user APK to vector embedding. To conduct a virus scan, they find viruses in their base that have embedding similar to the query APK and then compare the search results with the APK in more detail. They have two requirements for vector DBMS: (1) short delay for streaming update as new viruses (vectors) are continuously added to their virus base and vector search needs to observe the latest viruses with a short delay; (2) fast index building as they frequently adjust their embedding algorithm to fix problems, which leads to update of the entire dataset and requires to rebuild index. In Figure 12, we show the average delay of search requests for Manu. Recall that grace time (i.e., 𝜏) means that a search request must observe updates that happen time 𝜏before it, and is con- figurable by users. The legends correspond to different time tick interval, with which the loggers write time tick to WAL. The results show that search latency decreases quickly with grace time, and shorter time tick interval results in shorter search latency. This is because with longer grace time, search requests can tolerate longer update delay and are less likely to wait for updates. When the time tick interval reduces, each segment can confirm that all updates have been received more quickly, thus the search requests wait for a shorter time. In Figure 13, we report the index building time of Manu when changing data volume. The results show that index building time scales linearly with data volume. This is because Manu builds index for each segment and larger data volume leads to more segments.', 'part_title': '5 use cases and evaluation', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'Vector search algorithms. Vector search algorithms have a long research history, and most works focus on efficient approximate search on large-scale datasets. Existing algorithms can be roughly classified into four categories, i.e., space partitioning tree (SPT), locality sensitive hashing (LSH), vector quantization (VQ) and prox- imity graph (PG). SPT algorithms divide the space into areas, and use tree structures to quickly narrow down search results to some areas [30, 58, 64, 71, 80]. LSH algorithms design hash functions such that similar vectors are hashed to the same bucket with high prob- ability, and examples include [35, 36, 41, 43, 53, 56, 57, 60, 70, 90]. VQ algorithms compress vectors and accelerate similarity compu- tation by quantizing the vectors using a set of vector codebooks, and well-known VQ algorithms include [23, 34, 42, 45, 91]. PG al- gorithms form a graph by connecting a vector with those most similar to it in the dataset, and conduct vector search by graph walk [33, 61, 73, 89]. Different algorithms have different trade-offs, e.g., LSH is cheap in indexing building but poor in result quality, VQ reduces memory and computation but also harms result quality, PG has high efficiency but requires large memory. Manu supports a comprehensive set of search algorithms such that users can trade off between different factors.', 'part_title': '6 related work', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'Vector databases. Vector data management solutions have gone through two stages of development. Solutions in the first stage are libraries (e.g., Facebook Faiss [46], Microsoft SPTAG [16], HN- SWlib [61] and Annoy [1]) and plugins (e.g., ES plugins [6], Postgres plugins [12]) for vector search. They are insufficient for current ap- plications as full-fledged management functionalities are required, e.g., distributed execution for scalability, online data update, and failure recovery. Two OLAP database systems, AnalyticDB-V [82] and PASE [85] support vector data by adding a table column to store them but lacks optimizations tailored for vector data. The second stage solutions are full-fledged vector databases such as Vearch [52], Vespa [19], Weaviate [20], Vald [18], Qdrant [13], Pinecone [11], and our previous effort Milvus [81]. 6 Vearch uses Faiss as the underlying search engine and adopts a three-layer ag- gregation procedure to conduct distributed search. Similarly, Vespa distributes data over nodes for scalability. A modified version of the HNSW algorithm is used to support online updates for vector data, and Vespa also allows attribute filtering during search and learning- based inference on search results (e.g., for re-ranking). Weaviate adopts a GraphQL interface and allows storing objects (e.g., texts, images), properties, and vectors. Users can directly import vec- tors or customize embedding models to map objects to vectors, and Weaviate can retrieve objects based on vector search results. Vald supports horizontal scalability by partitioning a vector dataset into segments and builds indexes without stopping search services. Qdrant is a single-machine vector search engine with extensive support for attribute filtering. It allows filtering with various data types and query conditions (e.g., string matching, numerical ranges, geo-locations), and uses a tailored optimizer to determine the fil- tering strategy. Note that Vespa, Weaviate and Vald only support proximity graph index. We can observe that these vector databases focus on different functionalities, e.g., learning-based inference, embedding genera- tion, object retrieval, and attribute filtering. Thus, we treat evolv- ability as first class priority when design Manu such that new func- tionalities can be easily introduced. Manu also differs from these 6Pinecone is offered as SaaS and closed source. Thus, we do not know its design details.', 'part_title': '6 related work', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'vector databases in important perspectives. First, the log backbone of Manu provides time semantics and allows tunable consistency. Second, Manu decomposes system functionalities with fine granu- larity and instantiates them as cloud services for performance and failure isolation, and thus is more suitable for cloud deployment. Third, Manu comes with more comprehensive optimizations for usability and performance, e.g., support various indexes, hardware tailored implementations, and GUI tools.', 'part_title': '6 related work', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'Cloud native databases. Many OLAP databases are designed to run on the cloud recently and examples include Redshift [38], Big- Query [62], Snowflake [29] and AnalyticDB [88]. Redshift is a data warehouse system offered as a service on Amazon Web Service and adopts a shared-nothing architecture. It scales by adding or remov- ing EC2 instances, and data is redistributed in the granularity of columns. Snowflake uses a shared-data architecture by delegating data storage to Amazon S3. Compute nodes are stateless and fetch read-only copies of data for tasks, and thus can be easily scaled. For efficiency, high-performance local disk is used to cache hot data. Aurora [78] and PolarDB Serverless [51] are two cloud native OLTP databases. Aurora uses a shared-disk architecture and pro- poses the “log is database" principle by pushing transaction pro- cessing down to the storage engine. It observes that the bottleneck of cloud-based platforms has shifted from computation and storage IO to network IO. Thus, it only persists redo log for transaction processing and commits transaction by processing log according to LSN. PolarDB Serverless adopts a disaggregation architecture, which uses high-speed RDMA network to decouple hardware resources (e.g., compute, memory and storage) as resource pools. Our Manu follows the general design principles of cloud native databases to decouple the system functionalities at fine granularity for high elasticity, fast evolution and failure isolation. However, we also consider the unique design opportunities of vector databases to trade the simple data model and weak consistency requirement for performance, cost and flexibility. Specifically, complex transactions are not supported and the log backbone is utilized to support tunable consistency-performance trade-off. Moreover, vector search, index building and log archiving tasks are further decoupled as their workloads may have significant variations.', 'part_title': '6 related work', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'In this paper, we introduce the designs of Manu as a cloud native vector database. To ensure that Manu suits vector data applications, we set ambitious design goals, which include good evolvability, tun- able consistency, high elasticity, good efficiency, and etc. To meet these design goals, Manu trades the simple data model of vectors and weak consistency requirement of applications for performance, costs and flexibility. Specifically, Manu conducts fine-grained de- coupling of the system functionalities for component-wise scaling and evolution, and uses the log backbone to connect the system components while providing time semantics and simplifying inter- component interaction. We also introduce important features such as high-level API, GUI tool, hardware optimizations, and complex search. We think Manu is still far from perfect and some of our future directions include: • Multi-way search: Many applications jointly search multiple types of contents, e.g., vector and primary key, vector and text. The log system of Manu allows to add search engines for other contents (e.g., primary key and text) as co-processors by sub- scribing to the log stream. We will explore how multiple search engines can interact efficiently and how to flexibly coordinate different search engines to meet application requirements.', 'part_title': '7 conclusions and future directions', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '• Modularized algorithms: We think vector search algorithms can be distilled into independent components, e.g., compression for memory reduction and efficient computation, indexing for limiting computation to a small portion of vectors, and bucketing for grouping similar vectors. Existing vector search algorithms only explore some combinations of techniques for different com- ponents. We will provide a unified framework for vector search such that users can flexibly combine different techniques accord- ing to their desired trade-off between cost and performance.', 'part_title': '7 conclusions and future directions', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '• Hierarchical storage aware index: Current vector search in- dex assumes a single type of storage, e.g., GPU memory, main memory or disk. We will explore indexes that can jointly utilize all devices on the storage hierarchy. For example, most applications have some hot vectors (e.g., popular products in e-commerce) that are frequently accessed by search requests, which can be placed in fast storage. As a query accesses only a portion of the vectors and a node processes many concurrent queries, the storage swap latency may be hidden by pipelining.', 'part_title': '7 conclusions and future directions', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '• Advanced hardware: NVM [67] costs about one-third of DRAM for unit capacity but provides comparable read bandwidth and latency comparable, which makes it a good choice for replacing expensive DRAM when storing large datasets. RDMA [25, 47] significantly reduces the communication latency among nodes, and NVLink [66] directly connects GPUs with much larger band- width than PCIe. By exploiting these fast connections, we will explore indexes and search algorithms that jointly use multiple devices. We are also working with hardware vendors to apply FPGA and MLU for vector search and index building.', 'part_title': '7 conclusions and future directions', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '• Embedding generation toolbox: For better application level- integration, we plan to incorporate a application-oriented toolbox for generating embedding vectors. This toolbox would incorpo- rate model fine-tuning in addition to providing a number of pre-trained models that can be used out-of-the-box, allowing for rapid prototyping.', 'part_title': '7 conclusions and future directions', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'Manu is a multi-year project open sourced by Zilliz. The devel- opment of Manu involves many engineers in its community. In particular, we thank Bingyi Sun, Weida Zhu, Yudong Cai, Yihua Mo, Xi Ge, Yihao Dai, Jiquan Long, Cai Zhang, Congqi Xia, Xuan Yang, Binbin Lv, Xiaoyun Liu, Wenxing Zhu, Yufen Zong, Jie Zeng, Shaoyue Chen, Jing Li, Zizhao Chen, Jialian Ji, Min Tian, Yan Wang and all the other contributors in the community for their contri- butions. We also thank Filip Haltmayer for proofreading the paper and valuable suggestions to improve paper quality.', 'part_title': 'acknowledgments', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[1] 2021. Annoy: Approximate Nearest Neighbors Oh Yeah. https://github.com/ spotify/annoy.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[3] 2021. Billion-Scale Approximate Nearest Neighbor Search Challenge. https://big- ann-benchmarks.com.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[4] 2021. binlog. https://hevodata.com/learn/using-mysql-binlog/. [5] 2021. Datasets for approximate nearest neighbor search. http://corpus-texmex. irisa.fr/.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[6] 2021. ElasticSearch: Open Source, Distributed, RESTful Search Engine. https: //github.com/elastic/elasticsearch.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[10] 2021. NGT. https://github.com/yahoojapan/NGT. [11] 2021. Pinecone. https://www.pinecone.io/. [12] 2021. PostgreSQL: The World’s Most Advanced Open Source Relational Database. https://www.postgresql.org/.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[13] 2021. Qdrant. https://qdrant.tech/. [14] 2021. S3. https://aws.amazon.com/cn/s3/. [15] 2021. siri. https://www.apple.com/siri/. [16] 2021. SPTAG: A library for fast approximate nearest neighbor search. https: //github.com/microsoft/SPTAG.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[17] 2021. User Behavior Data from Taobao for Recommendation. https://tianchi. aliyun.com/dataset/dataDetail?dataId=649.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[18] 2021. Vald. https://github.com/vdaas/vald. [19] 2021. Vespa. https://vespa.ai/. [20] 2021. Weaviate. https://github.com/semi-technologies/weaviate. [21] 2021. Xiaoice. https://en.wikipedia.org/wiki/Xiaoice. [22] Reza Akbarinia, Esther Pacitti, and Patrick Valduriez. 2007. Best Position Algo- rithms for Top-k Queries. In Proceedings of the 33rd International Conference on Very Large Data Bases (Vienna, Austria). VLDB Endowment, 495–506.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[23] Fabien André, Anne-Marie Kermarrec, and Nicolas Le Scouarnec. 2015. Cache Locality is Not Enough: High-Performance Nearest Neighbor Search with Product Quantization Fast Scan. Proc. VLDB Endow. 9, 4, 288–299.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[24] Artem Babenko and Victor S. Lempitsky. 2015. The Inverted Multi-Index. IEEE Trans. Pattern Anal. Mach. Intell. 37, 6 (2015), 1247–1260. https://doi.org/10.1109/ TPAMI.2014.2361319 [25] Wei Cao, Yingqiang Zhang, Xinjun Yang, Feifei Li, Sheng Wang, Qingda Hu, Xun- tao Cheng, Zongzhi Chen, Zhenjun Liu, Jing Fang, et al. 2021. PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers. In Proceedings of the 2021 International Conference on Management of Data. 2477–2489.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[26] Paris Carbone, Asterios Katsifodimos, Stephan Ewen, Volker Markl, Seif Haridi, and Kostas Tzoumas. 2015. Apache flink: Stream and batch processing in a single engine. Bulletin of the IEEE Computer Society Technical Committee on Data Engineering 36, 4 (2015).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[27] Qi Chen, Bing Zhao, Haidong Wang, Mingqin Li, Chuanjie Liu, Zhiyong Zheng, Mao Yang, and Jingdong Wang. 2021. SPANN: Highly-efficient Billion-scale Approximate Nearest Neighborhood Search. Advances in Neural Information Processing Systems 34 (2021).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[28] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems. 191–198.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[29] Benoît Dageville, Thierry Cruanes, Marcin Zukowski, Vadim Antonov, Artin Avanes, Jon Bock, Jonathan Claybaugh, Daniel Engovatov, Martin Hentschel, Jiansheng Huang, Allison W. Lee, Ashish Motivala, Abdul Q. Munir, Steven Pelley, Peter Povinec, Greg Rahn, Spyridon Triantafyllis, and Philipp Unterbrunner. 2016. The Snowflake Elastic Data Warehouse. In Proceedings of the 2016 International Conference on Management of Data, SIGMOD Conference 2016, San Francisco, CA, USA, June 26 - July 01, 2016. ACM, 215–226.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[30] Sanjoy Dasgupta and Yoav Freund. 2008. Random projection trees and low dimensional manifolds. In Proceedings of the fortieth annual ACM symposium on Theory of computing. 537–546.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[31] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Under- standing. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Tech- nologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). Association for Computational Linguistics, 4171–4186. https://doi.org/10.18653/v1/n19-1423 [32] Stefan Falkner, Aaron Klein, and Frank Hutter. 2017. Combining hyperband and bayesian optimization. In NIPS 2017 Bayesian Optimization Workshop (Dec 2017).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[33] Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast approximate nearest neighbor search with the navigating spreading-out graph. Proceedings of the VLDB Endowment 12, 5 (2019), 461–474.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[34] Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun. 2013. Optimized product quantization for approximate nearest neighbor search. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2946–2953.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[35] Aristides Gionis, Piotr Indyk, Rajeev Motwani, et al. 1999. Similarity search in high dimensions via hashing. In Vldb, Vol. 99. 518–529.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[36] Long Gong, Huayi Wang, Mitsunori Ogihara, and Jun Xu. 2020. iDEC: indexable distance estimating codes for approximate nearest neighbor search. Proceedings of the VLDB Endowment 13, 9 (2020).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[37] Ruiqi Guo, Sanjiv Kumar, Krzysztof Choromanski, and David Simcha. 2016. Quan- tization based fast inner product search. In Artificial Intelligence and Statistics. PMLR, 482–490.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[38] Anurag Gupta, Deepak Agarwal, Derek Tan, Jakub Kulesza, Rahul Pathak, Ste- fano Stefani, and Vidhya Srinivasan. 2015. Amazon Redshift and the Case for Simpler Data Warehouses. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data, Melbourne, Victoria, Australia, May 31 - June 4, 2015. ACM, 1917–1923.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[39] Michael Hersovici, Michal Jacovi, Yoelle S Maarek, Dan Pelleg, Menachem Shtal- haim, and Sigalit Ur. 1998. The shark-search algorithm. an application: tailored web site mapping. Computer Networks and ISDN Systems 30, 1-7 (1998), 317–326.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[40] Dongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang, Xiaoyu Ma, Fei Xu, Li Shen, Liu Tang, Yuxing Zhou, Menglong Huang, et al. 2020. TiDB: a Raft-based HTAP database. Proceedings of the VLDB Endowment 13, 12 (2020), 3072–3084.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[41] Piotr Indyk and Rajeev Motwani. 1998. Approximate nearest neighbors: towards removing the curse of dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of computing. 604–613.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[42] Masajiro Iwasaki and Daisuke Miyazaki. 2018. Optimization of indexing based on k-nearest neighbor graph for proximity search in high-dimensional data. arXiv preprint arXiv:1810.07355 (2018).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[43] Omid Jafari, Parth Nagarkar, and Jonathan Montaño. 2020. mmLSH: A Practical and Efficient Technique for Processing Approximate Nearest Neighbor Queries on Multimedia Data. In International Conference on Similarity Search and Applications. Springer, 47–61.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[44] Mohsen Jamali and Martin Ester. 2010. A matrix factorization technique with trust propagation for recommendation in social networks. In Proceedings of the fourth ACM conference on Recommender systems. 135–142.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[45] Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2010. Product quantization for nearest neighbor search. IEEE transactions on pattern analysis and machine intelligence 33, 1 (2010), 117–128.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[46] Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale similarity search with gpus. IEEE Transactions on Big Data (2019).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[47] Anuj Kalia, Michael Kaminsky, and David G Andersen. 2014. Using RDMA efficiently for key-value services. In Proceedings of the 2014 ACM Conference on SIGCOMM. 295–306.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[48] Timothy King. 2019. 80 Percent of Your Data Will Be Unstructured in Five Years. https://solutionsreview.com/data-management/80-percent-of-your-data- will-be-unstructured-in-five-years/.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[49] Yann LeCun, Yoshua Bengio, et al. 1995. Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks 3361, 10 (1995), 1995.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[51] Feifei Li. 2019. Cloud native database systems at Alibaba: Opportunities and Challenges. Proc. VLDB Endow. 12, 12 (2019), 2263–2272.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[52] Jie Li, Haifeng Liu, Chuanghua Gui, Jianyu Chen, Zhenyuan Ni, Ning Wang, and Yuan Chen. 2018. The design and implementation of a real time visual search system on jd e-commerce platform. In Proceedings of the 19th International Middleware Conference Industry. 9–16.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[53] Mingjie Li, Ying Zhang, Yifang Sun, Wei Wang, Ivor W Tsang, and Xuemin Lin. 2020. I/O efficient approximate nearest neighbour search based on learned functions. In 2020 IEEE 36th International Conference on Data Engineering (ICDE). IEEE, 289–300.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[54] Wen Li, Ying Zhang, Yifang Sun, Wei Wang, Mingjie Li, Wenjie Zhang, and Xuemin Lin. 2019. Approximate nearest neighbor search on high dimensional data—experiments, analyses, and improvement. IEEE Transactions on Knowledge and Data Engineering 32, 8 (2019), 1475–1488.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[55] Jiahui Liu, Peter Dolan, and Elin Rønby Pedersen. 2010. Personalized news recommendation based on click behavior. In Proceedings of the 15th international conference on Intelligent user interfaces. 31–40.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[56] Wanqi Liu, Hanchen Wang, Ying Zhang, Wei Wang, and Lu Qin. 2019. I-LSH: I/O efficient c-approximate nearest neighbor search in high-dimensional space. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 1670–1673.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[57] Kejing Lu and Mineichi Kudo. 2020. R2LSH: A Nearest Neighbor Search Scheme Based on Two-dimensional Projected Spaces. In 2020 IEEE 36th International Conference on Data Engineering (ICDE). IEEE, 1045–1056.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[58] Kejing Lu, Hongya Wang, Wei Wang, and Mineichi Kudo. 2020. VHP: approximate nearest neighbor search via virtual hypersphere partitioning. Proceedings of the VLDB Endowment 13, 9 (2020), 1443–1455.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[59] Lailong Luo, Deke Guo, Richard TB Ma, Ori Rottenstreich, and Xueshan Luo. 2018. Optimizing bloom filter: Challenges, solutions, and comparisons. IEEE Communications Surveys & Tutorials 21, 2 (2018), 1912–1949.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[60] Qin Lv, William Josephson, Zhe Wang, Moses Charikar, and Kai Li. 2017. In- telligent probing for locality sensitive hashing: Multi-probe LSH and beyond. (2017).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[61] Yu A Malkov and Dmitry A Yashunin. 2018. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence 42, 4 (2018), 824–836.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[62] Sergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shiv- akumar, Matt Tolton, and Theo Vassilakis. 2010. Dremel: Interactive Analysis of Web-Scale Datasets. Proc. VLDB Endow. 3, 1 (2010), 330–339.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[63] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111–3119.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[64] Marius Muja and David G Lowe. 2014. Scalable nearest neighbor algorithms for high dimensional data. IEEE transactions on pattern analysis and machine intelligence 36, 11 (2014), 2227–2240.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[65] Michael P Papazoglou and Willem-Jan Van Den Heuvel. 2006. Service-oriented design and development methodology. International Journal of Web Engineering and Technology 2, 4 (2006), 412–442.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[66] Carl Pearson, I-Hsin Chung, Zehra Sura, Wen-Mei Hwu, and Jinjun Xiong. 2018. NUMA-aware data-transfer measurements for power/NVLink multi-GPU sys- tems. In International Conference on High Performance Computing. Springer, 448– 454.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[67] Jie Ren, Minjia Zhang, and Dong Li. 2020. Hm-ann: Efficient billion-point nearest neighbor search on heterogeneous memory. Advances in Neural Information Processing Systems 33 (2020).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[68] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE transactions on neural networks 20, 1 (2008), 61–80.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[69] Falk Scholer, Hugh E Williams, John Yiannis, and Justin Zobel. 2002. Compression of inverted indexes for fast query evaluation. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval. 222–229.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[70] Anshumali Shrivastava and Ping Li. 2014. Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS). Advances in neural information processing systems 27 (2014).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[71] Chanop Silpa-Anan and Richard Hartley. 2008. Optimised KD-trees for fast image descriptor matching. In 2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 1–8.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[72] Harsha Vardhan Simhadri, George Williams, Martin Aumüller, Matthijs Douze, Artem Babenko, Dmitry Baranchuk, Qi Chen, Lucas Hosseini, Ravishankar Krishnaswamy, Gopal Srinivasa, et al. 2022. Results of the NeurIPS’21 Chal- lenge on Billion-Scale Approximate Nearest Neighbor Search. arXiv preprint arXiv:2205.03763 (2022).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[73] Suhas Jayaram Subramanya, Fnu Devvrit, Harsha Vardhan Simhadri, Ravishankar Krishnaswamy, and Rohan Kadekodi. 2019. Rand-NSG: Fast Accurate Billion- point Nearest Neighbor Search on a Single Node. In Advances in Neural Informa- tion Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada. 13748– 13758.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[74] Rebecca Taft, Irfan Sharif, Andrei Matei, Nathan VanBenschoten, Jordan Lewis, Tobias Grieger, Kai Niemi, Andy Woods, Anne Birzin, Raphael Poss, et al. 2020. Cockroachdb: The resilient geo-distributed sql database. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data. 1493–1509.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[75] Gábor Takács and Domonkos Tikk. 2012. Alternating least squares for personal- ized ranking. In Proceedings of the sixth ACM conference on Recommender systems. 83–90.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[76] Ashish Thusoo, Joydeep Sen Sarma, Namit Jain, Zheng Shao, Prasad Chakka, Suresh Anthony, Hao Liu, Pete Wyckoff, and Raghotham Murthy. 2009. Hive: a warehousing solution over a map-reduce framework. Proceedings of the VLDB Endowment 2, 2 (2009), 1626–1629.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[77] Aäron Van Den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In Neural Information Processing Systems Conference (NIPS 2013), Vol. 26. Neural Information Processing Systems Founda- tion (NIPS).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[78] Alexandre Verbitski, Anurag Gupta, Debanjan Saha, Murali Brahmadesam, Kamal Gupta, Raman Mittal, Sailesh Krishnamurthy, Sandor Maurice, Tengiz Kharatishvili, and Xiaofeng Bao. 2017. Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases. In Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD Conference 2017, Chicago, IL, USA, May 14-19, 2017. ACM, 1041–1052.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[79] Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 839–848.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[80] Jingdong Wang, Naiyan Wang, You Jia, Jian Li, Gang Zeng, Hongbin Zha, and Xian-Sheng Hua. 2014. Trinary-Projection Trees for Approximate Nearest Neigh- bor Search. IEEE Trans. Pattern Anal. Mach. Intell. 36, 2 (2014), 388–403.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[81] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xi- angyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, et al. 2021. Milvus: A Purpose-Built Vector Data Management System. In Proceedings of the 2021 International Conference on Management of Data. 2614–2627.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[82] Chuangxian Wei, Bin Wu, Sheng Wang, Renjie Lou, Chaoqun Zhan, Feifei Li, and Yuanzhe Cai. 2020. AnalyticDB-V: A Hybrid Analytical Engine Towards Query Fusion for Structured and Unstructured Data. Proc. VLDB Endow. 13, 12 (2020), 3152–3165.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[83] Xiang Wu, Ruiqi Guo, Ananda Theertha Suresh, Sanjiv Kumar, Daniel N Holtmann-Rice, David Simcha, and Felix Yu. 2017. Multiscale quantization for fast similarity search. Advances in Neural Information Processing Systems 30 (2017), 5745–5755.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[84] SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. 2015. Convolutional LSTM network: A machine learning ap- proach for precipitation nowcasting. In Advances in neural information processing systems. 802–810.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[85] Wen Yang, Tao Li, Gai Fang, and Hong Wei. 2020. PASE: PostgreSQL Ultra-High- Dimensional Approximate Nearest Neighbor Search Extension. In Proceedings of the 2020 International Conference on Management of Data, SIGMOD Conference 2020, online conference [Portland, OR, USA], June 14-19, 2020. ACM, 2241–2253.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[86] Matei Zaharia, Mosharaf Chowdhury, Michael J Franklin, Scott Shenker, Ion Stoica, et al. 2010. Spark: Cluster computing with working sets. HotCloud 10, 10-10 (2010), 95.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[87] Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization. arXiv preprint arXiv:1409.2329 (2014).', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[88] Chaoqun Zhan, Maomeng Su, Chuangxian Wei, Xiaoqiang Peng, Liang Lin, Sheng Wang, Zhe Chen, Feifei Li, Yue Pan, Fang Zheng, et al. 2019. Analyticdb: Real-time olap database system at alibaba cloud. Proceedings of the VLDB Endowment 12, 12 (2019), 2059–2070.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[89] Weijie Zhao, Shulong Tan, and Ping Li. 2020. SONG: Approximate Nearest Neigh- bor Search on GPU. In 36th IEEE International Conference on Data Engineering, ICDE 2020, Dallas, TX, USA, April 20-24, 2020. IEEE, 1033–1044.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[90] Bolong Zheng, Zhao Xi, Lianggui Weng, Nguyen Quoc Viet Hung, Hang Liu, and Christian S Jensen. 2020. PM-LSH: A fast and accurate LSH framework for high-dimensional approximate NN search. Proceedings of the VLDB Endowment 13, 5 (2020), 643–655.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'Z6NcVJABCBTRytG2phPo', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 14, 'content': '[91] Wengang Zhou, Yijuan Lu, Houqiang Li, and Qi Tian. 2012. Scalar quantization for large scale image search. In Proceedings of the 20th ACM international conference on Multimedia. 169–178.', 'part_title': 'references', 'sub_title': '5.2 example use cases'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge Abstract—A vector database is used to store high-dimensional data that cannot be characterized by traditional DBMS. Although there are not many articles describing existing or introducing new vector database architectures, the approximate nearest neighbor search problem behind vector databases has been studied for a long time, and considerable related algorithmic articles can be found in the literature. This article attempts to comprehensively review relevant algorithms to provide a general understanding of this booming research area. The basis of our framework categorises these studies by the approach of solving ANNS problem, respectively hash-based, tree-based, graph-based and quantization-based approaches. Then we present an overview of existing challenges for vector databases. Lastly, we sketch how vector databases can be combined with large language models and provide new possibilities.'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Index Terms—Vector database, retrieval, storage, large lan- guage models, approximate nearest neighbour search.'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'I. INTRODUCTION V ECTOR database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of features or attributes. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data. The vectors are usually generated by applying some kind of transformation or embedding function to the raw data, such as text, images, audio, video, and others. The embedding function can be based on various methods, such as machine learning models, word embeddings, feature extraction algorithms. Vector databases have several advantages over traditional databases. Fast and accurate similarity search and retrieval. Vector database can find the most similar or relevant data based on their vector distance or similarity, which is a core functionality for many applications that involve natural language processing, computer vision, recommendation systems, etc. Traditional database can only query data based on exact matches or predefined criteria, which may not capture the semantic or contextual meaning of the data. Support for complex and unstructured data. Vector database can store and search data that have high complexity and granularity, such as text, images, audio, video, etc. These Yikun Han is with the Department of Statistics, University of Michigan, Ann Arbor, Michigan 48109, United States (e-mail:yikunhan@umich.edu). Chunjiang Liu is with Chengdu Library of the Chinese Academy of Sciences, Chengdu 610299, China (e-mail: liucj@clas.ac.cn). Pengfei Wang is with Computer Network Information Center of the Chinese Academy of Sciences, Beijing 100190, China (e-mail: pfwang@cnic.cn). (Corresponding authors: Chunjiang Liu) types of data are usually unstructured and do not fit well into the rigid schema of traditional database. Vector database can transform these data into high-dimensional vectors that can capture their features or attribute. Scalability and performance. Vector database can handle large-scale and real-time data analysis and processing, which are essential for modern data science and AI applications. Vector database can use techniques such as sharding, parti- tioning, caching, replication, etc. to distribute the workload and optimize the resource utilization across multiple machines or clusters. Traditional database may face challenges such as scalability bottlenecks, latency issues, or concurrency conflicts when dealing with big data.'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Sharding is a technique that distributes a vector database across multiple machines or clusters, called shards, based on some criteria, such as a hash function or a key range. Sharding can improve the scalability, availability, and performance of vector database. One way that sharding works in vector database is by using a hash-based sharding method, which assigns vector data to different shards based on the hash value of a key column or a set of columns. For example, users can shard a vector database by applying a hash function to the ID column of the vector data. This way, users can distribute the vector data evenly across the shards and avoid hotspots. Another way that sharding works in vector database is by using a range-based sharding method, which assigns vector data to different shards based on the value ranges of a key column or a set of columns. For example, users can shard a vector database by dividing the ID column of the vector data into different ranges, such as 0-999, 1000-1999, 2000-2999, etc. Each range corresponds to a shard. This way, users can query the vector data more efficiently by specifying the shard name or range.', 'part_title': 'storage', 'sub_title': 'sharding'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Partitioning is a technique that divides a vector database into smaller and manageable pieces, called partitions, based on some criteria, such as geographic location, category, or fre- quency. Partitioning can improve the performance, scalability, and usability of vector database. One way that partitioning works in vector database is by using a range partitioning method, which assigns vector data to different partitions based on their value ranges of a key column or a set of columns. For example, users can partition a vector database by date ranges, such as monthly or quarterly. This way, users can query the vector data more efficiently by specifying the partition name or range. Another way that partitioning works in vector database is by using a list partitioning method, which assigns vector data to different partitions based on their value lists of a key column or a set of columns. For example, users can partition a vector database by color values, such as red, yellow, and blue. Each partition contains vector data that have a given value of the color column. This way, users can query the vector data more easily by specifying the partition name or list.', 'part_title': 'storage', 'sub_title': 'partitioning'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'C. Caching Caching is a technique that stores frequently accessed or recently used data in a fast and accessible memory, such as RAM, to reduce the latency and improve the performance of data retrieval. Caching can be used in vector database to speed up the similarity search and retrieval of vector data. One way that caching works in vector database is by using a least recently used (LRU) policy, which evicts the least recently used vector data from the cache when it is full. This way, the cache can store the most relevant or popular vector data that are likely to be queried again. For example, Redis, a popular in-memory database, uses LRU caching to store vector data and support vector similarity search. Another way that caching works in vector database is by using a partitioned cache, which divides the vector data into different partitions based on some criteria, such as geographic location, category, or frequency. Each partition can have its own cache size and eviction policy, depending on the demand and usage of the vector data. This way, the cache can store the most appropriate vector data for each partition and opti- mize the resource utilization. For example, Esri, a geographic information system (GIS) company, uses partitioned cache to store vector data and support map rendering.', 'part_title': 'storage', 'sub_title': 'partitioning'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'D. Replication Replication is a technique that creates multiple copies of the vector data and stores them on different nodes or clusters. Replication can improve the availability, durability, and performance of vector database. One way that replication works in vector database is by us- ing a leaderless replication method, which does not distinguish between primary and secondary nodes, and allows any node to accept write and read requests. Leaderless replication can avoid single points of failure and improve the scalability and reliability of vector database. However, it may also introduce consistency issues and require coordination mechanisms to resolve conflicts. Another way that replication works in vector database is by using a leader-follower replication method, which designates one node as the leader and the others as the followers, and allows only the leader to accept write requests and propagate them to the followers. Leader-follower replication can ensure strong consistency and simplify the conflict resolution of vec- tor database. However, it may also introduce availability issues and require failover mechanisms to handle leader failures.', 'part_title': 'storage', 'sub_title': 'partitioning'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'Nearest neighbor search (NNS) is the optimization problem of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. For example, users can use NNS to find images that are similar to a given image based on their visual content and style, or documents that are similar to a given document based on their topic and sentiment. Approximate nearest neighbor search (ANNS) is a variation of NNS that allows for some error or approximation in the search results. ANNS can trade off accuracy for speed and space efficiency, which can be useful for large-scale and high- dimensional data. For example, users can use ANNS to find products that are similar to a given product based on their features and ratings, or users that are similar to a given user based on their preferences and behaviors. Observing the current division for NNS and ANNS algo- rithms, the boundary is precisely their design principle, such as how they organize, index, or hash the dataset, how they search or traverse the data structure, and how they measure or estimate the distance between points. NNS algorithms tend to use more exact or deterministic methods, such as partitioning the space into regions by splitting along one dimension (k-d tree) or enclosing groups of points in hyperspheres (ball tree), and visiting only the regions that may contain the nearest neighbor based on some distance bounds or criteria. ANNS algorithms tend to use more probabilistic or heuristic methods, such as mapping similar points to the same or nearby buckets with high probability (locality-sensitive hashing), visiting the regions in order of their distance to the query point and stopping after a fixed number of regions or points (best bin first), or following the edges that lead to closer points in a graph with different levels of coarseness (hierarchical navigable small world). In fact, a data structure or algorithm can support ANNS if it is applicable to NNS. For ease of categorization, it is assigned to the section on Nearest Neighbor Search.', 'part_title': 'search', 'sub_title': 'partitioning'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '1) Brute Force Approach: A brute force algorithm for NNS problem is a very simple and naive algorithm, which scans through all the points in the dataset and computes the distance to the query point, keeping track of the best so far. This algorithm guarantees to find the true nearest neighbor for any query point, but it has a high computational cost. The time complexity of a brute force algorithm for NNS problem is O(n), where n is the size of the dataset. The space complexity is O(1), since no extra space is needed. 2) Tree-Based Approach: Four tree-based methods will be presented here, namely KD-tree, Ball-tree, R-tree, and M-tree. KD-tree [1]. It is a technique for organizing points in a k-dimensional space, where k is usually a very big number. It works by building a binary tree in which every node is a k-dimensional point. Every non-leaf node in the tree acts as a splitting hyperplane that divides the space into two parts, known as half-spaces. The splitting hyperplane is perpendicular to the chosen axis, which is associated with one of the k dimensions. The splitting value is usually the median or the mean of the points along that dimension. The algorithm maintains a priority queue of nodes to visit, sorted by their distance to the query point. At each step, the algorithm pops the node with the smallest distance from the queue, and checks if it is a leaf node or an internal node. If it is a leaf node, the algorithm compares the distance between the query point and the data point stored in the node, and updates the current best distance and nearest neighbor if necessary. If it is an internal node, the algorithm pushes its left and right children to the queue, with their distances computed as follows: dR(q, N) = \x1a 0 if qN.axis ≥N.value (N.value −qN.axis)2 if qN.axis < N.value (1) where q is the query point, N is the internal node, N.axis is the splitting axis of N, and N.value is the splitting value of N. The algorithm repeats this process until the queue is empty or a termination condition is met. The advantage of KD-tree is that it is conceptually simpler and often easier to implement than some of the other tree structures. The performance of KD-tree depends on several factors, such as the dimensionality of the space, the number of points, and the distribution of the points. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of KD-tree, such as dealing with the curse of dimensionality when the dimensionality is high, introducing randomness in the splitting process to improve robustness, or using multiple trees to increase recall. This is a variation of KD-tree named randomized KD-tree, that introduces some randomness in the splitting process, which can improve the performance of KD-tree by reducing its sensitivity to noise and outliers [2]. Ball-tree [3], [4], [5]. It is a technique for finding the nearest neighbors of a given vector in a large collection of vectors. It works by building a ball-tree, which is a binary tree that partitions the data points into balls, i.e. hyperspheres that contain a subset of the points. Each node of the ball- tree defines the smallest ball that contains all the points in its subtree. The algorithm then searches for the closest ball to the query point, and then searches within the closest ball to find the closest point to the query point. To query for the nearest neighbor of a given point, the ball tree algorithm uses a priority queue to store the nodes to be visited, sorted by their distance to the query point. The algorithm starts from the root node and pushes its two children to the queue. Then, it pops the node with the smallest distance from the queue and checks if it is a leaf node or an internal node. If it is a leaf node, it computes the distance between the query point and each data point in the node, and updates the current best distance and nearest neighbor if necessary. If it is an internal node, it pushes its two children to the queue, with their distances computed as follows: where q is the query point, N is the internal node, N.center is the center of the ball associated with N, and N.value is the radius of the ball associated with N. The algorithm repeats this process until the queue is empty or a termination condition is met. The advantage of ball-tree is that it can perform well in high-dimensional spaces, as it can avoid the curse of dimensionality that affects other methods such as KD-tree. The performance of ball-tree depends on several factors, such as the dimensionality of the data, the number of balls per node, and the distance approximation method used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of ball-tree search, such as dealing with noisy and outlier data, choosing a good splitting dimension and value for each node, or using multiple trees to increase recall. R-tree [6]. It is a technique for finding the nearest neighbors of a given vector in a large collection of vectors. It works by building an R-tree, which is a tree data structure that partitions the data points into rectangles, i.e. hyperrectangles that contain a subset of the points. Each node of the R-tree defines the smallest rectangle that contains all the points in its subtree. The algorithm then searches for the closest rectangle to the query point, and then searches within the closest rectangle to find the closest point to the query point. The R-tree algorithm uses the concept of minimum bound- ing rectangle (MBR) to represent the spatial objects in the tree. The MBR of a set of points is the smallest rectangle that contains all the points. The formula for computing the MBR of a set of points P is: where px and py are the x and y coordinates of point p , and × denotes the Cartesian product. The R-tree algorithm also uses two metrics to measure the quality of a node split: area and overlap. The area of a node is the area of its MBR, and the overlap of two nodes is the area of the intersection of their MBRs. The formula for computing the area of a node N is: area(N) = (N.xmax −N.xmin) × (N · ymax −N · ymin) (4) where N.xmin, N.xmax, N.ymin, and N.ymax are the coor- dinates of the MBR of node N. The advantage of R-tree is that it can support spatial queries, such as range queries or nearest neighbor queries, on data points that represent geographical coordinates, rectangles, polygons, or other spatial objects.', 'part_title': 'search', 'sub_title': 'nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'R-tree search performance depends on roughly the same factors as B-tree, and also faces similar challenges as B-tree. M-tree [7]. It is a technique for finding the nearest neigh- bors of a given vector in a large collection of vectors. It works by building an M-tree, which is a tree data structure that partitions the data points into balls, i.e. hyperspheres that contain a subset of the points. Each node of the M-tree defines the smallest ball that contains all the points in its subtree. The algorithm then searches for the closest ball to the query point, and then searches within the closest ball to find the closest point to the query point. The M-tree algorithm uses the concept of covering radius to represent the spatial objects in the tree. The covering radius of a node is the maximum distance from the node’s routing object to any of its children objects. The formula for computing the covering radius of a node N is: where N.object is the routing object of node N, N.child is the set of child nodes of node N, C.object is the routing object of child node C, and d is the distance function. The M-tree algorithm also uses two metrics to measure the quality of a node split: area and overlap. The area of a node is the sum of the areas of its children’s covering balls, and the overlap of two nodes is the sum of the areas of their children’s overlapping balls. The formula for computing the area of a node N is: where π is the mathematical constant, and r(C) is the covering radius of child node C. The advantage of M-tree is that it can support dynamic op- erations, such as inserting or deleting data points, by updating the tree structure accordingly. M-tree search performance depends on roughly the same factors as B-tree, and also faces similar challenges as B-tree.', 'part_title': 'search', 'sub_title': 'nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '1) Hash-Based Approach: Three hash-based methods will be presented here, namely local-sensitive hashing, spectral hashing, and deep hashing. The idea is to reduce the memory footprint and the search time by comparing the binary codes instead of the original vectors [8]. Local-sensitive hashing [9]. It is a technique for finding the approximate nearest neighbors of a given vector in a large collection of vectors. It works by using a hash function to transform the high-dimensional vectors into compact binary codes, and then using a hash table to store and retrieve the codes based on their similarity or distance. The hash function is designed to preserve the locality of the vectors, meaning that similar vectors are more likely to have the same or similar codes than dissimilar vectors. Jafari et al. [10] conduct a survey on local-sensitive hashing. A trace of algorithm description and implementation for locally sensitive hashing can be seen on the home page [11].', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'The LSH algorithm works by using a family of hash functions that use random projections or other techniques which are locality sensitive, meaning that similar vectors are more likely to have the same or similar codes than dissimilar vectors [?], which satisfy the following property: Pr[h(p) = h(q)] = f(d(p, q)) (7) where h is a hash function, p and q are two points, d is a distance function, and f is a similarity function. The similarity function f is a monotonically decreasing function of the distance, such that the closer the points are, the higher the probability of collision. There are different families of hash functions for different distance functions and similarity functions. For example, one of the most common families of hash functions for Euclidean distance and cosine similarity is: where a is a random vector, b is a random scalar, and w is a parameter that controls the size of the hash bucket. The similarity function for this family of hash functions is: f(d(p, q)) = 1 −d(p, q) where d(p, q) is the Euclidean distance between p and q. The advantage of LSH is that it can reduce the memory footprint and the search time by comparing the binary codes instead of the original vectors, also adapt to dynamic data sets, by inserting or deleting codes from the hash table without affecting the existing codes [12]. The performance of LSH depends on several factors, such as the dimensionality of the data, the number of hash functions, the number of bits per code, and the desired accuracy and recall. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of LSH, such as dealing with noisy and outlier data, choosing a good hash function family, or using multiple hash tables to increase recall. It is improved by [13], [14], [15]. Spectral hashing [16]. It is a technique for finding the approximate nearest neighbors of a given vector in a large collection of vectors. It works by using spectral graph theory to generate hash functions that minimize the quantization error and maximize the variance of the binary codes. Spectral hashing can perform well when the data points lie on a low- dimensional manifold embedded in a high-dimensional space. The spectral hashing algorithm works by solving an opti- mization problem that balances two objectives: (1) minimizing the variance of each binary function, which ensures that the data points are evenly distributed among the hypercubes, and (2) maximizing the mutual information between differ- ent binary functions, which ensures that the binary code is informative and discriminative. The optimization problem can be formulated as follows: where yi is the i-th binary function, V ar (yi) is its variance, I (y1, . . . , yn) is the mutual information between all the binary functions, and λ is a trade-off parameter. The advantage of spectral hashing is that it can perform well when the data points lie on a low-dimensional manifold embedded in a high-dimensional space. Spectral hashing search performance depends on roughly the same factors as local-sensitive hashing. There are also some challenges and extensions of spectral hashing, such as dealing with noisy and outlier data, choosing a good graph Laplacian for the data manifold, or using multiple hash functions to increase recall. Deep hashing [17]. It is a technique for finding the approx- imate nearest neighbors of a given vector in a large collection of vectors. It works by using a deep neural network to learn hash functions that transform the high-dimensional vectors into compact binary codes, and then using a hash table to store and retrieve the codes based on their similarity or distance. The hash functions are designed to preserve the semantic information of the vectors, meaning that similar vectors are more likely to have the same or similar codes than dissimilar vectors [18]. Luo et al. [19] conduct a survey on deep hashing. The deep hashing algorithm works by optimizing an objec- tive function that balances two terms: (1) a reconstruction loss that measures the fidelity of the binary codes to the original data points, and (2) a quantization loss that measures the discrepancy between the binary codes and their continuous relaxations. The objective function can be formulated as fol- lows: where xi is the i-th data point, bi is its continuous relax- ation, sgn (bi) is its binary code, W is a weight matrix that maps the binary codes to the data space, and λ is a trade-off parameter. The advantage of deep hashing is that it can leverage the representation learning ability of neural networks to generate more discriminative and robust codes for complex data, such as images, texts, or audios. The performance of deep hashing depends on several fac- tors, such as the architecture of the neural network, the loss function used to train the network, and the number of bits per code. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of deep hashing, such as dealing with noisy and outlier data, choosing a good initialization for the network, or using multiple hash functions to increase recall. 2) Tree-Based Approach: Three tree-based methods will be presented here, namely approximate nearest neighbors oh yeah, best bin first, and k-means tree. The idea is to reduce the search space by following the branches of the tree that are most likely to contain the nearest neighbors of the query point. Approximate Nearest Neighbors Oh Yeah [20]. It is a technique which can perform fast and accurate similarity search and retrieval of high-dimensional vectors. It works by building a forest of binary trees, where each tree splits the vector space into two regions based on a random hyperplane. Each vector is then assigned to a leaf node in each tree based on which side of the hyperplane it falls on. To query a vector, Annoy traverses each tree from the root to the leaf node that contains the vector, and collects all the vectors in the same leaf nodes as candidates. Then, it computes the exact distance or similarity between the query vector and each candidate, and returns the top k nearest neighbors. The formula for finding the median hyperplane between two points p and q is: where w = p −q is the normal vector of the hyperplane, x is any point on the hyperplane, and b = −1 2(w · p + w · q) is the bias term. The formula for assigning a point x to a leaf node in a tree is: where wi and bi are the normal vector and bias term of the i-th split in the tree, and sign is a function that returns 1 if the argument is positive, −1 if negative, and 0 if zero. The point x follows the left or right branch of the tree depending on the sign of this expression, until it reaches a leaf node. The formula for searching for the nearest neighbor of a query point q in the forest is: min x∈C(q) d(q, x) (14) where C(q) is the set of candidate points obtained by traversing each tree in the forest and retrieving all the points in the leaf node that q belongs to, and d is a distance function, such as Euclidean distance or cosine distance. The algorithm uses a priority queue to store the nodes to be visited, sorted by their distance to q. The algorithm also prunes branches that are unlikely to contain the nearest neighbor by using a bound on the distance between q and any point in a node. The advantage of Annoy is that it can uses multiple random projection trees to index the data points, which can increase the recall and robustness of the search, also reduce the memory usage and improve the speed of nearest neighbor search, by creating large read-only file-based data structures that are mapped into memory so that many processes can share the same data. The performance of Annoy depends on several factors, such as the dimensionality of the data, the number of trees built, the number of nearest candidates to search, and the distance approximation method used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of Annoy, such as dealing with noisy and outlier data, choosing a good splitting plane for each node, or using multiple distance metrics to increase recall. Best bin first [21], [22]. It is a technique for finding the approximate nearest neighbors of a given vector in a large collection of vectors. It works by building a kd-tree that partitions the data points into bins, and then searching for the closest bin to the query point. The algorithm then searches within the closest bin to find the closest point to the query point. The best bin first algorithm still follows (1). The advantage of best bin first is that it can reduce the search time and improve the accuracy of nearest neighbor search, by focusing on the most promising bins and avoiding unnecessary comparisons with distant points. The performance of best bin first depends on several factors, such as the dimensionality of the data, the number of bins per node, the number of nearest candidates to search, and the distance approximation method used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of best bin first, such as dealing with noisy and outlier data, choosing a good splitting dimension and value for each node, or using multiple trees to increase recall. K-means tree [23]. It is a technique for clustering high- dimensional data points into a hierarchical structure, where each node represents a cluster of points. It works by applying a k-means clustering algorithm to the data points at each level of the tree, and then creating child nodes for each cluster. The process is repeated recursively until a desired depth or size of the tree is reached. The formula for assigning a point x to a cluster using the k-means algorithm is: where argmin is a function that returns the argument that minimizes the expression, and ∥· ∥2 denotes the Euclidean norm. The formula for assigning a point x to a leaf node in a k-means tree is: where L(x) is the set of leaf nodes that x belongs to, and N .center is the cluster center of node N. The point x belongs to a leaf node if it belongs to all its ancestor nodes in the tree. The formula for searching for the nearest neighbor of a query point q in the k-means tree is: where C(q) is the set of candidate points obtained by traversing each branch of the tree and retrieving all the points in the leaf nodes that q belongs to. The algorithm uses a priority queue to store the nodes to be visited, sorted by their distance to q. The algorithm also prunes branches that are unlikely to contain the nearest neighbor by using a bound on the distance between q and any point in a node. The advantage of K-means tree is that it can perform fast and accurate similarity search and retrieval of data points based on their cluster membership, by following the branches of the tree that are most likely to contain the nearest neighbors of the query point. K-means tree can also support dynamic operations, such as inserting and deleting points, by updating the tree structure accordingly. The performance of K-means tree depends on several fac- tors, such as the dimensionality of the data, the number of clusters per node, and the distance metric used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of K-means tree, such as dealing with noisy and outlier points, choosing a good initialization for the k-means algorithm, or using multiple trees to increase recall. 3) Graph-Based Approach: Two graph-based methods will be presented here, namely navigable small world, and hier- achical navigable small world. Navigable small world [24], [25], [26]. It is a technique that uses a graph structure to store and retrieve high-dimensional vectors based on their similarity or distance. The NSW algo- rithm builds a graph by connecting each vector to its nearest neighbors, as well as some random long-range links that span different regions of the vector space. The idea is that these long-range links create shortcuts that allow for faster and more efficient traversal of the graph, similar to how social networks have small world properties. The NSW algorithm works by using a greedy heuristic to add edges to the graph. The algorithm starts with an empty graph and adds one point at a time. For each point, the algorithm finds its nearest neighbor in the graph using a random walk, and connects it with an edge. Then, the algorithm adds more edges by connecting the point to other points that are closer than its current neighbors. The algorithm repeats this process until all points are added to the graph. The formula for finding the nearest neighbor of a point p in the graph using a random walk is: arg min q∈N(p) d(p, q) (18) where N(p) is the set of neighbors of p in the graph, and d is a distance function, such as Euclidean distance or cosine distance. The algorithm starts from a random point in the graph and moves to its nearest neighbor until it cannot find a closer point. The formula for adding more edges to the graph using a greedy heuristic is: ∀q ∈N(p), ∀r ∈N(q), if d(p, r) < d(p, q), then add edge (p, r) (19) where N(p) and N(q) are the sets of neighbors of p and q in the graph, respectively, and d is a distance function. The algorithm connects p to any point that is closer than its current neighbors. The advantage of the NSW algorithm is that it can handle arbitrary distance metrics, it can adapt to dynamic data sets, and it can achieve high accuracy and recall with low memory consumption. The NSW algorithm also uses a greedy routing strategy, which means that it always moves to the node that is closest to the query vector, until it reaches a local minimum or a predefined number of hops. The performance of the NSW algorithm depends on several factors, such as the dimensionality of the vectors, the number of neighbors per node, the number of long-range links per node, and the number of hops per query. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some extensions and variations of the NSW algorithm, such as hierarchical navigable small world (HNSW), which adds multiple layers of graphs, each with different scales and densities, or navigable small world with pruning (NSWP), which removes redundant links to reduce memory usage and improve search speed. Hierachical navigable small world [27]. It is a state-of- the-art technique for finding the approximate nearest neighbors of a given vector in a large collection of vectors. It works by building a graph structure that connects the vectors based on their similarity or distance, and then using a greedy search strategy to traverse the graph and find the most similar vectors. The HNSW algorithm still follows (18) and (19). The HNSW algorithm also builds a hierarchical structure of the graph by assigning each point to different layers with different probabilities. The higher layers contain fewer points and longer edges, while the lower layers contain more points and shorter edges. The highest layer contains only one point, which is the entry point for the search. The algorithm uses a parameter M to control the maximum number of neighbors for each point in each layer. The formula for assigning a point p to a layer l using a random probability is: where M is the parameter that controls the maximum num- ber of neighbors for each point in each layer. The algorithm assigns p to layer l with probability Pr[p ∈l], and stops when it fails to assign p to any higher layer. The formula for searching for the nearest neighbor of a query point q in the hierarchical graph is: min p∈C(q) d(q, p) (21) where C(q) is the set of candidate points obtained by traversing each layer of the graph from top to bottom and retrieving all the points that are closer than the current best distance. The algorithm uses a priority queue to store the nodes to be visited, sorted by their distance to q. The algorithm also prunes branches that are unlikely to contain the nearest neighbor by using a bound on the distance between q and any point in a node. The advantage of HNSW is that it can achieve better performance than other methods of approximate nearest neigh- bor search, such as tree-based or hash-based techniques. For example, it can handle arbitrary distance metrics, it can adapt to dynamic data sets, and it can achieve high accuracy and recall with low memory consumption. HNSW also uses a hierarchical structure that allows for fast and accurate search, by starting from the highest layer and moving down to the lowest layer, using the closest node as the next hop at each layer. The performance of HNSW depends on several factors, such as the dimensionality of the vectors, the number of layers, the number of neighbors per node, and the number of hops per query. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of HNSW, such as finding the optimal parameters for the graph construction, dealing with noise and outliers, and scaling to very large data sets. Some of the extensions include optimized product quantization (OPQ), which combines HNSW with product quantization to reduce quantization distortions, or product quantization network (PQN), which uses a neural network to learn an end-to-end product quantizer from data. 4) Quantization-Based Approach: Three quantization- based methods will be presented here, namely product quan- tization, optimized product quantization, and online product quantization. Product quantization can reduce the memory footprint and the search time of ANN search, by comparing the codes instead of the original vectors [28]. Product quantization [29]. It is a technique for compress- ing high-dimensional vectors into smaller and more efficient representations. It works by dividing a vector into several sub- vectors, and then applying a clustering algorithm (such as k- means) to each sub-vector to assign it to one of a finite number of possible values (called centroids). The result is a compact code that consists of the indices of the centroids for each sub- vector. The PQ algorithm works by using a vector quantization technique to map each subvector to its nearest centroid in a predefined codebook. The algorithm first splits each vector into m equal-sized subvectors, where m is a parameter that controls the length of the code. Then, for each subvector, the algorithm learns k centroids using the k-means algorithm, where k is a parameter that controls the size of the codebook. Finally, the algorithm assigns each subvector to its nearest centroid and concatenates the centroid indices to form the code. The formula for splitting a vector x into m subvectors is: where xi is the i-th subvector of x, and has dimension d/m, where d is the dimension of x. The formula for finding the centroids of a set of subvectors P using the k-means algorithm is: where ci is the i-th centroid, Si is the set of subvectors assigned to the i -th cluster, and | · | denotes the cardinality of a set. The formula for assigning a subvector x to a centroid using the k-means algorithm is: where argmin is a function that returns the argument that minimizes the expression, and ∥· ∥2 denotes the Euclidean norm. The formula for encoding a vector x using PQ is: where xi is the i-th subvector of x, and qi is the quantization function for the i-th subvector, which returns the index of the nearest centroid in the codebook. The advantage of product quantization is that it is simple and easy to implement, as it only requires a standard clustering algorithm and a simple distance approximation method. The performance of product quantization depends on several factors, such as the dimensionality of the data, the number of sub-vectors, the number of centroids per sub-vector, and the distance approximation method used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of product quantization, such as dealing with noisy and outlier data, optimizing the space decomposition and the codebooks, or adapting to dynamic data sets. Optimized product quantization [30]. It is a variation of product quantization (PQ), which is a technique for compress- ing high-dimensional vectors into smaller and more efficient representations. OPQ works by optimizing the space decompo- sition and the codebooks to minimize quantization distortions. OPQ can improve the performance of PQ by reducing the loss of information and increasing the discriminability of the codes [31]. The advantage of OPQ is that it can achieve higher accuracy and recall than PQ, as it can better preserve the similarity or distance between the original vectors. The formula for applying a random rotation to the data is: where x is the original vector, x′ is the rotated vector, and R is a random orthogonal matrix. The formula for finding the rotation matrix for a subvector using an optimization technique is: where Pi is the set of subvectors assigned to the i-th cluster, Ri is the rotation matrix for the i-th cluster, and ci is the quantization function for the i-th cluster, which returns the nearest centroid in the codebook. The formula for encoding a vector x using OPQ is: where xi is the i-th subvector of x, Ri is the rotation matrix for the i -th subvector, and qi is the quantization function for the i-th subvector, which returns the index of the nearest centroid in the codebook. The performance of OPQ depends on several factors, such as the dimensionality of the data, the number of sub-vectors, the number of centroids per sub-vector, and the distance approximation method used. These factors affect the trade-off between accuracy and efficiency, as well as the complexity and scalability of the algorithm. There are also some challenges and extensions of OPQ, such as dealing with noisy and outlier data, choosing a good optimization algorithm, or combining OPQ with other techniques such as hierarchical navigable small world (HNSW) or product quantization network (PQN). Online product quantization [32]. It is a variation of product quantization (PQ), which is a technique for compress- ing high-dimensional vectors into smaller and more efficient representations. O-PQ works by adapting to dynamic data sets, by updating the quantization codebook and the codes online. O-PQ can handle data streams and incremental data sets, without requiring offline retraining or reindexing. The formula for splitting a vector x into m subvectors is: where xi is the i-th subvector of x, and has dimension d/m, where d is the dimension of x. The formula for initializing the centroids of a set of sub- vectors P using the k-means++ algorithm is: ci = randomly choose a point from P (30) where ci is the i-th centroid, with probability proportional to D(x)2, D(x) is the distance between point x and its closest centroid among {c1, . . . , ci−1}. The formula for assigning a subvector x to a centroid using PQ is: where arg min is a function that returns the argument that minimizes the expression, and ∥· ∥2 denotes the Euclidean norm. The formula for encoding a vector x using PQ is: where xi is the i-th subvector of x, and qi is the quantization function for the i-th subvector, which returns the index of the nearest centroid in the codebook. The O-PQ algorithm also updates the codebooks and codes for each subvector using an online learning technique. The algorithm uses two parameters: α, which controls the learning rate, and β, which controls the forgetting rate. The algorithm updates the codebooks and codes as follows: For each new point x, assign it to its nearest centroid in each subvector using PQ. For each subvector xi, update its centroid cqi(xi) as: For each subvector xi, update its code qi (xi) as: where xi and cj are the mean vectors of all points and centroids in subvector i, respectively. The advantage of O-PQ is that it can deal with changing data distributions and new data points, as it can update the codebooks and the codes in real time. O-PQ search performance depends on roughly the same factors as OPQ, and also faces similar challenges as OPQ.', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'IV. CHALLENGES A. Index Construction and Searching of High-Dimensional Vectors Vector databases require efficient indexing and searching of billions of vectors in hundred or thousand dimensions, which poses a huge computational and storage challenge. Traditional indexing methods, such as B-trees or hash tables, are not suitable for high-dimensional vectors because they suffer from dimensionality catastrophe. Therefore, vector databases need to use specialized techniques such as ANN search, hashing, quantization, or graph-based search to reduce complexity and improve the accuracy of vector similarity search.', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'B. Support for Heterogeneous Vector Data Types Vector databases need to support different types of vector data, such as dense vectors, sparse vectors, binary vectors, and so on. Each type of vector data may have different char- acteristics and requirements, such as dimensionality, sparsity, distribution, similarity metrics, and so on. Therefore, vector databases need to provide a flexible and adaptive indexing system to handle various vector data types and optimize their performance and availability.', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'C. Distributed Parallel Processing Support Vector databases need to be scalable to handle large-scale vector data and queries that may exceed the capacity of a single machine. Therefore, vector databases need to support distributed parallel processing of vector data and queries across multiple computers or clusters. This involves challenges such as data partitioning, load balancing, fault tolerance, and consistency.', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'D. Integration with Mainstream Machine Learning Frame- works Vector databases need to be integrated with popular machine learning frameworks such as TensorFlow, PyTorch, Scikit- learn, etc., which are used to generate and use vector embed- dings. As a result, vector databases need to provide easy-to-use APIs and encapsulated connectors to seamlessly interact with these frameworks and support a variety of data formats and models.', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'V. LARGE LANGUAGE MODELS Typically, large language models (LLMs) refer to Trans- former language models that contain hundreds of billions (or more) of parameters, which are trained on massive text data [33], [34]. On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models and most state-of-the-art systems [35].', 'part_title': 'search', 'sub_title': 'approximate nearest neighbor search'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'Databases and large language models sit at opposite ends of the data science research: Databases are more concerned with storing data efficiently and retrieving it quickly and accurately. Large language models are more concerned with characterizing data and solving semantically related problems. If the database is specified as a vector database, a more ideal workflow can be constructed as follows: Fig. 1. An ideal workflow for combining vector databases and large language models.', 'part_title': 'search', 'sub_title': 'vector database & llm workflow'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': 'At first, the large language model is pre-trained using textual data, which stores knowledge that can be prepared for use in natural language processing tasks. The multimodal data is embedded and stored in a vector database to obtain vector representations. Next, when the user inputs a serialized textual question, the LLM is responsible for providing NLP capabilities, while the algorithms in the vector database are responsible for finding approximate nearest neighbors. Combining the two gives more desirable results than using only LLM and the vector database. If only LLM is used, the results obtained may not be accurate enough, while if only vector databases are used, the results obtained may not be user-friendly.', 'part_title': 'search', 'sub_title': 'vector database & llm workflow'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 9, 'content': '1) Data: By learning from massive amounts of pre-training textual data, LLMs can acquire various emerging capabilties, which are not present in smaller models but are present in larger models, e.g., in-context learning, chain-of-thought, and instruction following [36], [37]. Data plays a crucial role in LLM’s emerging ability, which in turn can unfold at three points: Data scale. This is the amount of data that is used to train the LLMs. According to [38], LLMs can improve their ca- pabilities predictably with increasing data scale, even without targeted innovation. The larger the data scale, the more diverse and representative the data is, which can help the LLMs learn more patterns and relationships in natural language. LLMs can improve their capabilities predictably with increasing data scale, even without targeted innovation. However, data scale also comes with challenges, such as computational cost, environmental impact, and ethical issues. Data quality. This is the accuracy, completeness, consis- tency, and relevance of the data that is used to train the LLMs. The higher the data quality, the more reliable and robust the LLMs are [39], which can help them avoid errors and biases. LLMs can benefit from data quality improvement techniques, such as data filtering, cleaning, augmentation, and balancing. However, data quality also requires careful evaluation and validation, which can be difficult and subjective. Data diversity. This is the variety and richness of the data that is used to train the LLMs. The more diverse the data, the more inclusive and generalizable the LLMs are, which can help them handle different languages, domains, tasks, and users. LLMs can achieve better performance and robustness by using diverse data sources, such as web text, books, news articles, social media posts, and more. However, data diversity also poses challenges, such as data alignment, integration, and protection. As for vector database, the traditional techniques of database such as cleaning, de-duplication and alignment can help LLM to obtain high-quality and large-scale data, and the storage in vector form is also suitable for diverse data. 2) Model: In addition to the data, LLM has benefited from growth in model size. The large number of parameters creates challenges for model training, and storage. Vector databases can help LLM reduce costs and increase efficiency in this regard. Distributed training. DBMS can help model storage in the context of model segmentation and integration. Vector databases can enable distributed training of LLM by allowing multiple workers to access and update the same vector data in parallel [40], [41]. This can speed up the training process and reduce the communication overhead among workers. Model compression. The purpose of this is to reduce the complexity of the model and the number of parameters, reduce model storage and computational resources, and improve the efficiency of model computing. The methods used are typically pruning, quantization, grouped convolution, knowledge distil- lation, neural network compression, low-rank decomposition, and so on. Vector databases can help compress LLM by storing only the most important or representative vectors of the model, instead of the entire model parameters. This can reduce the storage space and memory usage of LLM, as well as the inference latency. Vector storage. Vector databases can optimize the storage of vector data by using specialized data structures, such as in- verted indexes, trees, graphs, or hashing. This can improve the performance and scalability of LLM applications that rely on vector operations, such as semantic search, recommendation, or question answering. 3) Retrieval: Users can use a large language model to generate some text based on a query or a prompt, however, the output may not be diversiform, consistent, or factual. Vector databases can ameliorate these problems on a case-by-case basis, improving the user experience. Cross-modal support. Vector databases can support cross- modal search, which is the ability to search across different types of data, such as text, images, audio, or video. For example, an LLM can use a vector database to find images that are relevant to a text query, or vice versa. This can enhance the user experience and satisfaction by providing more diverse and rich results. Real-time knowledge. Vector databases can enable real- time knowledge search, which is the ability to search for the most up-to-date and accurate information from various sources. For example, an LLM can use a vector database to find the latest news, facts, or opinions about a topic or event. This can improve the user’s awareness and understanding by providing more timely and reliable results. Less hallucination. Vector databases can help reduce hal- lucination, which is the tendency of LLM to generate false or misleading statements. For example, an LLM can use a vector database to verify or correct the data that it generates or uses for search. This can increase the user’s trust and confidence by providing more accurate and consistent results.', 'part_title': 'search', 'sub_title': 'vector database for llm'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'Vector databases and LLMs can work together to enhance each other’s capabilities and create more intelligent and inter- active systems. Here are some potential applications for vector databases on LLMs: 1) Long-term memory: Vector Databases can provide LLMs with long-term memory by storing relevant documents or information in vector form. When a user gives a prompt to an LLM, the Vector Database can quickly retrieve the most similar or related vectors from its index and update the context for the LLM. This way, the LLM can generate more customized and informed responses based on the user’s query and the Vector Database’s content. 2) Semantic search: Vector Databases can enable semantic search for LLMs by allowing users to search for texts based on their meaning rather than keywords. For example, a user can ask an LLM a natural language question and the Vector Database can return the most relevant documents or passages that answer the question. The LLM can then summarize or paraphrase the answer for the user in natural language. 3) Recommendation systems: Vector Databases can power recommendation systems for LLMs by finding similar or com- plementary items based on their vector representations. For example, a user can ask an LLM for a movie recommendation and the Vector Database can suggest movies that have similar plots, genres, actors, or ratings to the user’s preferences. The LLM can then explain why the movies are recommended and provide additional information or reviews.', 'part_title': 'search', 'sub_title': 'potential applications for llm on vector database'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 10, 'content': 'LLMs on vector databases are also very interesting and promising. Here are some potential applications for LLMs on vector databases: 1) Text generation: LLMs can generate natural language texts based on vector inputs from Vector Databases. For example, a user can provide a vector that represents a topic, a sentiment, a style, or a genre, and the LLM can generate a text that matches the vector. This can be useful for creating content such as articles, stories, poems, reviews, captions, summaries, etc. One corresponding study is [42]. 2) Text augmentation: LLMs can augment existing texts with additional information or details from Vector Databases. For example, a user can provide a text that is incomplete, vague, or boring, and the LLM can enrich it with relevant facts, examples, or expressions from Vector Databases. This can be useful for improving the quality and diversity of texts such as essays, reports, emails, blogs, etc. One corresponding study is [43]. 3) Text transformation: LLMs can transform texts from one form to another using VDBs. For example, a user can provide a text that is written in one language, domain, or format, and the LLM can convert it to another language, domain, or format using VDBs. This can be useful for tasks such as translation, paraphrasing, simplification, summarization, etc. One corresponding study is [44].', 'part_title': 'search', 'sub_title': 'potential applications for llm on vector database'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': '1) Definition: Retrieval-based LLM is a language model which retrieves from an external datastore (at least during inference time) [46]. 2) Strength: Retrieval-based LLM is a high-level synergy of LLMs and databases, which has several advantages over LLM only. Memorize long-tail knowledge. Retrieval-based LLM can access external knowledge sources that contain more specific and diverse information than the pre-trained LLM parameters. This allows retrieval-based LLM to answer in-domain queries that cannot be answered by LLM only. Easily updated. Retrieval-based LLM can dynamically retrieve the most relevant and up-to-date documents from the data sources according to the user input. This avoids the need to fine-tune the LLM on a fixed dataset, which can be costly and time-consuming. Better for interpreting and verifying. Retrieval-based LLM can generate texts that cite their sources of information, which allows the user to validate the information and poten- tially change or update the underlying information based on requirements. Retrieval-based LLM can also use fact-checking modules to reduce the risk of hallucinations and errors. Improved privacy guarantees. Retrieval-based LLM can protect the user’s privacy by using encryption and anonymiza- tion techniques to query the data sources. This prevents the data sources from collecting or leaking the user’s personal information or preferences [45]. Retrieval-based LLM can also use differential privacy methods to add noise to the retrieved documents or the generated texts, which can further enhance the privacy protection [47]. Reduce time and money cost. Retrieval-based LLM can save time and money for the user by reducing the computa- tional and storage resources required for running the LLM. This is because retrieval-based LLM can leverage the existing data sources as external memory, rather than storing all the information in the LLM parameters. Retrieval-based LLM can also use caching and indexing techniques to speed up the document retrieval and passage extraction processes.', 'part_title': 'search', 'sub_title': 'retrieval-based llm'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': '3) Inference: Multiple parts of the data flow are involved in the inference session.', 'part_title': 'search', 'sub_title': 'retrieval-based llm'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'Datastore. The data store can be very diverse, it can have only one modality, such as a raw text corpus, or a vector database that integrates data of different modalities, and its treatment of the data determines the specific algorithms for subsequent retrieval. In the case of raw text corpus, which are generally at least a billion to trillion tokens, the dataset itself is unlabeled and unstructured, and can be used as a original knowledge base. Index. When the user enters a query, it can be taken as the input for retrieval, followed by using a specific algorithm to find a small subset of the datastore that is closest to the query, in the case of vector databases the specific algorithms are the NNS and ANNS algorithms mentioned earlier.', 'part_title': 'search', 'sub_title': 'retrieval-based llm'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'Fig. 3. A complex application of vector database + LLM for scientific research.', 'part_title': 'search', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 11, 'content': 'For a workflow that incorporates a large language model and a vector database, it can be understood by splitting it into four levels: the user level, the model level, the AI database level, and the data level, respectively. For a user who has never been exposed to large language modeling, it is possible to enter natural language to describe their problem. For a user who is proficient in large language modeling, a well-designed prompt can be entered.', 'part_title': 'search', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'The LLM next processes the problem to extract the key- words in it, or in the case of open source LLMs, the corre- sponding vector embeddings can be obtained directly. The vector database stores unstructured data and their joint embeddings. The next step is to go to the vector database to find similar nearest neighbors. The ones obtained from the sequences in the big language model are compared with the vector encodings in the vector database, by means of the NNS or ANNS algorithms. And different results are derived through a predefined serialization chain, which plays the role of a search engine. If it is not a generalized question, the results derived need to be further put into the domain model, for example, imagine we are seeking an intelligent scientific assistant, which can be put into the model of AI4S to get professional results. Eventually it can be placed again into the LLM to get coherent generated results. For the data layer located at the bottom, one can choose from a variety of file formats such as PDF, CSV, MD, DOC, PNG, SQL, etc., and its sources can be journals, conferences, textbooks, and so on. Corresponding disciplines can be art, science, engineering, business, medicine, law, and etc.', 'part_title': 'search', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': 'VI. CONCLUSION In this paper, we provide a comprehensive and up-to- date literature review on vector databases. One of our main objective is to reorganize and introduce most of the research so far in a comparative perspective. In a first step, we discuss the storage in detail. We then thoroughly review NNS and ANNS approaches, and then discuss the challenges. Last but not least, we discuss the future about vector database with LLMs.', 'part_title': 'search', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '[1] J. L. Bentley, “Multidimensional binary search trees used for associative searching,” Communications of the ACM, vol. 18, no. 9, p. 509–517, 1975. [2] B. Ghojogh, S. Sharifian, and H. Mohammadzade, “Tree-based optimiza- tion: A meta-algorithm for metaheuristic optimization,” 2018. [3] S. M. Omohundro, Five balltree construction algorithms. Berkeley: International Computer Science Institute, 1989. [4] T. Liu, A. W. Moore, A. Gray, and K. Yang, “New algorithms for effi- cient high-dimensional nonparametric classification,” Journal of machine learning research, vol. 7, no. 6, 2006. [5] S. Kumar and S. Kumar, “Ball*-tree: efficient spatial indexing for constrained nearest-neighbor search in metric spaces,‘’ arXiv preprint arXiv:1511.00628, 2015. [6] A. Guttman, “R-trees: a dynamic index structure for spatial searching,” in Proceedings of the 1984 ACM SIGMOD international conference on Management of data, p. 47–57, 1984. [7] P. Ciaccia, M. Patella, and P. Zezula, “M-tree: An efficient access method for similarity search in metric spaces,” in Vldb, vol. 97, p. 426–435, 1997. [8] D. Cai, “A revisit of hashing algorithms for approximate nearest neighbor search,‘’ arXiv preprint arXiv:1612.07545, 2019. [9] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni, “Locality-sensitive hashing scheme based on p-stable distributions,” in Proceedings of the twentieth annual symposium on Computational geometry, p. 253–262, 2004. [10] O. Jafari, P. Maurya, P. Nagarkar, K. M. Islam, and C. Crushev, “A survey on locality sensitive hashing algorithms and their applications,” 2021. [11] A. Andoni, P. Indyk, et al., “Locality sensitive hashing (lsh) home page.” ˆ1ˆ, 2023. Accessed: 2023-10-18. [12] K. Bob, D. Teschner, T. Kemmer, D. Gomez-Zepeda, S. Tenzer, B. Schmidt, and A. Hildebrandt, “Locality-sensitive hashing enables efficient and scalable signal classification in high-throughput mass spec- trometry raw data,” BMC Bioinformatics, vol. 23, no. 1, p. 287, 2022.', 'part_title': 'references', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 12, 'content': '[13] A. Andoni and P. Indyk, “Near-optimal hashing algorithms for approx- imate nearest neighbor in high dimensions,‘’ in 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06). IEEE, 2006, pp. 459–468. [14] A. Andoni, P. Indyk, T. Laarhoven, I. Peebles, and L. Schmidt, “Beyond locality-sensitive hashing,‘’ arXiv preprint arXiv:1306.1547, 2013. [15] Y.-C. Chen, T.-Y. Chen, Y.-Y. Lin, C.-S. Chen, and Y.-P. Hung, “Optimal data-dependent hashing for approximate near neighbors,‘’ arXiv preprint arXiv:1501.01062, 2015. [16] Y. Weiss, A. Torralba, and R. Fergus, “Spectral hashing,” Advances in neural information processing systems, vol. 21, 2008. [17] H. Liu, R. Wang, S. Shan, and X. Chen, “Deep supervised hashing for fast image retrieval,” in Proceedings of the IEEE conference on computer vision and pattern recognition, p. 2064–2072, 2016. [18] J.-H. Lee and J.-H. Kim, “Deep hashing using proxy loss on remote sensing image retrieval,‘’ Remote Sensing, vol. 13, no. 15, p. 2924, Jul. 2021. [19] X. Luo, H. Wang, D. Wu, C. Chen, M. Deng, J. Huang, and X.-S. Hua, “A survey on deep hashing methods,” 2022. [20] B. E and S. AB., “Annoy (approximate nearest neighbors oh yeah).” [DB/OL]. (2015) [2023-10-17]. 3, 2015. [21] B. J. S and L. D. G., “Shape indexing using approximate nearest- neighbour search in high-dimensional spaces,” in Proceedings of IEEE computer society conference on computer vision and pattern recognition, pp. 1000–1006, 1997. [22] H. Liu, M. Deng, and C. Xiao, “An improved best bin first algorithm for fast image registration,‘’ in Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology, vol. 1, 2011, pp. 355–358. [23] T. P, T. P, and S. M., “K-means tree: an optimal clustering tree for unsupervised learning,” The Journal of Supercomputing, vol. 77, pp. 5239–5266, 2021. [24] P. A, M. Y, L. A, and K. A., “Approximate nearest neighbor search small world approach,” in International Conference on Information and Communication Technologies & Applications, 2011. [25] M. Y, P. A, L. A, and K. A., “Scalable distributed algorithm for approximate nearest neighbor search problem in high dimensional general metric spaces,” in Similarity Search and Applications: 5th International Conference, SISAP 2012, Toronto, ON, Canada, August 9-10, 2012. Proceedings 5, pp. 132–147, 2012. [26] M. Y, P. A, L. A, and K. A., “Approximate nearest neighbor algorithm based on navigable small world graphs,” Information Systems, vol. 45, pp. 61–68, 2014. [27] Y. A. Malkov and D. A. Yashunin, “Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs,” IEEE transactions on pattern analysis and machine intelligence, vol. 42, no. 4, p. 824–836, 2018. [28] Y. Wang, Z. Pan, and R. Li, “A new cell-level search based non- exhaustive approximate nearest neighbor (ann) search algorithm in the framework of product quantization,” IEEE Access, vol. 7, pp. 37059– 37070, 2019. [29] H. Jegou, M. Douze, and C. Schmid, “Product quantization for nearest neighbor search,” IEEE transactions on pattern analysis and machine intelligence, vol. 33, no. 1, p. 117–128, 2010. [30] T. Ge, K. He, Q. Ke, and J. Sun, “Optimized product quantization,” IEEE transactions on pattern analysis and machine intelligence, vol. 36, no. 4, p. 744–755, 2013. [31] L. Li and Q. Hu, “Optimized high order product quantization for approximate nearest neighbors search,” Frontiers of Computer Science, vol. 14, no. 2, pp. 259–272, 2020. [32] D. Xu, I. W. Tsang, Y. Zhang, and J. Yang, “Online product quantiza- tion,” IEEE Transactions on Knowledge and Data Engineering, vol. 30, no. 11, p. 2185–2198, 2018. [33] W. X. Zhao et al., “A survey of large language models,‘’ arXiv preprint arXiv:2303.18223, 2023. [34] M. Shanahan, “Talking about large language models,” 2023. [35] OpenAI, “GPT-4 technical report,‘’ arXiv preprint arXiv:2303.08774, 2023. [36] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, and W. Fedus, “Emergent abilities of large language models,” 2022. [37] X. Yang, “The collision of databases and big language models - recent reflections,‘’ China Computer Federation, Tech. Rep., Jul. 2023. [38] S. R. Bowman, “Eight things to know about large language models,‘’ arXiv preprint arXiv:2304.00612, 2023.', 'part_title': 'references', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aKNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 13, 'content': '[39] A. Mallen et al., “When not to trust language models: Investigating ef- fectiveness of parametric and non-parametric memories,‘’ arXiv preprint arXiv:2212.10511, 2023. [40] X. Nie et al., “FlexMoE: Scaling large-scale sparse pre-trained model training via dynamic device placement,‘’ Proceedings of the ACM on Management of Data, vol. 1, no. 1, pp. 1–19, May 2023. [41] X. Nie et al., “HetuMoE: An efficient trillion-scale mixture-of-expert distributed training system,‘’ arXiv preprint arXiv:2203.14685, 2022. [42] R. Tang, X. Han, X. Jiang, and X. Hu, “Does synthetic data generation of LLMs help clinical text mining¿’ arXiv preprint arXiv:2303.04360, 2023. [43] C. Whitehouse, M. Choudhury, and A. Fikri Aji, “LLM-powered data augmentation for enhanced crosslingual performance,‘’ arXiv preprint arXiv:2305.14288, 2023. [44] S. Chang and E. Fosler-Lussier, “How to prompt LLMs for text-to-SQL: A study in zero-shot, single-domain, and cross-domain settings,‘’ arXiv preprint arXiv:2305.11853, 2023. [45] J. Liu et al., “RETA-LLM: A retrieval-augmented large language model toolkit,‘’ arXiv preprint arXiv:2306.05212, 2023. [46] A. Asai, S. Min, Z. Zhong, and D. Chen, “ACL 2023 tutorial: Retrieval- based language models and applications,‘’ ACL 2023, 2023. [47] Y. Huang et al., “Privacy implications of retrieval-based language models,‘’ arXiv preprint arXiv:2305.14888, 2023.', 'part_title': 'references', 'sub_title': 'synergized example'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'The Universal NFT Vector Database: A Scaleable Vector Database for NFT Similarity Matching Non-Fungible Tokens (NFTs) are a type of digital asset that repre- sents a proof of ownership over a particular digital item such as art, music, or real estate. Due to the non-fungible nature of NFTs, duplicate tokens should not possess the same value. However, with the surge of new blockchains and a massive influx of NFTs being created, a wealth of NFT data is being generated without a method of tracking similarity. This enables people to create almost iden- tical NFTs by changing one pixel or one byte of data. Despite the similarity among NFTs, each NFT is assigned a completely different token ID. To address the NFT duplication issue, we developed a modular, easily-extendable, hardware-agnostic, cloud-centered NFT processing system that represents NFTs as vectors. We established a database containing a vector representation of the NFTs in ac- cordance with the Ethereum Request for Comment 721 (ERC-721) token standards to initiate the process of aggregating NFT data from various blockchains. Finally, we developed an NFT visualization dashboard application with a user-friendly graphical user interface (GUI) to provide non-technical users access to the aggregated NFT data. The Universal NFT Vector Database is an off-chain framework for NFT data aggregation based on similarity, which provides an organized way to query and analyze NFT data that was previously unavailable through on-chain solutions.'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'PVLDB Reference Format: Samrat Sahoo, Nitin Paul, Agam Shah, Andrew Hornback, and Sudheer Chava. The Universal NFT Vector Database: A Scaleable Vector Database for NFT Similarity Matching. PVLDB, 17(1): XXX-XXX, 2023. doi:XX.XX/XXX.XX PVLDB Artifact Availability: The source code, data, and/or other artifacts have been made available at https://github.com/gtfintechlab/Universal-NFT-Vector-Database.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 17, No. 1 ISSN 2150-8097. doi:XX.XX/XXX.XX NFTs are digital assets on the blockchain that are intertwined with cryptography, containing metadata and a distinct hash for identifica- tion [10]. Designed to be cryptographically unique, NFTs originated from the Bitcoin blockchain in 2012 and have become widespread on the Ethereum blockchain [1]. Typically represented with the ERC-721 standard [4], NFTs are ideal for use cases involving col- lectible items, digital key management, concert tickets, and more because they establish uniqueness among digital tokens. To en- force authenticity between NFTs and improve fairness in the NFT ecosystem, especially among image-based NFTs, researchers and blockchain developers are searching for mechanisms to detect and enforce the cryptographic uniqueness enabling blockchain systems and infrastructure to fulfill their purpose [2]. Currently, it is expensive to store raw file data on a blockchain. As a result, NFTs on a blockchain store a reference (i.e., a URL) to the file data, and off-chain storage solutions host the metadata. The NFT is assigned a unique token ID; while the token ID is unique, the off-chain data may not be. With recent blockchain infrastructure development, there is a lack of robust protocols and standards to enforce the authenticity of an NFT. This means that an entity can duplicate the content of the original NFT, change one byte, and create a completely new NFT. As a result, the lack of enforcement technology impedes new digital innovations which rely on NFTs to be unique and not be replicated by another entity, effectively nullifying the original intention of NFT technology. To address the challenges with NFTs, we propose a modular, easily-extendable, hardware-agnostic, cloud-centered NFT database. Such infrastructure helps enable and facilitate the enforcement of token uniqueness. It standardizes the data to a vector data repository which users can easily access through a web interface for research and utility purposes. The vector database determines similarities between NFT feature vectors to conclude the uniqueness of an NFT. First, to develop the NFT vector database, we extract the ERC-721 contracts using the Graph Protocol. After receiving the contract information, we collect the individual NFT data through Alchemy (a blockchain infrastructure provider). From the media URL associated with the NFT data, we aggregate the images, embed them, and place the vectors (each containing a distinct ID) in Pinecone, a vector database provider.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'Figure 1: This figure illustrates the infrastructure of the system we have designed. The upper left illustrates our client and server-side logic and blockchain data collection tools. The bottom represents the task queue processing system which processes NFT collections and NFTs. The upper right shows the infrastructure for our search and visualization APIs.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'Next, we connect the database to an interactive GUI to derive updated metrics and critical information regarding NFT contract data. The web application enables researchers and consumers to interact with the vector database and have a direct access point to the NFT data. Furthermore, this infrastructure for NFT data could be generalized for various applications surrounding the necessity of unique digital assets, such as identity authentication and NFT filtration systems [5]. Through this study, we present a framework for enforcing the uniqueness of NFTs to extract more value from these tokens to be used by researchers and consumers. Additionally, We produce a web application interface with the NFT vector database with a user-friendly graphical user interface to improve access to NFT data and advance future innovations involving NFTs. This study aims to illustrate the system’s extensibility and modular design, enabling developers to replace parts of the system instead of developing new infrastructure for each application area.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '2 DATA COLLECTION AND PROCESSING 2.1 Blockchain Data Querying and Collection Ethereum blockchain data is challenging to query due to the blockchain’s inherent linked-list structure. Traditionally, querying the blockchain for all ERC-721 contracts and tokens would require spinning up an Ethereum RPC node and iterating through every block. Our system, instead, leverages the Graph Protocol, a decentralized querying layer built on top of Ethereum [9], allowing for easy and fast query- ing of subsets of blockchain data (called subgraphs) via a GraphQL API. We utilize an EIP-721 subgraph [7] that monitors all ERC-721 contracts and collects contract addresses through this subgraph. We collect these contract addresses in a paginated manner – processing anywhere from 10 to 100 contracts at a time – to ensure neither the subgraph infrastructure nor our infrastructure is overwhelmed with excessive data input and output operations. We tested two methods to obtain the individual NFT data for each ERC-721 contract. The first method utilized the subgraph used for the contracts to acquire the NFTs and individual details of each NFT. The second method involved integrating the system with Alchemy’s – a Web3 infrastructure provider – NFT infrastructure. Since speed was a priority for us in retrieving as many NFTs as possible, we ran benchmark tests to measure which method would run faster. We discovered that Alchemy’s NFT infrastructure had significant time improvements and scales roughly linearly according to the number of NFTs. The linear scaling is because Alchemy caches NFT media information in a database, allowing almost instant retrieval.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'By utilizing Alchemy’s NFT Infrastructure, we obtain the media URL of an individual NFT. We feed this media URL through a data processing system that obtains the file contents at the URL. Our system conducts no preprocessing steps on the media contents to retain the inherent attributes of the NFT. The image is then directly converted into a 2016x1 dimensional vector via a RegNetY- 080 embedding [6]. The system divides the data into two database pipelines. The first pipeline stores the generated vector in a vector database provider called Pinecone. The second pipeline stores addi- tional information about the NFT, such as chain information, the NFT metadata URL, and NFT standard information in a MongoDB database. The dual database system enables users to obtain NFT details (from the MongoDB database) based on visual aspects of NFTs (using the vector database). Our design differs from tradi- tional methods, which rely solely on querying based on the NFT collection contract ID and token ID.', 'part_title': '1 introduction', 'sub_title': '2.2 data processing'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Raw images have large, arbitrary dimensions when converted to a vector, posing two issues our system attempts to solve. First, large dimensions are storage intensive, with even smaller images requir- ing tens of thousands of elements per vector. By utilizing image embeddings, we can apply dimensionality reduction to the image while retaining the inherent attributes of the NFT. The RegNetY-080 represents the image as a 2016x1 dimensional vector, significantly reducing the amount of space each image takes up in the database. The second problem of arbitrary vector dimensions poses an issue for vector comparison. Current metrics for vector comparison, such as euclidean distance, require consistently sized vectors [3]. However, with different-sized images, it is impossible to compare the images without some standardization. After standardizing the vectors, we were able to add functionality to search for similar NFTs – we chose to use cosine distance as our search metric as cosine distance tends to perform best for higher dimensional embeddings [8]. For the visualization capabilities, we need an effective dimen- sionality reduction technique to reduce the embedding vectors into a two-dimensional surface. To determine which dimensionality re- duction technique is most effective, we run experiments to compare different methods including multidimensional scaling, t-distributed stochastic neighbor embedding, principal component analysis, trun- cated singular value decomposition, and isometric mapping. For this experiment, we define and calculate a metric called the cluster ratio to determine which low-dimensionality reduction technique is most effective – a higher cluster ratio indicates a more effective dimensionality reduction technique. We define effectiveness as the algorithm that maximizes the distance between NFT collections clusters centers while minimizing the distance between the individ- ual NFTs and the NFT collection cluster centers. We define cluster ratio, cluster distance, and collection distance as follows: • Cluster Distance: This is the Euclidean distance between the centers of two clusters of NFTs.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Collection Distance: This is the average Euclidean distance between the individual elements of each NFT cluster and the center of the NFT cluster.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Cluster Ratio: This is the ratio of the distance between two cluster centers and the average distance between the individual elements of each cluster and the respective cluster center of the elements. The cluster ratio is better defined as the ratio of cluster distance to collection distance.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'We used an NFT dataset with 50 NFTs from two different NFT collections. Each NFT collection has NFTs with similar aesthetic attributes. The initial step in determining the best algorithm was creating embeddings for all of the images in the dataset. We then applied the dimensionality reduction technique we were testing and created two clusters on the lower dimensional data using a K-means clustering algorithm. From this, we calculated the cluster distance, collection distance, and cluster ratio. The truncated singu- lar value decomposition had the higher cluster ratio and was the chosen dimensionality reduction technique for the visualization capabilities.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '3 SOFTWARE INFRASTRUCTURE 3.1 Control Panel, Dashboard, and Backend Server Our GUI grants nontechnical users complete access to the system’s capabilities. To create this GUI, we leveraged a standard software engineering model for building applications called the Model-View- Controller (MVC) pattern to ensure organized, secure, and easy access to data: • Model: The model portion of the application primarily en- tails the database schemas, which enable a better organiza- tion of data – we write and enforce using the Mongoose client for MongoDB when inserting data into our database. Ad- ditionally, using a strongly-typed language like TypeScript allows us to declare and enforce types strictly.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• View: The view portion of the application enables users to view current data and perform create, read, update, and delete (CRUD) operations, all abstractedly. In the case of the GUI, users leverage CRUD operations through actions such as viewing analytics, controlling the task queue, and updating analytics.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '• Controller: The system’s controller is a backend server that manages all CRUD operations’ logic. The CRUD operations include actions like retrieving analytics and updating the task queue. Additionally, the controller enables greater security in the application’s admin panel, where users are authenticated via JavaScript Object Notation (JSON) web tokens, allowing them to control the task queue. The controller was written in TypeScript using a full-stack web framework known as Nuxt.js, enabling client-side and server-side under a mono repository structure, greatly simplifying the organization and infrastructure of the project.', 'part_title': '1 introduction', 'sub_title': '2.3 vector operations and dimensionality reduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Converting an image into a vector using image embeddings is com- putationally intensive. As a result, loading this onto an API would cause an overload of requests, requiring vertical scalability (increas- ing computational resources) and resulting in a less robust image processing system. To solve this, we implement a task queue system in which NFT data can be saved and processed on a separate server, allowing horizontal scalability. The flow of this system starts at the admin dashboard, where authenticated users can add NFT collec- tions to the task queue. When the admin adds these collections, the system stores supplementary information regarding the pro- cessed item along with an ID and status in a MongoDB task queue collection. The system sends the ID to a messaging queue. We use Amazon Web Services (AWS) Simple Queue Service (SQS) as the messaging queue. These items are then individually processed on a separate server running a Celery worker service with two different tasks: • Contract Task: The first task is a contract task where the workers will get all the individual NFTs for a certain contract using Alchemy’s NFT infrastructure and add task items into the task queue for each NFT as discussed in section 2.2.', 'part_title': '1 introduction', 'sub_title': '3.2 task queue, workers, and horizontal scalability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• NFT Task: The second task is an NFT task where the work- ers will get the data at the media URLs and convert this to a 2016 dimensional vector via the RegNetY-080 embedding as discussed in section 2.2.', 'part_title': '1 introduction', 'sub_title': '3.2 task queue, workers, and horizontal scalability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'This architecture allows the system to be agnostic to a machine’s physical hardware and focuses on reusability across devices.', 'part_title': '1 introduction', 'sub_title': '3.2 task queue, workers, and horizontal scalability'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'We offer a public search and visualization API to enable users to interact with the vector database. Both APIs also have interactive user interfaces in our web application.', 'part_title': '1 introduction', 'sub_title': '3.3 search and visualization api'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• Search API: The search API will take any base64 encoded image and find the closest NFTs to the image by taking the cosine distance between the source image vector – derived from the RegNetY-080 image embedding – and the vectors in the database. We utilize Pinecone’s vector database search API to search for the appropriate vectors.', 'part_title': '1 introduction', 'sub_title': '3.3 search and visualization api'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• Visualization API: The goal of the visualization API is to apply dimensionality reduction on a set of vectors via a t-distributed stochastic neighbor embedding. The visualiza- tion API will take in a list of vectors and reduce them to two dimensions. Each vector in the newly produced vectors corresponds to a point on a cartesian coordinate system.', 'part_title': '1 introduction', 'sub_title': '3.3 search and visualization api'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'Deploying with a combination of cloud and on-premise servers enables us to scale and process more NFTs per second on dedicated, robust hardware. When deploying the system, the objective was to keep costs low and the processing efficiency high. We had to deploy five systems: the vector database, MongoDB database, task queue, public APIs, and web application. Figure 1 details the deployment infrastructure.', 'part_title': '1 introduction', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• Vector Database: By using the Pinecone vector database, we greatly simplify the architecture by avoiding manually configuring scaling, storage, sharding, and other infrastruc- ture details.', 'part_title': '1 introduction', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• Task Queue: For the task queue processing system, we de- ploy two different systems. The first system was the task queue, which stored the other task IDs. For this, we utilized Amazon Simple Queue Service, which would act as the bro- ker for our Celery worker server. The second is the Celery worker server which is set up as a system service in a Docker container and deployed on an on-premise server where it runs 24/7 and is always waiting to process task queue items.', 'part_title': '1 introduction', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '• Public APIs: For the public APIs, we dockerize and deploy them to Google Cloud Run as serverless functions. We use Firebase hosting to direct HTTP requests to trigger func- tions in our containerized application. Following a serverless architecture, the container horizontally scales up or down depending on API traffic while ensuring that the costs match the usage.', 'part_title': '1 introduction', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'In this study, we designed and developed a framework for enforcing the uniqueness of NFTs using a system with an NFT vector database as its central component to improve the value that users can extract inherently from NFTs. We developed an NFT vector database by extracting contract information and then querying the individual NFT data to find the media URL from which we aggregated the NFT images and placed them accordingly as vectors in the database. We also improved access to NFT data and associated metrics by allowing easy access through an intuitive web application interface where users can search for NFTs in the database and receive similarity scores. Our data access and standardized framework solution for NFT uniqueness based on similarity help make the NFT ecosystem fairer for blockchain developers, consumers, and researchers to leverage its potential for future innovations and research across various applications and fields.', 'part_title': '4 conclusion', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '[1] Yoni Assia, Vitalik Buterin, M LiorhakiLior Hakim, Meni Rosenfeld, Peter Racz, and Rotem Lev. 2015. Colored Coins whitepaper. Technical Report. Colored Coins.', 'part_title': 'references', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '[3] Ivan Dokmanic, Reza Parhizkar, Juri Ranieri, and Martin Vetterli. 2015. Euclidean Distance Matrices: A Short Walk Through Theory, Algorithms and Applications. CoRR abs/1502.07541 (2015). arXiv:1502.07541 http://arxiv.org/abs/1502.07541 [5] Rodolfo Mecozzi, Giuseppe Perrone, Dario Anelli, Nicola Saitto, Elia Paggi, and David Mancini. 2022. Blockchain-related identity and access management challenges: (de)centralized digital identities regulation. In 2022 IEEE Interna- tional Conference on Blockchain (Blockchain). 443–448. https://doi.org/10.1109/ Blockchain55522.2022.00068 [6] Ilija Radosavovic, Raj Prateek Kosaraju, Ross B. Girshick, Kaiming He, and Piotr Dollár. 2020. Designing Network Design Spaces. CoRR abs/2003.13678 (2020). arXiv:2003.13678 https://arxiv.org/abs/2003.13678 [8] Erich Schubert. 2021. A Triangle Inequality for Cosine Similarity. CoRR abs/2107.04071 (2021). arXiv:2107.04071 https://arxiv.org/abs/2107.04071 [9] Yaniv Tal, Brandon Ramirez, and Jannis Pohlmann. 2019. The Graph: A Decen- tralized Query Protocol for Blockchains, 2nd ed. Technical Report. The Graph Foundation.', 'part_title': 'references', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aaNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '[10] Qin Wang, Rujia Li, Qi Wang, and Shiping Chen. 2021. Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and Challenges. CoRR abs/2105.07447 (2021). arXiv:2105.07447 https://arxiv.org/abs/2105.07447', 'part_title': 'references', 'sub_title': '3.4 system deployment'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Feature vectors are now mission-critical for many applications, in- cluding retrieval-based large language models (LLMs). Traditional database management systems are not equipped to deal with the unique characteristics of feature vectors, such as the vague notion of semantic similarity, large size of vectors, expensive similarity comparisons, lack of indexable structure, and difficulty of answering “hybrid” queries that combine structured attributes with feature vec- tors. A number of vector database management systems (VDBMSs) have been developed to address these challenges, combining novel techniques for query processing, storage and indexing, and query optimization and execution and culminating in a spectrum of perfor- mance and accuracy characteristics and capabilities. In this tutorial, we review the existing vector database management techniques and systems. For query processing, we review similarity score design and selection, vector query types, and vector query interfaces. For storage and indexing, we review various indexes and discuss com- pression as well as disk-resident indexes. For query optimization and execution, we review hybrid query processing, hardware ac- celeration, and distibuted search. We then review existing systems, search engines and libraries, and benchmarks. Finally, we present research challenges and open problems.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'Vector Database, Vector Similarity Search, Dense Retrieval, 𝑘-NN ACM Reference Format: James Jie Pan, Jianguo Wang, and Guoliang Li. 2024. Vector Database Management Techniques and Systems. In Companion of the 2024 Inter- national Conference on Management of Data (SIGMOD-Companion ’24), June 9–15, 2024, Santiago, AA, Chile. ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3626246.3654691 High-dimensional feature vectors are now used in a variety of dense retrieval search applications, including retrieval-based large language models (LLMs) [28, 31, 51], e-commerce [54], recommen- dation [82], document retrieval [76], and so on [45, 51, 79, 84]. These applications may involve billions of vectors and require millisecond This work is licensed under a Creative Commons Attribution International 4.0 License.', 'part_title': 'abstract'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile © 2024 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0422-2/24/06. https://doi.org/10.1145/3626246.3654691 Figure 1: Overview of a VDBMS (Vector Database Manage- ment System).', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 1, 'content': 'query latencies, all while needing to scale to increasing workloads without sacrificing performance or response quality. But existing traditional database management systems, includ- ing NoSQL and relational databases, are not designed for these datasets and workloads. First, vector queries rely on the concept of similarity which can be vague for different applications, requiring a different query specification. Second, similarity computation is more expensive than other types of comparisons seen in relational predicates, requiring efficient techniques. Third, processing a vector query often requires retrieving full vectors from the collection. But each vector may be large, possibly spanning multiple disk pages, and the cost of retrieval is more expensive compared to simple attributes while also straining memory. Fourth, vector collections lack obvious properties that can be used for indexing, such as being sortable or ordinal, preventing the use of traditional techniques. Fi- nally, “hybrid” queries require accessing both attributes and vectors together, but it remains unclear how to do this efficiently. These challenges have led to the rise of vector database man- agement systems (VDBMSs) specially adapted for these applica- tions, and there are now over 20 commercial VDBMSs developed within the past five years. A typical VDBMS is composed of a query processor and a storage manager (Figure 1). For the query proces- sor, VDBMSs introduce new approaches to query interfaces, query types such as 𝑘-nearest-neighbor search, hybrid, and multi-vector queries, and data operators such as similarity projection and hybrid index scan. New techniques have also been proposed for query SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile James Jie Pan, Jianguo Wang, and Guoliang Li optimization and execution, including plan enumeration and se- lection for hybrid query plans and hardware accelerated search. For the storage manager, several techniques for large-scale vector indexing and vector storage are now available, including hashing and quantization-based approaches like PQ [1] and IVFADC [49] that tend to be easy to update; tree-based indexes like FLANN [62] and ANNOY [2] that tend to support logarithmic search complex- ity; and graph-based indexes like HNSW [58] and others that are efficient in practice but with less theoretical understanding. To- gether, these techniques culminate into a variety of native systems, extended systems, and search engines and libraries over a spectrum of performance and accuracy characteristics and capabilities. In this tutorial, we review techniques and systems for vector data management along with benchmarks, followed by remaining challenges and open problems. Tutorial Overview. This tutorial contains three parts and the intended length is 1.5 hours. The first part discusses specific tech- niques and will last 50 minutes. (1) Query Processing (10 min.). Query processing begins with a search specification that defines the search parameters. These include considerations for similarity score design, score selection and the curse of dimensionality [22, 30, 61], the query type such as basic, multi-vector, and hybrid queries [79, 84], and the query interface. (2) Storage and Indexing (30 min.). Vector indexes tend to rely on novel partitioning techniques such as randomization, learned par- titioning, and navigable partitioning. The performance, accuracy, and storage characteristics of an index depend on the techniques used and the index structure. We classify indexes into table, tree, or graph-based, and then describe the techniques for each index type. To deal with large size, we also discuss vector compression using quantization [49, 59] and disk-resident indexes [32, 74]. (3) Optimization and Execution (10 min.). For processing hybrid queries, several plan enumeration and plan selection techniques have been proposed, including rule-based [3, 4] and cost-based selection [79, 84], and which also introduce new hybrid operators including block-first scan [43, 79, 84, 87] and visit-first scan [43, 87]. Several techniques also speed up vector search via hardware acceleration using SIMD [26, 27], GPUs [50], and distributed search. To address slow index updates, some VDBMSs also rely on out-of- place updates. The second part discusses vector database management systems and will last 30 minutes. (1) Native Systems (10 min). Native systems such as Pinecone [5], Miluvs [6, 79], and Manu [45] aim at high performance vector search applications by offering a narrower range of capabilities. (2) Extended Systems (10 min). For applications that require more so- phisticated capabilities, several extended systems such as AnalyticDB- V [84], PASE [90], pgvector [7], and Vespa [4] have been developed based on NoSQL or relational systems. (3) Search Engines and Libraries (5 min). Several search engines such as Apache Lucene [8] and Elasticsearch [9] now also incorporate vector search capability via integrated vector indexes. Several li- braries are also available such as Meta Faiss [1] that provide vector search functionality.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': '(4) Benchmarks (5 min). We describe two notable benchmarks that evaluate a wide variety of search algorithms and systems over a range of workloads [29, 91]. The final part discusses challenges and open problems (10 min.). We describe several fundamental challenges, including how to per- form similarity score selection, design more efficient hybrid oper- ators and indexes, and estimate the cost of hybrid plans. We also describe future applications, including index-supported incremental search, multi-vector search, and enhancing security and privacy. Target Audience. This tutorial is intended for database researchers interested in understanding and advancing the state-of-art tech- niques for large-scale vector database management and modern applications beyond similarity search. This tutorial may also ben- efit industry practitioners interested in learning about the latest commercial systems. There are no prerequisites beyond a basic understanding of database concepts. Related Tutorials. A recent tutorial [28] discusses how vector search can be used for retrieval-based LLMs. There are also separate tutorials on similarity search techniques [37, 67, 68]. Our tutorial aims to complement these tutorials by focusing on vector database management systems as a whole, and most of this tutorial has not been covered elsewhere. Specifically, most of the overlap is confined to Section 2.2, and the extent is not large. In [37], a broad taxonomy of search techniques is given, along with representative examples. Similarly in [67, 68], an overview of various exact and approximate search techniques is given. Some of the material in Section 2.2, mainly locality-sensitive hashing, learning-to-hash, ANNOY, and HNSW, overlaps with these past tutorials. But Section 2.2 also discusses key indexing trends in VDBMSs that have not been discussed in past tutorials, including disk-based indexes, quantization-based compression approaches for handling large vector collections, and the diversity of graph-based indexes. Aside from this section, all other sections in this tutorial have not been covered elsewhere as they pertain to the VDBMS as a whole, including query processing, hybrid operators, plan enumeration, and plan selection, and a survey of existing VDBMSs.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 2, 'content': 'Similarity Scores. Dense retrieval works based on similarity. A similarity score can be used to quantify the degree of similarity be- tween two feature vectors. While many scores have been proposed, different scores may lead to different query results, and so how to perform score selection is an important problem for VDBMSs, in addition to score design. (1) Score Design. A similarity score is designed to accurately capture similarity relationships between feature vectors. Existing similarity scores can be classified as basic scores, aggregate scores, and learned scores. Basic scores are derived directly from the vector space and include Hamming distance, inner product, cosine angle, Minkowski distance, and Mahalanobis distance. For certain workloads involv- ing multiple query or feature vectors per entity, aggregate scores such as mean, weighted sum, and others [79] combine multiple scores into a single scalar score that can be more easily compared.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'Vector Database Management Techniques and Systems SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile It may also be possible to improve query results by learning a suit- able score directly over the vector space. This is the goal of metric learning, and several techniques have been proposed [21, 60, 91]. (2) Score Selection. Score selection aims to select the most appro- priate score for a particular application. While many scores are known, automatic score selection remains challenging. We mention one attempt to dynamically adjust the score based on the query [82]. Score selection is also related to query semantics, as certain query entities such as text strings may still be ambiguous and need to be resolved before a suitable score can be selected [75]. Finally, the curse of dimensionality limits the usefulness of certain distance- based scores, requiring other scores to compensate [22, 30, 61]. Query Types and Basic Operators. Data manipulation queries aim to alter the vector collection. As each vector is derived from an embedding model, it is possible to integrate the model within the VDBMS. A VDBMS also must handle vector search queries. Basic search queries include 𝑘-nearest neighbor (𝑘-NN) and approximate nearest neighbor (ANN) queries, and query variants include predi- cated, batched, and multi-vector queries. To answer these queries, a VDBMS compares the similarity between the query vector and a number of candidate vectors using similarity projection. The quality of a result set is measured using precision and recall. (1) Data Manipulation. The embedding model can live inside or out- side the VDBMS. Under direct manipulation, users directly modify the feature vectors, and the user is responsible for the embedding model [7, 90]. Under indirect manipulation, the collection appears as a collection of entities, not vectors, and users manipulate the entities [5, 10]. The VDBMS is responsible for the embedding model. (2) Basic Search Queries. In a (𝑐,𝑘)-search query, the goal is to retrieve 𝑘vectors that are most similar to the query vector, and where no retrieved vector has a similarity score that is a factor of 𝑐worse than the best non-zero score. In a range query, a similarity threshold is given, and the goal is to retrieve all vectors with similarity scores within the threshold. Some particular cases of (𝑐,𝑘)-search queries have been studied, notably 𝑐= 0,𝑘> 1 corresponding to the 𝑘-NN query and 𝑐> 0,𝑘> 1 corresponding to the ANN query. These queries have been individually studied for many decades, leading to a variety of techniques and theoretical results [24, 48, 70]. (3) Query Variants. Most VDBMSs support predicated or “hybrid” queries, and some also support batched and multi-vector queries for applications such as e-commerce, facial recognition, and text retrieval [11, 79, 84]. In a hybrid query, vectors in the collection are associated to structured attributes regarding the represented entity, and each vector in the search result set must also satisfy boolean predicates over the corresponding attributes [84]. For batched queries, a number of search queries are given at once, and the VDBMS must answer all the queries in the batch. Several techniques have been proposed to exploit commonalities between the queries in order to speed up processing the batch [50, 79]. Fi- nally in a multi-vector query, multiple feature vectors are used to represent either the query, each entity, or both, and these can be supported via aggregate scores [79]. Multi-vector queries support several additional sub-variants.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': '(4) Basic Operators. Similarity projection can be used to answer vector search queries by projecting each vector in the collection onto its similarity score. Query Interfaces. Some VDBMSs aim to support only a small num- ber of query types and simple APIs are sufficient. Other VDBMSs aim to support a wide range of query types and may rely on SQL extensions.', 'part_title': '1 introduction'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 3, 'content': 'An index can be used to speed up search queries, but vectors cannot be indexed like structured attributes as they lack a natural sort or- der and categories that are used in typical attribute indexes such as B-tree. As a result, vector indexes rely on techniques including ran- domization, learned partitioning, and navigable partitioning in order to partition the collection so that it can be more easily explored. To address the large size of vectors, disk-resident indexes have also been proposed, in addition to techniques based on a compression technique called quantization. A single index may combine several of these techniques, but the performance of an index also depends on its structure that can be table-based, tree-based, or graph-based. In this section, we describe several vector indexes that are used in existing VDBMSs, starting from table-based indexes. Table-Based Indexes. A table-based index partitions the vector collection into buckets, and each bucket can be retrieved by looking up a key like the rows in a hash table. In general, table-based indexes are easy to maintain but search performance may be worse than other indexes at same recall if buckets are very large. Large buckets can improve recall but are harder to scan while small buckets may suffer from low recall but are easier to scan. Existing techniques, including locality sensitive hashing (LSH) and learning to hash (L2H), tend to rely on randomization and learned partitioning to improve performance at high recall. Furthermore, quantization is a compres- sion technique that relies mostly on learning compression codes in order to reduce storage costs. (1) Locality Sensitive Hashing (LSH). Locality sensitive hashing relies on random hash functions to bucket vectors. The basic idea is to hash each vector into each of 𝐿tables, with each hash function a concatenation of 𝐾number of hash functions that belong to a “hash family”. To answer a query, the query vector is hashed to each of the tables, and collisions are kept as candidates. The hash family, along with the tunable parameters 𝐿and 𝐾, can be designed to give error guarantees for ANN. Many hash families are known with varying performance and accuracy characteristics, including random hyperplanes in E2LSH [35], binary projections in IndexLSH [1], and overlapping spheres in FALCONN [23, 25]. (2) Learning to Hash (L2H). Learning to hash aims to use machine learning techniques to directly learn a hash function that can bucket similar vectors together. One technique is 𝑘-means clustering in SPANN, where each vector is bucketed along with other members of the same cluster [32]. The SPANN index also introduces several techniques for disk-resident collections such as overlapping buckets to reduce I/O retrievals. Other techniques include spectral hashing [85] and techniques based on neural networks [71]. While these techniques may produce high quality partitionings, they are data dependent and cannot easily handle out-of-distribution updates. A survey of techniques can be found in [81].', 'part_title': '1 introduction', 'sub_title': '2.2 indexing'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile James Jie Pan, Jianguo Wang, and Guoliang Li (3) Quantization. Quantization aims to map each vector onto a smaller discrete subset of compression codes [44]. For example, the SQ index works by mapping each vector onto a bit-compressed representation, where every 64-bit dimension is reduced to 32 bits [1], and the IVFSQ index first buckets the vectors into a few𝑘-means clusters, and then stores the bit-compressed vectors in each bucket. The 𝑘-means centroids can also be directly used as compression codes [42, 56], but this may require large 𝑘for large collections. Product quantization splits the original space into multiple sub- spaces, each of which can support more efficient 𝑘-means clustering compared to the original space [49]. The PQ index directly maps each vector onto its product quantization code [1]. The IVFADC index first buckets the vectors into a few 𝑘-means clusters, and then stores the product quantized codes in each of the buckets. Other techniques aim to reduce the compression error and include Cartesian 𝑘-means [64], optimized PQ (OPQ) [41], hierarchical quantizers [89], and the score-aware ScaNN anisotropic quantizer 1 [46]. A survey of quantization techniques is available at [59]. Tree-based indexes. A tree-based index recursively partitions the vectors to yield a search tree, in general offering logarithmic search. One of the fundamental indexes is 𝑘-d tree, which performs partitioning splits deterministically and has well-understood prop- erties [33, 69]. More recent techinques rely on randomization to determine splits or for other purposes, as deterministic trees cannot easily adapt to the intrinsic dataset dimensionality. For example, a principal component tree first finds the principal components of the dataset, and then splits along the principal axes. The PKD-tree splits by rotating through the principal axes [72], while FLANN splits along random principal dimensions [62]. To avoid the expensive pre-processing step for finding the principal components incurred by these indexes, random projection trees adopt random splits. The RPTree uses random splitting planes along with random splitting thresholds [33, 34]. To improve recall, a forest of trees can be used, similar to the multiple hash tables used in LSH. The ANNOY index is similar to RPTree but selects the splitting threshold based on random medians [2]. Graph-based indexes. A graph can be overlayed on top of the vectors so that a node resides at each vector location in the vector space, inducing distances between the nodes. The nodes correspond- ing to similar vectors are then connected with edges that can be weighted by similarity. These edges, along with the distance metric, guide vector search through the graph. The edge selection prob- lem that determines which edges to include in the graph has been extensively studied, leading to distinct graph categories. Typically edges are selected in order to yield high performance search, but as graphs are highly data dependent, they tend to be hard to update. In a 𝑘-nearest neighbor graph (KNNG), each vector is connected to its 𝑘most similar vectors. This allows 𝑘-NN queries to be answered exactly in 𝑂(1) time if the query vector is a member of the vector collection. In a monotonic search network (MSN) and small world graph (SWG), the aim is to select edges that make the graph easily navigable. All graph types may make use of randomized, learned, and navigable partitioning techniques during graph construction.', 'part_title': '1 introduction', 'sub_title': '2.2 indexing'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': '(1) 𝑘-Nearest Neighbor Graphs (KNNGs). The brute-force approach for constructing a KNNG requires 𝑂(𝑁2) time, and unfortunately this appears to be a fundamental limit [86] despite some empirical results [65, 77]. Other techniques aim to approximate a KNNG via iterative refinement. For example, KGraph (NN-Descent) begins with a random KNNG and refines it by examining the second- order neighbors of each node in the graph [36]. To improve recall, EFANNA2 begins with a KNNG constructed using a forest of ran- domized 𝑘-d trees. In [78], a similar approach is taken but using trees that split on random hyerplanes. (2) Monotonic Search Networks (MSNs). An MSN guarantees that a monotonic search path exists for every pair of nodes in the graph, allowing for a simple best-first vector search procedure. But similar to KNNGs, MSNs are also difficult to construct [38, 63]. Recent techniques use search trials that repeatedly probe the quality of the graph as edges are added. During a search trial, a best-first search is conducted on the given source and target nodes. If no monotonic search path can be found, then edges are added until such a path exists. An initial graph such as a random graph [74] or approximate KNNG [40] may be used to initialize the MSN to reduce the number of trials. Some indexes such as FANNG [47] perform a large number of search trials over random node pairs, while others such as NSG [40] and Vamana [74] designates a “navigating node” as the source for all trials and selects random targets instead in order to speed up construction. In [74], a disk-resident version of Vamana (DiskANN) is also introduced. (3) Small World Graphs (SWGs). A “small-world” graph is one where the characteristic path length scales logarithmically with the num- ber of nodes [83], and a “navigable” graph is one where the number of nodes visited by best-first search grows in 𝑂(log 𝑁) [52]. These properties combine to support efficient search. In [57], a naviga- ble SWG (NSW) is constructed by inserting nodes one at a time into the graph and connecting each one to its 𝑘nearest neighbors that are already in the graph. In [58], a hierarchical NSW (HNSW) graph is constructed by assigning each node to a random maximum “layer”, chosen from an exponentially decaying distribution, and then adding it to each of the underlying layers while connecting it to its𝑘nearest neighbors in each layer to avoid the degree explosion problem of a flat graph.', 'part_title': '1 introduction', 'sub_title': '2.2 indexing'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 4, 'content': 'For predicated queries, plan enumeration and selection may depend on hybrid operators. We introduce these first before discussing enumeration, selection, and query execution. Hybrid Operators. A hybrid operator works by combining vector index scan with attribute search, and there are generally two ap- proaches. In block-first scan, parts of the vector index are prevented from exploration (“blocked”) based on their associated attribute values, and then the index scan proceeds as normal over the blocked index. The main consideration is how to efficiently perform the blocking. In visit-first scan, the scan operator itself is modified so that it takes into consideration the attribute values on the visited vectors during index traversal. The main consideration is how to design the operator so that search is efficient.', 'part_title': '1 introduction', 'sub_title': '2.3 query optimization and execution'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'Vector Database Management Techniques and Systems SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile (1) Block-First Scan. For block-first scan, some techniques perform online blocking, where the index is blocked at query time. This allows it to be more flexible to different queries but adds query latency overhead. To reduce the overhead, [6, 79, 84] first construct a bitmask using traditional attribute filtering techniques. This bit- mask is then used during index scan to quickly determine if a vector is blocked. Other techniques perform offline blocking, where the index is blocked beforehand. In [6, 79], the vector collection is pre- partitioned along attributes so that at query time, only the relevant partition needs to be searched. In [3, 43, 87], online blocking can cause a graph-based index to become disconnected, complicating the search procedure. Thus, these techniques construct the graph in a way that can prevent disconnections from occurring by con- sidering attribute values during edge selection. (2) Visit-First Scan. For visit-first scan, if the predicate is highly selective, then the scan may backtrack in order to fill the result set. To avoid backtracking, several techniques infuse the best-first search operator for a graph-based index with attribute information so that the scan prefers nodes that satisfy the predicate [43, 87]. Plan Enumeration. There may be multiple query plans for any given query. For example for non-predicated queries, a VDBMS may support multiple search indexes, and each can potentially be used to answer the query. For predicated queries, there are three broad approaches. The predicate can be applied first, for example via block-first scan, known as “pre-filtering”; applied onto the result set after the search, known as “post-filtering”; or applied while the search is being conducted, for example via visit-first scan, known as “single-stage filtering”. To enumerate all the possible plans, a VDBMS may predefine all the plans for every supported query type, or it may automatically enumerate the plans. (1) Predefined. Some VDBMSs predefine a single plan for each query type, removing the overhead of plan selection. This is useful for workloads with specific needs. For example for e-commerce, Vearch [12, 54] executes all predicated search queries using post-filtering. Post-filtering risks returning fewer than 𝑘results for a (𝑐,𝑘)-search query, but for e-commerce, this is acceptable. Other VDBMSs such as Weaviate [13] execute all predicated search queries using pre- filtering. Still others such as Euclid [14] only support a single search index at a time, and all search queries are executed using the index. There are also some VDBMSs that predefine multiple plans for different queries. For example, AnalyticDB-V [84] supports four different plans for predicated queries based on index availability, and then a cost-based optimizer is used to select the plan. (2) Automatic. Some VDBMSs that are based on relational systems, such as pgvector [7] and PASE [90], take advantage of the under- yling relational optimizer to automatically perform plan enumer- ation. This is achieved by extending the relational language with vector search operators, including index scan operators. Plan Selection. Plan selection aims to select the optimal query plan, usually the minimum latency plan. This is achieved using rule-based or cost-based selection. (1) Rule Based. For VDBMSs that only support a small number of plans, simple rules can be sufficient for plan selection. For exam- ple, Qdrant [3] and Vespa [4] use predicate selectivity estimates as a heuristic for deciding whether to perform pre-filtering, post- filtering, or single-stage brute-force scan. (2) Cost Based. Other VDBMSs use a cost model to select the plan with minimum cost. For example, AnalyticDB-V [84] and Milvus [6, 79] devise costs for several vector operators in order to use a linear cost model that aggregates the I/O and computation cost of each plan operator in order to yield a total plan cost. Query Execution. Several techniques aim to exploit hardware acceleration in order to speed up search queries. Additionally, many VDBMSs adopt distributed architecture, allowing them to scale to larger datasets and workloads. Finally, as some vector indexes are hard to update, some VDBMSs adopt mechanisms for out-of- place updates that enable high write throughput without sacrificing search throughput. (1) Hardware Acceleration. Modern machines equipped with SIMD and GPUs support high amounts of data parallelism. In [26, 27], in addition to parallelizing similarity projection, memory retrieval is identified as a key bottleneck during IVFADC index scan, and a technique is introduced to reduce the amount of retrievals by exploiting the storage capacity of SIMD registers along with SIMD shuffle. In [50], a similar technique is introduced for GPU registers. In Milvus [6, 79], the small register size is identified as a limiting factor, and a technique based on multiple rounds is introduced in order to support (𝑐,𝑘)-search queries with large 𝑘. (2) Distributed Search. Several VDBMSs adopt a distributed archi- tecture where the vector collection is sharded and replicated and scatter-gather is used to answer vector search. To partition the collection into shards, the vectors can be equally partitioned or the partitioning can be index guided, such as placing all vectors in the same bucket into the same partition for a table-based index. These can also take advantage of disaggregated architecture [80] or cloud functions [73] to increase elasticity. (3) Out-of-Place Updates. Many vector indexes are hard to update due to their data dependent nature, leading to long query latencies. To address this issue, some VDBMs perform updates out-of-place, either by applying updates asynchronously over replicas [10, 13, 84], storing updates in a temporary structure and then applying them in bulk at a more appropriate time [10, 84], or using dedicated structures such as a log-structured merge (LSM) tree [6, 45, 79].', 'part_title': '1 introduction', 'sub_title': '2.3 query optimization and execution'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 5, 'content': 'Native. Native systems aim at providing dedicated vector capabili- ties. Some native systems target mostly vector workloads, whereas others target mostly mixed workloads that consist of queries over both vectors and attributes. (1) Mostly Vector. Mostly-vector systems aim to support efficient vector queries with limited support for attribute-related capabilities such as predicated search. As a result, these systems tend to be streamlined for vectors. The interface tends to be a simple API, and there is usually no query parser or rewriter, reducing the query processing overhead. Usually there is also no optimizer as all queries are handled in the same way by a single search index. Some systems like EuclidesDB [14] and Vald [10] do not support predicated search at all, whereas others like Vearch [12], Pinecone [5], and Chroma [15] support it with a single predefined plan.', 'part_title': '1 introduction', 'sub_title': '2.4 existing systems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile James Jie Pan, Jianguo Wang, and Guoliang Li (2) Mostly Mixed. Mostly-mixed systems aim to support a wider variety of queries and query plans, including attribute-only queries in some cases. This makes them more complex, featuring more sophisticated data and storage models as well as query optimiza- tion. For example, Milvus [6, 79], Qdrant [3], and Manu [45] all include query optimizers. Systems like Weaviate [13], NucliaDB [16], and Marqo [11] support other queries in addition to vector queries. Weaviate uses a graph data model over data entities and supports graph-based queries, while NucliaDB and Marqo support non-vector keyword queries in addition to combined similarity and keyword queries via dense and sparse multi-vectors. Extended. When deploying a native system is difficult3 or when it simply lacks capabilities, an extended system may be preferred. Extended systems aim to offer best of both worlds by integrating vector capabilities into a non-vector NoSQL or relational system. (1) NoSQL. Many NoSQL systems have or are planned to be extended to support vector capabilities, including Vespa [4], Cassandra [53], Spark-based Databricks, MongoDB, CosmosDB, and Redis. This is typically achieved by adding vector search indexes into the stor- age engine. For example Cassandra plans to integrate an HNSW index into the storage layer, implement scatter-gather to support distributed vector search, and extend the Cassandra query language with vector-related operators. (2) Relational. If a similarity score is available, a relational system can already answer vector queries via brute-force scan, as demon- strated by SingleStore [17, 66]. Moreover, after the built-in query optimizer is made aware of vector operators, it can be used for plan enumeration and selection as in PASE [90] and pgvector [7] which also introduce search indexes into PostgreSQL. Other rela- tional systems with similar vector support include AnalyticDB-V [84], Clickhouse, and MyScale. A recent work [92] analyzed the potential limitations of using relational databases to support vector search and explored ways to overcome these limitations. Search Engines and Libraries. Some applications may not require a fully managed system. In this case, a few popular search engines, including Apache Lucene [8], Elasticsearch [9], OpenSearch [18], and Solr [19] now support vector search and may be preferred. There are also several libraries that offer low-level search capability, including Microsoft SPTAG [20] and Meta Faiss [1].', 'part_title': '1 introduction', 'sub_title': '2.4 existing systems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'We discuss two comprehensive benchmarks. In [55], a wide vari- ety of ANN techniques and search indexes are reimplemented and evaluated across a range of workloads. The datasets go up to thou- sands of dimensions and are collected from real-world image, text, video, and audio collections. In [29], existing implementations that are available for use are compared, leaving intact implementation- specific techniques. It also includes several commercial VDBMSs in the evaluation, and the results are available online4.', 'part_title': '1 introduction', 'sub_title': '2.5 benchmarks'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'Despite this progress, several challenges remain.', 'part_title': '1 introduction', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': '(1) Similarity Score Selection. Approaches for similarity score selec- tion remain lacking. EuclidesDB [14] offers one approach where many scores and embedding models can be queried at once, but the ultimate decision is left to the user. In [82], the score is dynamically adjusted based on the query, but the technique is limited to social media recommendation. (2) Operator and Index Design. Existing hybrid operators are limited to only small number of attribute categories, and there is a need for more powerful operators that can support more complex hybrid queries. Additionally, aside from DiskANN [74] and SPANN [32], there remains a lack of disk-based indexes. (3) Cost Estimation. The cost of block-first scan and visit-first scan is difficult to estimate due to the uncertain effect from blocking. For tree and graph-based indexes, blocking and predicate failures can lead to excessive backtracking, increasing query latency. On the other hand, post-filtering leads to uncertainty in the size of the result set as fewer than 𝑘results may be returned for a (𝑐,𝑘)-search query due to the filter. One way to avoid this is to retrieve 𝛼𝑘results before the filter so that there are enough results after the filter is applied [79, 84], but how to tune 𝛼remains unclear. (4) Security and Privacy. Many VDBMSs are offered as managed cloud services that may be vulnerable to attack. For multi-tenant systems, there is a need for techniques that can support private and secure vector operations, such as secure 𝑘-NN search [88, 93]. (5) Incremental Search. Applications such as e-commerce rely on incremental search, where the result set is seamlessly fetched in parts. Techniques such as [39] exist for incremental 𝑘-NN search but it is unclear how to support this search within vector indexes. (6) Multi-Vector Search. Applications such as facial recognition or contextual text retrieval make use of multi-vector search. While aggregate scores can be used to support these applications, they re- quire significant computations and increase query latency. Generic multi-attribute top-𝑘techniques also cannot easily be applied to vector indexes [79], and new techniques are needed.', 'part_title': '1 introduction', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'James Jie Pan is a postdoctoral researcher at Tsinghua University. His research interest is vector data management. Jianguo Wang is a tenure-track assistant professor in the De- partment of Computer Science at Purdue University. His research interests include disaggregated databases and vector databases. He is a recipient of the NSF CAREER Award. Guoliang Li is a professor in the Department of Computer Science at Tsinghua University in Beijing, China. His research interests include machine learning for databases, database systems, and data cleaning and integration.', 'part_title': '3 presenters', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 6, 'content': 'This paper was sponsored by National Key Research and Devel- opment Program of China (2023YFB4503600), and NSF of China (61925205, 62232009, 62102215). Jianguo Wang acknowledges the support of the National Science Foundation under Grant Number 2337806.', 'part_title': '3 presenters', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': 'Vector Database Management Techniques and Systems SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile [10] [n. d.]. http://vald.vdaas.org. [11] [n. d.]. http://marqo.ai. [12] [n. d.]. http://github.com/vearch. [13] [n. d.]. http://weaviate.io. [14] [n. d.]. http://euclidesdb.readthedocs.io. [15] [n. d.]. http://trychroma.com. [16] [n. d.]. http://nuclia.com. [17] [n. d.]. http://singlestore.com. [18] [n. d.]. http://opensearch.org. [19] [n. d.]. http://solr.apache.org. [20] [n. d.]. http://github.com/microsoft/SPTAG. [21] Ahmed Abdelkader, Sunil Arya, Guilherme D. da Fonseca, and David M. Mount. 2019. Approximate nearest neighbor searching with non-Euclidean and weighted distances. In SODA. 355–372.', 'part_title': '3 presenters', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[22] Charu C. Aggarwal, Alexander Hinneburg, and Daniel A. Keim. 2001. On the surprising behavior of distance metrics in high dimensional space. In ICDT.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[23] Alexandr Andoni, Piotr Indyk, Thijs Laarhoven, Ilya Razenshteyn, and Ludwig Schmidt. 2015. Practical and optimal LSH for angular distance. In NeurIPS. 1225– 1233.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[24] Alexandr Andoni, Piotr Indyk, and Ilya Razenshteyn. 2018. Approximate nearest neighbor search in high dimensions. In ICM. 3287–3318.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[25] Alexandr Andoni and Ilya Razenshteyn. 2015. Optimal data-dependent hashing for approximate near neighbors. In STOC. 793–801.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[26] Fabien André, Anne-Marie Kermarrec, and Nicolas Le Scouarnec. 2017. Acceler- ated Nearest Neighbor Search with Quick ADC. In ICMR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[27] Fabien André, Anne-Marie Kermarrec, and Nicolas Le Scouarnec. 2021. Quicker ADC: Unlocking the hidden potential of product quantization with SIMD. IEEE Trans. Pattern Anal. and Mach. Intell. 43, 5 (2021), 1666–1677.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[28] Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023. Retrieval-based Language Models and Applications. In ACL.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[29] Martin Aumüller, Erik Bernhardsson, and Alexander Faithfull. 2020. ANN- Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms. Inform. Syst. 87 (2020).', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[30] Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft. 1999. When is “nearest neighbor” meaningful?. In ICDT.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[31] Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. 2020. Pre-training tasks for embedding-based large-scale retrieval. In ICLR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[32] Qi Chen, Bing Zhao, Haidong Wang, Mingqin Li, Chuanjie Liu, Zengzhong Li, Mao Yang, Jingdong Wang, Mao Yang, and Jingdong Wang. 2021. SPANN: Highly-efficient billion-scale approximate nearest neighbor search. In NeurIPS.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[33] Sanjoy Dasgupta and Yoav Freund. 2008. Random projection trees and low dimensional manifolds. In STOC. 537–546.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[34] Sanjoy Dasgupta and Kaushik Sinha. 2013. Randomized partition trees for exact nearest neighbor search. In COLT. 317–337.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[35] Mayur Datar, Nicole Immorlica, Piotr Indyk, and Vahab S. Mirrokni. 2004. Locality- sensitive hashing scheme based on p-stable distributions. In SCG. 253–262.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[36] Wei Dong, Moses Charikar, and Kai Li. 2011. Efficient 𝑘-nearest neighbor graph construction for generic similarity measures. In WWW.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[37] Karima Echihabi, Kostas Zoumpatianos, and Themis Palpanas. 2021. New trends in high-D vector similarity search: AI-driven, progressive, and distributed. Proc. VLDB Endow. 14, 12 (2021), 3198–3201.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[38] H. Edelsbrunner and N. R. Shah. 1996. Incremental topological flipping works for regular triangulations. Algorithmica 15 (1996), 223–241.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[39] Danyel Fisher, Igor Popov, Steven Drucker, and M. C. Schraefel. 2012. Trust me, I’m partially right: Incremental visualization lets analysts explore large datasets faster. In SIGCHI. 1673–1682.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[40] Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast approximate nearest neighbor search with the navigating spreading-out graph. Proc. VLDB Endow. 12, 5 (2019), 461–474.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[41] Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun. 2013. Optimized product quantization for approximate nearest neighbor search. In CVPR. 2946–2953.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[42] Allen Gersho and Robert M. Gray. 1991. Vector Quantization and Signal Compres- sion. Springer.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[43] Siddharth Gollapudi, Neel Karia, Varun Sivashankar, Ravishankar Krishnaswamy, Nikit Begwani, Swapnil Raz, Yiyong Lin, Yin Zhang, Neelam Mahapatro, Premku- mar Srinivasan, Amit Singh, and Harsha Vardhan Simhadri. 2023. Filtered- DiskANN: Graph algorithms for approximate nearest neighbor search with filters.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[44] Robert M. Gray. 1984. Vector quantization. IEEE ASSP Mag. 1, 2 (1984), 4–29. [45] Rentong Guo, Xiaofan Luan, Long Xiang, Xiao Yan, Xiaomeng Yi, Jigao Luo, Qianya Cheng, Weizhi Xu, Jiarui Luo, Frank Liu, Zhenshan Cao, Yanliang Qiao, Ting Wang, Bo Tang, and Charles Xie. 2022. Manu: A cloud native vector database management system. Proc. VLDB Endow. 15, 12 (2022), 3548–3561.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[46] Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and Sanjiv Kumar. 2020. Accelerating large-scale inference with anisotropic vector quantization. In ICML, Vol. 119. 3887–3896.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[47] Ben Harwood and Tom Drummond. 2016. FANNG: Fast approximate nearest neighbour graphs. In CVPR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[48] Piotr Indyk and Rajeev Motwani. 1998. Approximate nearest neighbors: Towards removing the curse of dimensionality. In STOC. 604–613.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[49] Hervé Jégou, Matthijs Douze, and Cordelia Schmid. 2011. Product quantization for nearest neighbor search. IEEE Trans. Pattern Anal. and Mach. Intell. 33, 1 (2011), 117–128.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[50] Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2021. Billion-scale similarity search with GPUs. IEEE Trans. Big Data 7, 3 (2021), 535–547.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[51] Yubin Kim. 2022. Applications and future of dense retrieval in industry. In SIGIR. 3373–3374.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[52] Jon M. Kleinberg. 2000. Navigation in a small world. Nature 406 (2000), 845. [53] Avinash Lakshman and Prashant Malik. 2010. Cassandra: A decentralized struc- tured storage system. SIGOPS Oper. Syst. Rev. 44, 2 (2010), 35–40.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[54] Jie Li, Haifeng Liu, Chuanghua Gui, Jianyu Chen, Zhenyuan Ni, Ning Wang, and Yuan Chen. 2018. The design and implementation of a real time visual search system on JD e-commerce platform. In Middleware. 9–16.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[55] Wen Li, Ying Zhang, Yifang Sun, Wei Wang, Mingjie Li, Wenjie Zhang, and Xuemin Lin. 2020. Approximate nearest neighbor search on high dimensional data — Experiments, analyses, and improvement. IEEE Trans. Knowl. Data Eng. 32, 8 (2020), 1475–1488.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[56] S. Lloyd. 1982. Least squares quantization in PCM. IEEE Trans. Inform. Theory 28, 2 (1982), 129–137.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[57] Yury Malkov, Alexander Ponomarenko, Andrey Logvinov, and Vladimir Krylov. 2014. Approximate nearest neighbor algorithm based on navigable small world graphs. Inform. Syst. 45 (2014), 61–68.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[58] Yury Malkov and D. A. Yashunin. 2020. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Trans. Pattern Anal. and Mach. Intell. 42, 4 (2020), 824–836.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[59] Yusuke Matsui, Yusuke Uchida, Hervé Jégou, and Shin’ichi Satoh. 2018. A survey of product quantization. ITE Trans. Media Technol. and Appl. 6, 1 (2018), 2–10.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[60] Jingfan Meng, Huayi Wang, Jun Xu, and Mitsunori Ogihara. 2022. ONe Index for All Kernels (ONIAK): A zero re-indexing LSH solution to ANNS-ALT (After Linear Transformation). Proc. VLDB Endow. 15, 13 (2022), 3937–3949.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[61] Evgeny M. Mirkes, Jeza Allohibi, and Alexander Gorban. 2020. Fractional Norms and Quasinorms Do Not Help to Overcome the Curse of Dimensionality. Entropy 22, 10 (2020).', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[62] Marius Muja and David G Lowe. 2009. FLANN: Fast library for approximate nearest neighbors. In VISAPP.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[63] Gonzalo Navarro. 2002. Searching in metric spaces by spatial approximation. VLDB J. (2002).', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[64] Mohammad Norouzi and David J. Fleet. 2013. Cartesian 𝑘-means. In CVPR. [65] Rodrigo Paredes, Edgar Chávez, Karina Figueroa, and Gonzalo Navarro. 2006. Practical construction of 𝑘-nearest neighbor graphs in metric spaces. In WEA.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[66] Adam Prout, Szu-Po Wang, Joseph Victor, Zhou Sun, Yongzhu Li, Jack Chen, Evan Bergeron, Eric Hanson, Robert Walzer, Rodrigo Gomes, and Nikita Shamgunov. 2022. Cloud-native transactions and analytics in SingleStore. In SIGMOD. 2340– 2352.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[67] Jianbin Qin, Wei Wang, Chuan Xiao, and Ying Zhang. 2020. Similarity query processing for high-dimensional data. Proc. VLDB Endow. 13, 12 (2020), 3437– 3440.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[68] Jianbin Qin, Wei Wang, Chuan Xiao, Ying Zhang, and Yaoshu Wang. 2021. High- dimensional similarity query processing for data science. In KDD. 4062–4063.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[69] Parikshit Ram and Kaushik Sinha. 2019. Revisiting 𝑘𝑑-tree for nearest neighbor search. In KDD. 1378–1388.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[70] Aviad Rubinstein. 2018. Hardness of approximate nearest neighbor search. In STOC. 1260–1268.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[71] R. R. Salakhutdinov and G. E. Hinton. 2007. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[72] C. Silpa-Anan and R. Hartley. 2008. Optimised KD-trees for fast image descriptor matching. In CVPR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[73] Yongye Su, Yinqi Sun, Minjia Zhang, and Jianguo Wang. 2024. Vexless: A Server- less Vector Data Management System Using Cloud Functions. In Proceedings of ACM Conference on Management of Data (SIGMOD).', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[74] Suhas Jayaram Subramanya, Devvrit, Rohan Kadekodi, Ravishankar Krish- naswamy, and Harsha Simhadri. 2019. DiskANN: Fast accurate billion-point nearest neighbor search on a single node. In NeurIPS.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 7, 'content': '[75] Jacopo Tagliabue and Ciro Greco. 2023. (Vector) Space is not the final frontier: Product search as program synthesis. In SIGIR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': 'SIGMOD-Companion ’24, June 9–15, 2024, Santiago, AA, Chile James Jie Pan, Jianguo Wang, and Guoliang Li [76] Jiajie Tan, Jinlong Hu, and Shoubin Dong. 2023. Incorporating entity-level knowledge in pretrained language model for biomedical dense retrieval. Comput. Biol. Med. 166 (2023).', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[77] P. M. Vaidya. 1989. An 𝑂(𝑛log𝑛) algorithm for the all-nearest-neighbors prob- lem. Discrete Comput. Geom. 4 (1989), 101–115.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[78] Jing Wang, Jingdong Wang, Gang Zeng, Zhuowen Tu, Rui Gan, and Shipeng Li. 2012. Scalable 𝑘-NN graph construction for visual descriptors. In CVPR. 1106–1113.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[79] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xi- angyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, Kun Yu, Yuxing Yuan, Yinghao Zou, Jiquan Long, Yudong Cai, Zhenxiang Li, Zhifeng Zhang, Yihua Mo, Jun Gu, Ruiyi Jiang, Yi Wei, and Charles Xie. 2021. Milvus: A purpose-built vector data management system. In SIGMOD. 2614–2627.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[81] Jingdong Wang, Ting Zhang, Jingkuan Song, Nicu Sebe, and Heng Tao Shen. 2018. A survey on learning to hash. IEEE Trans. Pattern Anal. and Mach. Intell. 40, 4 (2018), 769–790.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[82] Wenping Wang, Yunxi Guo, Chiyao Shen, Shuai Ding, Guangdeng Liao, Hao Fu, and Pramodh Karanth Prabhakar. 2023. Integrity and junkiness failure handling for embedding-based retrieval: A case study in social network search. In SIGIR.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[83] Duncan J. Watts and Steven H. Strogatz. 1998. Collective dynamics of ‘small- world’ networks. Nature 393 (1998), 440–442.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[84] Chuangxian Wei, Bin Wu, Sheng Wang, Renjie Lou, Chaoqun Zhan, Feifei Li, and Yuanzhe Cai. 2020. AnalyticDB-V: A hybrid analytical engine towards query fusion for structured and unstructured data. Proc. VLDB Endow. 13, 12 (2020), 3152–3165.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[85] Yair Weiss, Antonio Torralba, and Rob Fergus. 2008. Spectral hashing. In NeurIPS. 1753–1760.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[86] Ryan Williams. 2018. On the difference between closest, furthest, and orthogonal pairs: Nearly-linear vs barely-subquadratic complexity. In SODA. 1207–1215.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[87] Wei Wu, Junlin He, Yu Qiao, Guoheng Fu, Li Liu, and Jin Yu. 2022. HQANN: Efficient and robust similarity search for hybrid queries with structured and unstructured constraints. In CIKM.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[88] Wenzhuo Xue, Hui Li, Yanguo Peng, Jiangtao Cui, and Yu Shi. 2018. Secure𝑘near- est neighbors query for high-dimensional vectors in outsourced environments. IEEE Trans. Big Data 4, 4 (2018), 586–599.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[89] Artem Babenko Yandex and Victor Lempitsky. 2016. Efficient indexing of billion- scale datasets of deep descriptors. In CVPR. 2055–2063.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[90] Wen Yang, Tao Li, Gai Fang, and Hong Wei. 2020. PASE: PostgreSQL ultra- high-dimensional approximate nearest neighbor search extension. In SIGMOD. 2241–2253.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[91] Huayi Zhang, Lei Cao, Yizhou Yan, Samuel Madden, and Elke A. Rundensteiner. 2020. Continuously adaptive similarity search. In SIGMOD. 2601–2616.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[92] Yunan Zhang, Shige Liu, and Jianguo Wang. 2024. Are there fundamental limi- tations in supporting vector data management in relational databases? A case study of PostgreSQL. In ICDE.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}, {'_index': 'search-index-202406261143vector-database', 'doc': {'database': 'google_scholar', 'es_pdf_id': 'aqNcVJABCBTRytG2phPp', 'created_on': '2024-06-26T11:43:27.719712', 'pdf_page': 8, 'content': '[93] Zhilin Zhang, Ke Wang, Chen Lin, and Weipeng Lin. 2018. Secure top-k inner product retrieval. In CIKM. 77–86.', 'part_title': 'references', 'sub_title': '2.6 challenges and open problems'}}]