{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_scholar_search_url(query_terms : list[str], query_params : dict | None = None):\n",
    "\n",
    "    scholar_base_url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5\"\n",
    "\n",
    "    search_url = f\"{scholar_base_url}&q={'+'.join(query_terms)}&btnG=\"\n",
    "\n",
    "    return search_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies_list():\n",
    "    with open(file='./proxyscrape_premium_http_proxies.txt', mode='r') as proxies_file:\n",
    "        proxies = proxies_file.readlines()\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./headers.yml') as f_headers:\n",
    "    browser_header = yaml.safe_load(f_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       " 'accept-encoding': 'gzip, deflate, br',\n",
       " 'accept-language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
       " 'cache-control': 'max-age=0',\n",
       " 'sec-fetch-dest': 'document',\n",
       " 'sec-fetch-mode': 'navigate',\n",
       " 'sec-fetch-site': 'same-origin',\n",
       " 'sec-fetch-user': '?1',\n",
       " 'upgrade-insecure-requests': '1',\n",
       " 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser_header['Chrome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "import uuid\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from typing import Iterator\n",
    "import logging\n",
    "import yaml\n",
    "def get_dataframe_shuffled(df : pd.DataFrame, column : str | None = None) -> Iterator[pd.Series]:\n",
    "\n",
    "    rows = df.sample(frac=1).iterrows()\n",
    "\n",
    "    for row in rows :\n",
    "        if column :\n",
    "            yield row[1][column]\n",
    "        else :\n",
    "            yield row[1]\n",
    "\n",
    "class ProxiesHandler():\n",
    "    free_proxies_providers = [\"https://free-proxy-list.net\"]\n",
    "\n",
    "    _retrieved_proxies      = None\n",
    "    _proxies                = set()\n",
    "    _used_proxies           = set()\n",
    "    _not_working_proxies    = set()\n",
    "    _browser_header         = None\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._mimic_header = None\n",
    "\n",
    "    def get_proxies_elements(self):\n",
    "        for proxies_provider in self.free_proxies_providers :\n",
    "            resp = requests.get(proxies_provider)\n",
    "            proxy_list = pd.read_html(resp.text)[0]\n",
    "            proxy_list[\"url\"]=\"http://\" + proxy_list[\"IP Address\"] + \":\" + proxy_list[\"Port\"].astype(str)\n",
    "            self._retrieved_proxies = proxy_list[proxy_list[\"Https\"]==\"yes\"]\n",
    "\n",
    "    def build_good_proxies(self):\n",
    "        test_url = \"https://httpbin.org/ip\"\n",
    "\n",
    "\n",
    "        for proxy_row in get_dataframe_shuffled(df=self.proxies_retrived):\n",
    "            proxy_url = proxy_row['url']\n",
    "            try :\n",
    "                proxies = {\n",
    "                    'http'  : proxy_url,\n",
    "                    'https' : proxy_url\n",
    "                }\n",
    "                resp = requests.get(url=test_url, headers=self.browser_header['Chrome'], proxies=proxies, timeout=2)\n",
    "                print(f\"proxy inscription : {proxy_url}\")\n",
    "                proxy_ip = f\"{proxy_row['IP Address']}:{proxy_row['Port']}\" if proxy_row['Port'] else proxy_row['IP Address']\n",
    "                # proxy_ip = {proxy_row['IP Address']}\n",
    "                self._proxies.add(proxy_ip)\n",
    "                self.proxies_retrived.drop(index=self.proxies_retrived[self.proxies_retrived['url']==proxy_url].index)\n",
    "            except Exception :\n",
    "                print(f\"proxy eviction : {proxy_url}\")\n",
    "                print(f\"mimic_header = {self.mimic_header}\")\n",
    "                self.proxies_retrived.drop(index=self.proxies_retrived[self.proxies_retrived['url']==proxy_url].index)\n",
    "            if len(self._proxies) >= 5 :\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def mimic_header(self) -> dict[str, str]:\n",
    "        if not self._mimic_header :\n",
    "            resp = requests.get(\n",
    "                url='https://headers.scrapeops.io/v1/browser-headers',\n",
    "                params={\n",
    "                    'api_key': \"eba35a93-5dc6-4c01-971b-57b649ef7b6b\",\n",
    "                    'num_results': '1'}\n",
    "                )\n",
    "            self._mimic_header = resp.json()['result'][0]\n",
    "        \n",
    "        return self._mimic_header\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def proxies_retrived(self) -> pd.DataFrame:\n",
    "        if not isinstance(self._retrieved_proxies, pd.DataFrame) :\n",
    "            self.get_proxies_elements()\n",
    "            # dataframe = pd.DataFrame({'IP Address' : get_proxies_list()})\n",
    "            # dataframe['IP Address'] = dataframe['IP Address'].replace('\\\\n', \"\", regex=True)\n",
    "            # dataframe['url'] = \"http://\" + dataframe\n",
    "            # self._retrieved_proxies = dataframe\n",
    "        \n",
    "        if self._retrieved_proxies.empty:\n",
    "            self.get_proxies_elements()\n",
    "            # dataframe = pd.DataFrame({'IP Address' : get_proxies_list()})\n",
    "            # dataframe['IP Address'] = dataframe['IP Address'].replace('\\\\n', \"\", regex=True)\n",
    "            # dataframe['url'] = \"http://\" + dataframe\n",
    "            # self._retrieved_proxies = dataframe\n",
    "        \n",
    "        return self._retrieved_proxies\n",
    "    \n",
    "    @property\n",
    "    def proxies(self) -> set:\n",
    "        if not self._proxies :\n",
    "            self.build_good_proxies()\n",
    "            # self._proxies = set(self.proxies_retrived['IP Address'])\n",
    "        return self._proxies\n",
    "    \n",
    "    @property\n",
    "    def proxy(self) -> str:\n",
    "        return self.proxies.pop()\n",
    "    \n",
    "    @property\n",
    "    def browser_header(self):\n",
    "        if not self._browser_header :\n",
    "            with open('./headers.yml') as f_headers:\n",
    "                self._browser_header = yaml.safe_load(f_headers)\n",
    "        return self._browser_header\n",
    "\n",
    "class ScrapingDriver():\n",
    "    AGENT_LIST = [\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:24.0) Gecko/20100101 Firefox/24.0\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/91.0.4472.114 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\"\n",
    "        ]\n",
    "    _proxies_handler = ProxiesHandler()\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_driver(self, url : str) -> tuple[Chrome, Path]:\n",
    "        # lg.info(\"Creation d'un moteur de scraping.\")\n",
    "        # service = Service(executable_path='/usr/bin/chromedriver')\n",
    "        chrome_options = ChromeOptions()\n",
    "\n",
    "        # temp_folder = Path(os.getenv(\"TEMP_EMPL\"))\n",
    "        # temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "        temp_folder = Path('./temp_' + str(uuid.uuid4()))\n",
    "        temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        prefs = {\n",
    "            \"download.default_directory\" : str(temp_folder.absolute()),\n",
    "            'download.prompt_for_download': False,\n",
    "            'plugins.always_open_pdf_externally': True,\n",
    "            \"plugins.plugins_disabled\" : \"Chrome PDF Viewer\",\n",
    "        }\n",
    "\n",
    "        # chrome_options.add_argument(\"--headless=new\")\n",
    "        chrome_options.add_argument('--disable-blink-features')\n",
    "        chrome_options.add_argument(\"--incognito\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_argument(f'--proxy-server={self._proxies_handler.proxy}')\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "        chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "        \n",
    "\n",
    "        driver = Chrome(\n",
    "            options=chrome_options,\n",
    "            # service=service\n",
    "            )\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": choice(self.AGENT_LIST)})\n",
    "        driver.get(url=url)\n",
    "\n",
    "        return driver, temp_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = ProxiesHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = requests.get(url='https://api.proxyscrape.com/v2/account/datacenter_shared/proxy-list?auth=6ff2g7v49p686gac8bte&type=getproxies&country[]=all&protocol=http&format=json&status=online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterable, Any\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4.element import Tag\n",
    "import os\n",
    "from copy import copy\n",
    "from search_app.core.services.webscraping.random_wait import wait_rand\n",
    "class DocumentRetriever():\n",
    "\n",
    "    _scraping_driver = ScrapingDriver()\n",
    "\n",
    "    def __init__(self, document_extract:Tag, webdriver_package : dict[str, Chrome | Path]) -> None:\n",
    "\n",
    "        print(\"Récupération des données du document.\")\n",
    "\n",
    "        self._webdriver_package = webdriver_package\n",
    "        self.document_extract = document_extract\n",
    "        self.url = copy(self.driver.current_url)\n",
    "\n",
    "        self.result_id = document_extract.attrs['data-cid']\n",
    "\n",
    "    def get_files(self) -> tuple[bytes, str] | None:\n",
    "        print(\"Récupération des fichiers disponnibles sur la page.\")\n",
    "        self.__get_pdf_file_if_exist()\n",
    "\n",
    "        if self.pdf_file :\n",
    "            self.ris_file = self.__get_bilio_info()\n",
    "        \n",
    "            if self.ris_file :\n",
    "                # return {\"pdf_file\" : self.pdf_file, \"ris_file\" : self.ris_file}\n",
    "                return self.pdf_file, self.ris_file\n",
    "            else :\n",
    "                return None\n",
    "        else :\n",
    "                return None\n",
    "        \n",
    "    @property\n",
    "    def driver(self) -> Chrome:\n",
    "        return self._webdriver_package['driver']\n",
    "    \n",
    "    @driver.setter\n",
    "    def driver(self, value):\n",
    "        self._webdriver_package.update({\n",
    "            'driver' : value\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def temp_folder(self) -> Path:\n",
    "        return self._webdriver_package['folder']\n",
    "    \n",
    "    @temp_folder.setter\n",
    "    def temp_folder(self, value):\n",
    "        self._webdriver_package.update({\n",
    "            'folder' : value\n",
    "        })\n",
    "\n",
    "    def rebuild_driver(self):\n",
    "        print('reconstruction du moteur de scraping')\n",
    "        self.temp_folder.rmdir()\n",
    "        new_driver_package  = self._scraping_driver.get_driver(url = self.url)\n",
    "        self.driver         = new_driver_package['driver']\n",
    "        self.temp_folder    = new_driver_package['folder']\n",
    "\n",
    "\n",
    "    def __get_bilio_info(self, *args, **kwargs) -> dict:\n",
    "\n",
    "        print(\"Récupération des données bibliographiques.\")\n",
    "\n",
    "        try :\n",
    "            self.driver.find_element(by=By.XPATH, value=f\"//div[@data-cid='{self.result_id}']//a[@aria-controls='gs_cit']\").click()\n",
    "            wait_rand(size=\"medium\")\n",
    "            WebDriverWait(self.driver, 20.0).until(lambda d: self.driver.find_element(by=By.XPATH, value=\"//a[@class='gs_citi' and contains(., 'RefMan')]\"))\n",
    "        except NoSuchElementException as e :\n",
    "            retry = kwargs.get('retry', 3)\n",
    "            if retry :\n",
    "                print(f\"Rééssaie de telechargement des données bibliographiques : tentative restantes {retry}\")\n",
    "                retry += -1\n",
    "                self.rebuild_driver()\n",
    "                self.__get_bilio_info(retry = retry)\n",
    "            else:\n",
    "                e_text = f\"Les données bibliogrqphiques n'ont pu être récupérées\"\n",
    "                print(e_text, exc_info=True)\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            e_text = f\"Les données bibliogrqphiques n'ont pu être récupérées\"\n",
    "            print(e_text, exc_info=True)\n",
    "            return None\n",
    "\n",
    "        ris_citation = self.driver.find_element(by=By.XPATH, value=\"//a[@class='gs_citi' and contains(., 'RefMan')]\")\n",
    "\n",
    "        if not ris_citation:\n",
    "            print('Le document ne possède par de références bibliographiques téléchargeables')\n",
    "            self.driver.find_element(by=By.XPATH, value=f\"//div[@class='gs_md_d gs_md_ds gs_ttzi gs_vis']//a[@id='gs_cit-x']\").click()\n",
    "            return None\n",
    "        ris_citation.click()\n",
    "        wait_rand(size=\"small\")\n",
    "\n",
    "        dwl_dir = self.temp_folder\n",
    "        files_in_temp = [f for f in dwl_dir.iterdir() if f.is_file()]\n",
    "        if files_in_temp :\n",
    "            ris_file = files_in_temp[0]\n",
    "            # ris_file_path = dwl_dir.joinpath(ris_file)\n",
    "            with open(ris_file.absolute(), mode=\"r\") as risfile:\n",
    "                ris_content = risfile.read()\n",
    "            os.remove(ris_file.absolute())\n",
    "\n",
    "        else :\n",
    "            e_text = f\"Erreur de récupération des références bibliographiques, le téléchargement n'a pas eu lieu.\"\n",
    "            print(e_text)\n",
    "            raise ConnectionError(e_text)\n",
    "        self.driver.find_element(by=By.XPATH, value=f\"//div[@class='gs_md_d gs_md_ds gs_ttzi gs_vis']//a[@id='gs_cit-x']\").click()\n",
    "        wait_rand(size=\"small\")\n",
    "        \n",
    "        if ris_content :\n",
    "            return ris_content\n",
    "        else :\n",
    "            return None\n",
    "    \n",
    "    def __download_pdf_file(self, *args, **kwargs):\n",
    "\n",
    "        print(\"Téléchargement du fichier PDF.\")\n",
    "\n",
    "        try :\n",
    "            print(\"Suivi du lien de téléchargement.\")\n",
    "            self.driver.find_element(by=By.XPATH, value=f\"//a[@data-clk-atid='{self.result_id}']\").click()\n",
    "            wait_rand(size='medium')\n",
    "        except NoSuchElementException as e :\n",
    "            retry = kwargs.get('retry', 3)\n",
    "            if retry :\n",
    "                print(f\"Rééssaie de telechargement du fichier pdf : tentative restantes {retry}\")\n",
    "                retry += -1\n",
    "                self.rebuild_driver()\n",
    "                self.__download_pdf_file(retry = retry)\n",
    "            else:\n",
    "                e_text = \"Erreur lors de la récupération du fichier PDF (ouverture du téléchargement).\"\n",
    "                print(e_text, exc_info=True)\n",
    "                return None\n",
    "        except Exception as e :\n",
    "            e_text = \"Erreur lors de la récupération du fichier PDF (ouverture du téléchargement).\"\n",
    "            print(e_text, exc_info=True)\n",
    "            return None\n",
    "\n",
    "        print(\"Recupération du fichier dans le dossier temporaire.\")\n",
    "        dwl_dir = self.temp_folder\n",
    "        files_in_temp = [f for f in  dwl_dir.iterdir() if f.is_file()]\n",
    "        if files_in_temp :\n",
    "            pdf_file = files_in_temp[0]\n",
    "            if pdf_file :\n",
    "                # pdf_file = dwl_dir.joinpath(pdf_file)\n",
    "                \n",
    "                print(\"Lecture du fichier pdf.\")\n",
    "                with open(pdf_file.absolute(), mode=\"rb\") as pdf_local_file:\n",
    "                    pdf = pdf_local_file.read()\n",
    "                print(\"Suppression du fichier pdf du dossier temporaire.\")\n",
    "                os.remove(pdf_file.absolute())\n",
    "                if pdf :\n",
    "                    return pdf\n",
    "                else:\n",
    "                    return None\n",
    "        else :\n",
    "            return None\n",
    "    \n",
    "    def __get_pdf_file_if_exist(self):\n",
    "        \n",
    "        print(\"Tentative de récupération du fichier PDF.\")\n",
    "\n",
    "        is_pdf = None\n",
    "\n",
    "        print(\"Repérage du lien de téléchargement.\")\n",
    "        pdf_block = self.document_extract.find(\"a\", attrs={'data-clk-atid' : self.result_id})\n",
    "        if pdf_block :\n",
    "            pdf_tag = pdf_block.find(\"span\", attrs={'class' : 'gs_ctg2'})\n",
    "            if pdf_tag :\n",
    "                pdf_tag = pdf_tag.text\n",
    "                if pdf_tag :\n",
    "                    if 'pdf' in pdf_tag.lower() :\n",
    "                        is_pdf = True\n",
    "\n",
    "        if is_pdf :\n",
    "            self.pdf_file = self.__download_pdf_file()\n",
    "        else :\n",
    "            print(\"Le lien de téléchagrement PDF est absent\")\n",
    "            self.pdf_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# from search_app.core.services.webscraping.drivers import ScrapingDriver\n",
    "\n",
    "sd = ScrapingDriver()\n",
    "\n",
    "def get_webdriver(url :str):\n",
    "    driver, temp_folder = sd.get_driver(url=url)\n",
    "\n",
    "    wedriver_package = {\n",
    "        'driver' : driver,\n",
    "        'folder' : temp_folder\n",
    "    }\n",
    "    return wedriver_package\n",
    "\n",
    "def get_research_pages_on_gs(url : str, nb_pages:int) -> list[str]:\n",
    "\n",
    "    webdriver_package = get_webdriver(url=url)\n",
    "\n",
    "    results_page = BeautifulSoup(webdriver_package[\"driver\"].execute_script(\"return document.documentElement.outerHTML;\"), 'html.parser')\n",
    "\n",
    "    navigator = results_page.find(\"div\", attrs={'id' : \"gs_n\", 'role' : \"navigation\"})\n",
    "    pages = navigator.find_all(\"a\", limit=nb_pages)\n",
    "    base_url = \"https://scholar.google.com\"\n",
    "\n",
    "    pages_urls = [base_url + page.get(\"href\") for page in pages]\n",
    "\n",
    "    pages_urls[:0] = [webdriver_package[\"driver\"].current_url]\n",
    "\n",
    "    webdriver_package[\"folder\"].rmdir()\n",
    "    webdriver_package[\"driver\"].delete_all_cookies()\n",
    "    webdriver_package[\"driver\"].quit()\n",
    "\n",
    "    return pages_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_app.core.services.webscraping.google_scholar_scraping import DocumentRetriever\n",
    "\n",
    "def parse_page_for_gs(url: str) -> list[tuple[bytes, str]]:\n",
    "    webdriver_package = get_webdriver(url=url)\n",
    "\n",
    "    results_page = BeautifulSoup(webdriver_package[\"driver\"].execute_script(\"return document.documentElement.outerHTML;\"), 'html.parser')\n",
    "    results = results_page.find_all('div', attrs={'class' : \"gs_r gs_or gs_scl\"})\n",
    "    \n",
    "    files = list()\n",
    "    for result in results :\n",
    "            extractor = DocumentRetriever(document_extract=result, webdriver_package=webdriver_package)\n",
    "            file = extractor.get_files()\n",
    "            if file :\n",
    "\n",
    "                files.append(file)\n",
    "\n",
    "    webdriver_package[\"driver\"].delete_all_cookies()\n",
    "    webdriver_package[\"driver\"].quit()\n",
    "    webdriver_package[\"folder\"].rmdir()\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_files(results_list = list[list[tuple[bytes, str]]]):\n",
    "    results_out = list()\n",
    "    for results in results_list :\n",
    "        results_out.extend(results)\n",
    "\n",
    "    return results_out\n",
    "\n",
    "def retrieve_files(pages : list[str]) -> list[tuple[bytes, str]]:\n",
    "\n",
    "    pages_scraping_list = list()\n",
    "\n",
    "    for page in pages :\n",
    "        print(f\"page : {page}\")\n",
    "        pages_scraping_list.append(parse_page_for_gs(page))\n",
    "     \n",
    "    result = get_result_files(pages_scraping_list)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/9gm2w_f53xj6vsx7dgtz95_c0000gn/T/ipykernel_20010/1898748862.py:37: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  proxy_list = pd.read_html(resp.text)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy inscription : http://189.240.60.169:9090\n",
      "proxy eviction : http://52.16.232.164:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://185.64.208.103:53281\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://8.219.97.248:80\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://148.72.173.18:30127\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://67.43.227.227:17629\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://15.236.106.236:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy inscription : http://172.183.241.1:8080\n",
      "proxy eviction : http://103.118.28.41:1004\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://103.208.27.214:999\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://54.179.44.51:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://221.140.235.236:5002\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy inscription : http://221.140.235.237:5002\n",
      "proxy eviction : http://13.56.163.250:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://3.127.62.252:80\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://52.67.10.183:80\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://186.215.87.194:30011\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://189.240.60.168:9090\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://117.250.3.58:8080\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://18.228.198.164:80\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://18.185.169.150:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://3.212.148.199:3128\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy eviction : http://35.72.118.126:80\n",
      "mimic_header = {'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'sec-ch-ua': 'Google Chrome;v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': 'macOS', 'sec-fetch-site': 'none', 'sec-fetch-mod': '', 'sec-fetch-user': '?1', 'accept-encoding': 'gzip, deflate', 'accept-language': 'en-US,en;q=0.5'}\n",
      "proxy inscription : http://35.185.196.38:3128\n",
      "proxy inscription : http://34.92.250.88:11111\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=125.0.6422.142)\nStacktrace:\n0   chromedriver                        0x00000001013c24c8 chromedriver + 4302024\n1   chromedriver                        0x00000001013bae10 chromedriver + 4271632\n2   chromedriver                        0x0000000100fec19c chromedriver + 278940\n3   chromedriver                        0x0000000100fc7474 chromedriver + 128116\n4   chromedriver                        0x0000000101053394 chromedriver + 701332\n5   chromedriver                        0x00000001010664e4 chromedriver + 779492\n6   chromedriver                        0x0000000101023004 chromedriver + 503812\n7   chromedriver                        0x00000001010239ec chromedriver + 506348\n8   chromedriver                        0x000000010138a510 chromedriver + 4072720\n9   chromedriver                        0x000000010138efbc chromedriver + 4091836\n10  chromedriver                        0x0000000101371754 chromedriver + 3970900\n11  chromedriver                        0x000000010138f8a4 chromedriver + 4094116\n12  chromedriver                        0x00000001013646d4 chromedriver + 3917524\n13  chromedriver                        0x00000001013acb08 chromedriver + 4213512\n14  chromedriver                        0x00000001013acc84 chromedriver + 4213892\n15  chromedriver                        0x00000001013baa08 chromedriver + 4270600\n16  libsystem_pthread.dylib             0x00000001a0212f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x00000001a020dd34 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search_url \u001b[38;5;241m=\u001b[39m get_google_scholar_search_url(query_terms\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m pages \u001b[38;5;241m=\u001b[39m \u001b[43mget_research_pages_on_gs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m retrieve_files(pages\u001b[38;5;241m=\u001b[39mpages)\n",
      "Cell \u001b[0;32mIn[118], line 19\u001b[0m, in \u001b[0;36mget_research_pages_on_gs\u001b[0;34m(url, nb_pages)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_research_pages_on_gs\u001b[39m(url : \u001b[38;5;28mstr\u001b[39m, nb_pages:\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     17\u001b[0m     webdriver_package \u001b[38;5;241m=\u001b[39m get_webdriver(url\u001b[38;5;241m=\u001b[39murl)\n\u001b[0;32m---> 19\u001b[0m     results_page \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43mwebdriver_package\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.documentElement.outerHTML;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     navigator \u001b[38;5;241m=\u001b[39m results_page\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnavigation\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     22\u001b[0m     pages \u001b[38;5;241m=\u001b[39m navigator\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, limit\u001b[38;5;241m=\u001b[39mnb_pages)\n",
      "File \u001b[0;32m~/miniconda3/envs/projet_certif/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:407\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[0;34m(self, script, *args)\u001b[0m\n\u001b[1;32m    404\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/projet_certif/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/projet_certif/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=125.0.6422.142)\nStacktrace:\n0   chromedriver                        0x00000001013c24c8 chromedriver + 4302024\n1   chromedriver                        0x00000001013bae10 chromedriver + 4271632\n2   chromedriver                        0x0000000100fec19c chromedriver + 278940\n3   chromedriver                        0x0000000100fc7474 chromedriver + 128116\n4   chromedriver                        0x0000000101053394 chromedriver + 701332\n5   chromedriver                        0x00000001010664e4 chromedriver + 779492\n6   chromedriver                        0x0000000101023004 chromedriver + 503812\n7   chromedriver                        0x00000001010239ec chromedriver + 506348\n8   chromedriver                        0x000000010138a510 chromedriver + 4072720\n9   chromedriver                        0x000000010138efbc chromedriver + 4091836\n10  chromedriver                        0x0000000101371754 chromedriver + 3970900\n11  chromedriver                        0x000000010138f8a4 chromedriver + 4094116\n12  chromedriver                        0x00000001013646d4 chromedriver + 3917524\n13  chromedriver                        0x00000001013acb08 chromedriver + 4213512\n14  chromedriver                        0x00000001013acc84 chromedriver + 4213892\n15  chromedriver                        0x00000001013baa08 chromedriver + 4270600\n16  libsystem_pthread.dylib             0x00000001a0212f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x00000001a020dd34 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "search_url = get_google_scholar_search_url(query_terms=['vector', 'database'])\n",
    "pages = get_research_pages_on_gs(search_url, 1)\n",
    "result = retrieve_files(pages=pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=vector+database&btnG=''\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_certif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
